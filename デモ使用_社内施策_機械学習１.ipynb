{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PortugalJip2022/Portugal2022/blob/main/%E3%83%87%E3%83%A2%E4%BD%BF%E7%94%A8_%E7%A4%BE%E5%86%85%E6%96%BD%E7%AD%96_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%EF%BC%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgO07u0n5FUj"
      },
      "source": [
        "# 01-1.パッケージの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJRvfwCFwcIL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c5c8004d-eb7b-4a0a-b1df-ad70259a87b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'IRdisplay'</li><li>'IRkernel'</li><li>'pbdZMQ'</li><li>'repr'</li><li>'askpass'</li><li>'assertthat'</li><li>'backports'</li><li>'base64enc'</li><li>'bit'</li><li>'bit64'</li><li>'blob'</li><li>'brew'</li><li>'brio'</li><li>'broom'</li><li>'bslib'</li><li>'cachem'</li><li>'callr'</li><li>'cellranger'</li><li>'cli'</li><li>'clipr'</li><li>'colorspace'</li><li>'commonmark'</li><li>'cpp11'</li><li>'crayon'</li><li>'credentials'</li><li>'curl'</li><li>'data.table'</li><li>'DBI'</li><li>'dbplyr'</li><li>'desc'</li><li>'devtools'</li><li>'diffobj'</li><li>'digest'</li><li>'dplyr'</li><li>'dtplyr'</li><li>'ellipsis'</li><li>'evaluate'</li><li>'fansi'</li><li>'farver'</li><li>'fastmap'</li><li>'forcats'</li><li>'fs'</li><li>'gargle'</li><li>'generics'</li><li>'gert'</li><li>'ggplot2'</li><li>'gh'</li><li>'gitcreds'</li><li>'glue'</li><li>'googledrive'</li><li>'googlesheets4'</li><li>'gtable'</li><li>'haven'</li><li>'highr'</li><li>'hms'</li><li>'htmltools'</li><li>'httr'</li><li>'ids'</li><li>'ini'</li><li>'isoband'</li><li>'jquerylib'</li><li>'jsonlite'</li><li>'knitr'</li><li>'labeling'</li><li>'lifecycle'</li><li>'lubridate'</li><li>'magrittr'</li><li>'memoise'</li><li>'mime'</li><li>'modelr'</li><li>'munsell'</li><li>'openssl'</li><li>'pillar'</li><li>'pkgbuild'</li><li>'pkgconfig'</li><li>'pkgload'</li><li>'praise'</li><li>'prettyunits'</li><li>'processx'</li><li>'progress'</li><li>'ps'</li><li>'purrr'</li><li>'R6'</li><li>'rappdirs'</li><li>'rcmdcheck'</li><li>'RColorBrewer'</li><li>'readr'</li><li>'readxl'</li><li>'rematch'</li><li>'rematch2'</li><li>'remotes'</li><li>'reprex'</li><li>'rlang'</li><li>'rmarkdown'</li><li>'roxygen2'</li><li>'rprojroot'</li><li>'rstudioapi'</li><li>'rversions'</li><li>'rvest'</li><li>'sass'</li><li>'scales'</li><li>'selectr'</li><li>'sessioninfo'</li><li>'stringi'</li><li>'stringr'</li><li>'svglite'</li><li>'sys'</li><li>'systemfonts'</li><li>'testthat'</li><li>'tibble'</li><li>'tidyr'</li><li>'tidyselect'</li><li>'tidyverse'</li><li>'tinytex'</li><li>'tzdb'</li><li>'usethis'</li><li>'utf8'</li><li>'uuid'</li><li>'vctrs'</li><li>'viridisLite'</li><li>'vroom'</li><li>'waldo'</li><li>'whisker'</li><li>'withr'</li><li>'xfun'</li><li>'xml2'</li><li>'xopen'</li><li>'yaml'</li><li>'zip'</li><li>'base'</li><li>'boot'</li><li>'class'</li><li>'cluster'</li><li>'codetools'</li><li>'compiler'</li><li>'datasets'</li><li>'foreign'</li><li>'graphics'</li><li>'grDevices'</li><li>'grid'</li><li>'KernSmooth'</li><li>'lattice'</li><li>'MASS'</li><li>'Matrix'</li><li>'methods'</li><li>'mgcv'</li><li>'nlme'</li><li>'nnet'</li><li>'parallel'</li><li>'rpart'</li><li>'spatial'</li><li>'splines'</li><li>'stats'</li><li>'stats4'</li><li>'survival'</li><li>'tcltk'</li><li>'tools'</li><li>'utils'</li></ol>\n"
            ],
            "text/markdown": "1. 'IRdisplay'\n2. 'IRkernel'\n3. 'pbdZMQ'\n4. 'repr'\n5. 'askpass'\n6. 'assertthat'\n7. 'backports'\n8. 'base64enc'\n9. 'bit'\n10. 'bit64'\n11. 'blob'\n12. 'brew'\n13. 'brio'\n14. 'broom'\n15. 'bslib'\n16. 'cachem'\n17. 'callr'\n18. 'cellranger'\n19. 'cli'\n20. 'clipr'\n21. 'colorspace'\n22. 'commonmark'\n23. 'cpp11'\n24. 'crayon'\n25. 'credentials'\n26. 'curl'\n27. 'data.table'\n28. 'DBI'\n29. 'dbplyr'\n30. 'desc'\n31. 'devtools'\n32. 'diffobj'\n33. 'digest'\n34. 'dplyr'\n35. 'dtplyr'\n36. 'ellipsis'\n37. 'evaluate'\n38. 'fansi'\n39. 'farver'\n40. 'fastmap'\n41. 'forcats'\n42. 'fs'\n43. 'gargle'\n44. 'generics'\n45. 'gert'\n46. 'ggplot2'\n47. 'gh'\n48. 'gitcreds'\n49. 'glue'\n50. 'googledrive'\n51. 'googlesheets4'\n52. 'gtable'\n53. 'haven'\n54. 'highr'\n55. 'hms'\n56. 'htmltools'\n57. 'httr'\n58. 'ids'\n59. 'ini'\n60. 'isoband'\n61. 'jquerylib'\n62. 'jsonlite'\n63. 'knitr'\n64. 'labeling'\n65. 'lifecycle'\n66. 'lubridate'\n67. 'magrittr'\n68. 'memoise'\n69. 'mime'\n70. 'modelr'\n71. 'munsell'\n72. 'openssl'\n73. 'pillar'\n74. 'pkgbuild'\n75. 'pkgconfig'\n76. 'pkgload'\n77. 'praise'\n78. 'prettyunits'\n79. 'processx'\n80. 'progress'\n81. 'ps'\n82. 'purrr'\n83. 'R6'\n84. 'rappdirs'\n85. 'rcmdcheck'\n86. 'RColorBrewer'\n87. 'readr'\n88. 'readxl'\n89. 'rematch'\n90. 'rematch2'\n91. 'remotes'\n92. 'reprex'\n93. 'rlang'\n94. 'rmarkdown'\n95. 'roxygen2'\n96. 'rprojroot'\n97. 'rstudioapi'\n98. 'rversions'\n99. 'rvest'\n100. 'sass'\n101. 'scales'\n102. 'selectr'\n103. 'sessioninfo'\n104. 'stringi'\n105. 'stringr'\n106. 'svglite'\n107. 'sys'\n108. 'systemfonts'\n109. 'testthat'\n110. 'tibble'\n111. 'tidyr'\n112. 'tidyselect'\n113. 'tidyverse'\n114. 'tinytex'\n115. 'tzdb'\n116. 'usethis'\n117. 'utf8'\n118. 'uuid'\n119. 'vctrs'\n120. 'viridisLite'\n121. 'vroom'\n122. 'waldo'\n123. 'whisker'\n124. 'withr'\n125. 'xfun'\n126. 'xml2'\n127. 'xopen'\n128. 'yaml'\n129. 'zip'\n130. 'base'\n131. 'boot'\n132. 'class'\n133. 'cluster'\n134. 'codetools'\n135. 'compiler'\n136. 'datasets'\n137. 'foreign'\n138. 'graphics'\n139. 'grDevices'\n140. 'grid'\n141. 'KernSmooth'\n142. 'lattice'\n143. 'MASS'\n144. 'Matrix'\n145. 'methods'\n146. 'mgcv'\n147. 'nlme'\n148. 'nnet'\n149. 'parallel'\n150. 'rpart'\n151. 'spatial'\n152. 'splines'\n153. 'stats'\n154. 'stats4'\n155. 'survival'\n156. 'tcltk'\n157. 'tools'\n158. 'utils'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'IRdisplay'\n\\item 'IRkernel'\n\\item 'pbdZMQ'\n\\item 'repr'\n\\item 'askpass'\n\\item 'assertthat'\n\\item 'backports'\n\\item 'base64enc'\n\\item 'bit'\n\\item 'bit64'\n\\item 'blob'\n\\item 'brew'\n\\item 'brio'\n\\item 'broom'\n\\item 'bslib'\n\\item 'cachem'\n\\item 'callr'\n\\item 'cellranger'\n\\item 'cli'\n\\item 'clipr'\n\\item 'colorspace'\n\\item 'commonmark'\n\\item 'cpp11'\n\\item 'crayon'\n\\item 'credentials'\n\\item 'curl'\n\\item 'data.table'\n\\item 'DBI'\n\\item 'dbplyr'\n\\item 'desc'\n\\item 'devtools'\n\\item 'diffobj'\n\\item 'digest'\n\\item 'dplyr'\n\\item 'dtplyr'\n\\item 'ellipsis'\n\\item 'evaluate'\n\\item 'fansi'\n\\item 'farver'\n\\item 'fastmap'\n\\item 'forcats'\n\\item 'fs'\n\\item 'gargle'\n\\item 'generics'\n\\item 'gert'\n\\item 'ggplot2'\n\\item 'gh'\n\\item 'gitcreds'\n\\item 'glue'\n\\item 'googledrive'\n\\item 'googlesheets4'\n\\item 'gtable'\n\\item 'haven'\n\\item 'highr'\n\\item 'hms'\n\\item 'htmltools'\n\\item 'httr'\n\\item 'ids'\n\\item 'ini'\n\\item 'isoband'\n\\item 'jquerylib'\n\\item 'jsonlite'\n\\item 'knitr'\n\\item 'labeling'\n\\item 'lifecycle'\n\\item 'lubridate'\n\\item 'magrittr'\n\\item 'memoise'\n\\item 'mime'\n\\item 'modelr'\n\\item 'munsell'\n\\item 'openssl'\n\\item 'pillar'\n\\item 'pkgbuild'\n\\item 'pkgconfig'\n\\item 'pkgload'\n\\item 'praise'\n\\item 'prettyunits'\n\\item 'processx'\n\\item 'progress'\n\\item 'ps'\n\\item 'purrr'\n\\item 'R6'\n\\item 'rappdirs'\n\\item 'rcmdcheck'\n\\item 'RColorBrewer'\n\\item 'readr'\n\\item 'readxl'\n\\item 'rematch'\n\\item 'rematch2'\n\\item 'remotes'\n\\item 'reprex'\n\\item 'rlang'\n\\item 'rmarkdown'\n\\item 'roxygen2'\n\\item 'rprojroot'\n\\item 'rstudioapi'\n\\item 'rversions'\n\\item 'rvest'\n\\item 'sass'\n\\item 'scales'\n\\item 'selectr'\n\\item 'sessioninfo'\n\\item 'stringi'\n\\item 'stringr'\n\\item 'svglite'\n\\item 'sys'\n\\item 'systemfonts'\n\\item 'testthat'\n\\item 'tibble'\n\\item 'tidyr'\n\\item 'tidyselect'\n\\item 'tidyverse'\n\\item 'tinytex'\n\\item 'tzdb'\n\\item 'usethis'\n\\item 'utf8'\n\\item 'uuid'\n\\item 'vctrs'\n\\item 'viridisLite'\n\\item 'vroom'\n\\item 'waldo'\n\\item 'whisker'\n\\item 'withr'\n\\item 'xfun'\n\\item 'xml2'\n\\item 'xopen'\n\\item 'yaml'\n\\item 'zip'\n\\item 'base'\n\\item 'boot'\n\\item 'class'\n\\item 'cluster'\n\\item 'codetools'\n\\item 'compiler'\n\\item 'datasets'\n\\item 'foreign'\n\\item 'graphics'\n\\item 'grDevices'\n\\item 'grid'\n\\item 'KernSmooth'\n\\item 'lattice'\n\\item 'MASS'\n\\item 'Matrix'\n\\item 'methods'\n\\item 'mgcv'\n\\item 'nlme'\n\\item 'nnet'\n\\item 'parallel'\n\\item 'rpart'\n\\item 'spatial'\n\\item 'splines'\n\\item 'stats'\n\\item 'stats4'\n\\item 'survival'\n\\item 'tcltk'\n\\item 'tools'\n\\item 'utils'\n\\end{enumerate*}\n",
            "text/plain": [
              "  [1] \"IRdisplay\"     \"IRkernel\"      \"pbdZMQ\"        \"repr\"         \n",
              "  [5] \"askpass\"       \"assertthat\"    \"backports\"     \"base64enc\"    \n",
              "  [9] \"bit\"           \"bit64\"         \"blob\"          \"brew\"         \n",
              " [13] \"brio\"          \"broom\"         \"bslib\"         \"cachem\"       \n",
              " [17] \"callr\"         \"cellranger\"    \"cli\"           \"clipr\"        \n",
              " [21] \"colorspace\"    \"commonmark\"    \"cpp11\"         \"crayon\"       \n",
              " [25] \"credentials\"   \"curl\"          \"data.table\"    \"DBI\"          \n",
              " [29] \"dbplyr\"        \"desc\"          \"devtools\"      \"diffobj\"      \n",
              " [33] \"digest\"        \"dplyr\"         \"dtplyr\"        \"ellipsis\"     \n",
              " [37] \"evaluate\"      \"fansi\"         \"farver\"        \"fastmap\"      \n",
              " [41] \"forcats\"       \"fs\"            \"gargle\"        \"generics\"     \n",
              " [45] \"gert\"          \"ggplot2\"       \"gh\"            \"gitcreds\"     \n",
              " [49] \"glue\"          \"googledrive\"   \"googlesheets4\" \"gtable\"       \n",
              " [53] \"haven\"         \"highr\"         \"hms\"           \"htmltools\"    \n",
              " [57] \"httr\"          \"ids\"           \"ini\"           \"isoband\"      \n",
              " [61] \"jquerylib\"     \"jsonlite\"      \"knitr\"         \"labeling\"     \n",
              " [65] \"lifecycle\"     \"lubridate\"     \"magrittr\"      \"memoise\"      \n",
              " [69] \"mime\"          \"modelr\"        \"munsell\"       \"openssl\"      \n",
              " [73] \"pillar\"        \"pkgbuild\"      \"pkgconfig\"     \"pkgload\"      \n",
              " [77] \"praise\"        \"prettyunits\"   \"processx\"      \"progress\"     \n",
              " [81] \"ps\"            \"purrr\"         \"R6\"            \"rappdirs\"     \n",
              " [85] \"rcmdcheck\"     \"RColorBrewer\"  \"readr\"         \"readxl\"       \n",
              " [89] \"rematch\"       \"rematch2\"      \"remotes\"       \"reprex\"       \n",
              " [93] \"rlang\"         \"rmarkdown\"     \"roxygen2\"      \"rprojroot\"    \n",
              " [97] \"rstudioapi\"    \"rversions\"     \"rvest\"         \"sass\"         \n",
              "[101] \"scales\"        \"selectr\"       \"sessioninfo\"   \"stringi\"      \n",
              "[105] \"stringr\"       \"svglite\"       \"sys\"           \"systemfonts\"  \n",
              "[109] \"testthat\"      \"tibble\"        \"tidyr\"         \"tidyselect\"   \n",
              "[113] \"tidyverse\"     \"tinytex\"       \"tzdb\"          \"usethis\"      \n",
              "[117] \"utf8\"          \"uuid\"          \"vctrs\"         \"viridisLite\"  \n",
              "[121] \"vroom\"         \"waldo\"         \"whisker\"       \"withr\"        \n",
              "[125] \"xfun\"          \"xml2\"          \"xopen\"         \"yaml\"         \n",
              "[129] \"zip\"           \"base\"          \"boot\"          \"class\"        \n",
              "[133] \"cluster\"       \"codetools\"     \"compiler\"      \"datasets\"     \n",
              "[137] \"foreign\"       \"graphics\"      \"grDevices\"     \"grid\"         \n",
              "[141] \"KernSmooth\"    \"lattice\"       \"MASS\"          \"Matrix\"       \n",
              "[145] \"methods\"       \"mgcv\"          \"nlme\"          \"nnet\"         \n",
              "[149] \"parallel\"      \"rpart\"         \"spatial\"       \"splines\"      \n",
              "[153] \"stats\"         \"stats4\"        \"survival\"      \"tcltk\"        \n",
              "[157] \"tools\"         \"utils\"        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#事前準備\n",
        "p = installed.packages()\n",
        "rownames( p )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bhqDoba-3JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJAQ957zyY9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4faff6-5832-4765-e366-ef88cb72eba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"dplyr\")\n",
        "library(dplyr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfA-5YQB3Cyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deeba476-5dc0-4868-bad2-cc62a93c526c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘bitops’, ‘gtools’, ‘caTools’, ‘gplots’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"ROCR\")\n",
        "library(ROCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNWhr-3p3Fm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f4340f-9572-4653-9585-bf14e1d6d4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message:\n",
            "“package ‘splines’ is a base package, and should not be updated”\n"
          ]
        }
      ],
      "source": [
        "\n",
        "install.packages(\"splines\")\n",
        "library(splines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvQPaOgH3HGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8171301c-e7dd-4d01-e096-f656cf103f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"stringr\")\n",
        "library(stringr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rbW2O6E3Je9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccdbe5b-26a7-494b-f017-c226da7e3efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘future.apply’, ‘progressr’, ‘numDeriv’, ‘SQUAREM’, ‘lava’, ‘prodlim’, ‘proxy’, ‘iterators’, ‘Rcpp’, ‘gower’, ‘hardhat’, ‘ipred’, ‘timeDate’, ‘e1071’, ‘foreach’, ‘ModelMetrics’, ‘plyr’, ‘pROC’, ‘recipes’, ‘reshape2’\n",
            "\n",
            "\n",
            "Loading required package: ggplot2\n",
            "\n",
            "Loading required package: lattice\n",
            "\n",
            "Warning message in system(\"timedatectl\", intern = TRUE):\n",
            "“running command 'timedatectl' had status 1”\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"caret\")\n",
        "library(caret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUgC8E753Kof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5defb0d-fc8b-4296-a3d2-18adf21068cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"readr\")\n",
        "library(readr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbgmfEVh38g_"
      },
      "outputs": [],
      "source": [
        "#install.packages(\"magick\")\n",
        "#library(magick)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqxHlRSi3KfV"
      },
      "outputs": [],
      "source": [
        "#install.packages(\"summarytools\")\n",
        "#library(summarytools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "malSGODf3NfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd52a57-0927-4899-f4ec-804371bef2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"RANN\")\n",
        "library(RANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EMiovX23PYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ae7a85-1d30-487b-a77f-5b2c1667397f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"skimr\")\n",
        "library(skimr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JawmK7tfYZfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92caab1c-f96b-4dab-b056-89a85a5ea760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘xgboost’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    slice\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"xgboost\")\n",
        "library(xgboost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVez4HvQPiG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019a581f-4841-4622-c5fe-2cce935cb377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘TH.data’, ‘libcoin’, ‘matrixStats’, ‘multcomp’, ‘mvtnorm’, ‘modeltools’, ‘strucchange’, ‘coin’, ‘zoo’, ‘sandwich’, ‘measures’, ‘party’\n",
            "\n",
            "\n",
            "Loading required package: measures\n",
            "\n",
            "\n",
            "Attaching package: ‘measures’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:caret’:\n",
            "\n",
            "    MAE, RMSE\n",
            "\n",
            "\n",
            "Loading required package: party\n",
            "\n",
            "Loading required package: grid\n",
            "\n",
            "Loading required package: mvtnorm\n",
            "\n",
            "Loading required package: modeltools\n",
            "\n",
            "Loading required package: stats4\n",
            "\n",
            "Loading required package: strucchange\n",
            "\n",
            "Loading required package: zoo\n",
            "\n",
            "\n",
            "Attaching package: ‘zoo’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    as.Date, as.Date.numeric\n",
            "\n",
            "\n",
            "Loading required package: sandwich\n",
            "\n",
            "\n",
            "Attaching package: ‘strucchange’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:stringr’:\n",
            "\n",
            "    boundary\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘varImp’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:caret’:\n",
            "\n",
            "    varImp\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"varImp\")\n",
        "library(varImp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z6VznLNo3hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f009e51-4e11-40fa-b609-a1e9b23a0e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘kernlab’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:modeltools’:\n",
            "\n",
            "    prior\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:ggplot2’:\n",
            "\n",
            "    alpha\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"kernlab\")\n",
        "library(kernlab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsihRmGrTn_O"
      },
      "outputs": [],
      "source": [
        "#install.packages(\"doParallel\")\n",
        "#library(doParallel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C8sj-isUDHk"
      },
      "outputs": [],
      "source": [
        "#detectCores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUjxYh6AWKmb"
      },
      "outputs": [],
      "source": [
        "#cl <- makePSOCKcluster(2)\n",
        "#registerDoParallel(cl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdacJBrx8huP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61efa744-677e-41f8-e014-f373b479b6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘R.methodsS3’, ‘R.oo’, ‘R.utils’, ‘httpuv’, ‘xtable’, ‘fontawesome’, ‘sourcetools’, ‘later’, ‘promises’, ‘R.cache’, ‘shiny’, ‘miniUI’, ‘styler’, ‘classInt’, ‘labelled’, ‘combinat’, ‘questionr’\n",
            "\n",
            "\n",
            "Loading required package: MASS\n",
            "\n",
            "\n",
            "Attaching package: ‘MASS’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    select\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"klaR\")\n",
        "library(klaR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-NX6rsTPm1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a527f18-ba18-45be-c6f1-04bdf7da85f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "randomForest 4.7-1.1\n",
            "\n",
            "Type rfNews() to see new features/changes/bug fixes.\n",
            "\n",
            "\n",
            "Attaching package: ‘randomForest’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:ggplot2’:\n",
            "\n",
            "    margin\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    combine\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"randomForest\")\n",
        "library(randomForest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlg14TBhBSe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b0945d-78b8-4626-b467-ebc209aef582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"deepnet\")\n",
        "library(deepnet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " install.packages(\"stepPlr\")\n",
        "library(stepPlr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm_B5TOt27Nl",
        "outputId": "210fff5e-ce45-4c29-e5c2-3b086bcd1541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " install.packages(\"VGAM\")\n",
        "library(VGAM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu5bUlcZEbAh",
        "outputId": "eabaa5e8-5236-4190-e53c-6e9139d81dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘VGAM’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:kernlab’:\n",
            "\n",
            "    nvar\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:caret’:\n",
            "\n",
            "    predictors\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyFDjKV67P3r"
      },
      "source": [
        "# 01-2.データ準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLNmP38MPc_G"
      },
      "outputs": [],
      "source": [
        "samp <-\n",
        "  read.table(\"https://raw.githubusercontent.com/PortugalJip2022/Portugal2022/main/bank-full.csv\",\n",
        "                  header=TRUE, stringsAsFactors=TRUE, sep=\";\", na.strings=\"NA\", dec=\".\",\n",
        "             strip.white=TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imVuOeZYSHV3"
      },
      "outputs": [],
      "source": [
        "#頭にidをふる\n",
        "samp$id <- 1:nrow(samp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3jufgPsDoLBN",
        "outputId": "e989c446-513a-4934-9ba5-cf4e0c4cad97"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "45211"
            ],
            "text/markdown": "45211",
            "text/latex": "45211",
            "text/plain": [
              "[1] 45211"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#件数確認\n",
        "nrow(samp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXCF2Rj37Zzj"
      },
      "source": [
        "# 01-3.モデル投入用変数の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ad5uDA0fw7d"
      },
      "outputs": [],
      "source": [
        "# カテゴリ変数作成\n",
        "\n",
        "samp$C_job <- as.factor(samp$job)\n",
        "samp$C_marital <- as.factor(samp$marital)\n",
        "samp$C_education <- as.factor(samp$education)\n",
        "samp$C_default <- as.factor(samp$default)\n",
        "samp$C_housing <- as.factor(samp$housing)\n",
        "samp$C_loan<- as.factor(samp$loan)\n",
        "samp$C_contact <- as.factor(samp$contact)\n",
        "samp$C_day <- as.factor(samp$day)\n",
        "samp$C_month <- as.factor(samp$month)\n",
        "samp$C_poutcome <- as.factor(samp$poutcome)\n",
        "samp$C_y <- as.factor(samp$y)\n",
        "\n",
        "#目的変数をフラグに\n",
        "samp$yF <- if_else(samp$y == \"yes\",1,0)\n",
        "samp$C_yF <- as.factor(samp$yF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9niZEluVGt6"
      },
      "outputs": [],
      "source": [
        "# 連続値作成\n",
        "\n",
        "##年齢\n",
        "samp$age_60 <- pmin(samp$age,60)\n",
        "\n",
        "#＃平均残高\n",
        "samp$balance_5000 <- pmax(samp$balance,-1)\n",
        "samp$balance_5000 <- pmin(samp$balance_5000,5000)\n",
        "\n",
        "##現在のマーケティングキャンペーンにおける顧客への連絡回数\n",
        "samp$campaign_11 <- pmin(samp$campaign,11)\n",
        "\n",
        "##以前のマーケティングキャンペーンにおける顧客への最終連絡日からの経過日数\n",
        "samp$pdays_120 <- pmin(samp$pdays,120)\n",
        "\n",
        "##以前のマーケティングキャンペーンにおける顧客への連絡回数\n",
        "samp$previous_11 <- pmin(samp$previous,11)\n",
        "\n",
        "\n",
        "#平滑化\n",
        "library(splines)\n",
        "i <- 3\n",
        "\n",
        "B_age <- bs(samp$age_60,df=i)\n",
        "B_balance <- bs(samp$balance_5000,df = i)\n",
        "B_campaign <- bs(samp$campaign_11,df = i)\n",
        "B_pdays <- bs(samp$pdays_120,df = i)\n",
        "B_previous <- bs(samp$previous_11,df = i)\n",
        "\n",
        "samp[,\"B_age\"] <- B_age\n",
        "samp[,\"B_balance\"] <- B_balance\n",
        "samp[,\"B_campaign\"] <- B_campaign\n",
        "samp[,\"B_pdays\"] <- B_pdays\n",
        "samp[,\"B_previous\"] <- B_previous\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8ZNcJy-oYYGz",
        "outputId": "f9e37cca-5547-4e23-87ad-ee978ef12ad6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      age                 job           marital          education    \n",
              " Min.   :18.00   blue-collar:9732   divorced: 5207   primary  : 6851  \n",
              " 1st Qu.:33.00   management :9458   married :27214   secondary:23202  \n",
              " Median :39.00   technician :7597   single  :12790   tertiary :13301  \n",
              " Mean   :40.94   admin.     :5171                    unknown  : 1857  \n",
              " 3rd Qu.:48.00   services   :4154                                     \n",
              " Max.   :95.00   retired    :2264                                     \n",
              "                 (Other)    :6835                                     \n",
              " default        balance       housing      loan            contact     \n",
              " no :44396   Min.   : -8019   no :20081   no :37967   cellular :29285  \n",
              " yes:  815   1st Qu.:    72   yes:25130   yes: 7244   telephone: 2906  \n",
              "             Median :   448                           unknown  :13020  \n",
              "             Mean   :  1362                                            \n",
              "             3rd Qu.:  1428                                            \n",
              "             Max.   :102127                                            \n",
              "                                                                       \n",
              "      day            month          duration         campaign     \n",
              " Min.   : 1.00   may    :13766   Min.   :   0.0   Min.   : 1.000  \n",
              " 1st Qu.: 8.00   jul    : 6895   1st Qu.: 103.0   1st Qu.: 1.000  \n",
              " Median :16.00   aug    : 6247   Median : 180.0   Median : 2.000  \n",
              " Mean   :15.81   jun    : 5341   Mean   : 258.2   Mean   : 2.764  \n",
              " 3rd Qu.:21.00   nov    : 3970   3rd Qu.: 319.0   3rd Qu.: 3.000  \n",
              " Max.   :31.00   apr    : 2932   Max.   :4918.0   Max.   :63.000  \n",
              "                 (Other): 6060                                    \n",
              "     pdays          previous           poutcome       y               id       \n",
              " Min.   : -1.0   Min.   :  0.0000   failure: 4901   no :39922   Min.   :    1  \n",
              " 1st Qu.: -1.0   1st Qu.:  0.0000   other  : 1840   yes: 5289   1st Qu.:11304  \n",
              " Median : -1.0   Median :  0.0000   success: 1511               Median :22606  \n",
              " Mean   : 40.2   Mean   :  0.5803   unknown:36959               Mean   :22606  \n",
              " 3rd Qu.: -1.0   3rd Qu.:  0.0000                               3rd Qu.:33908  \n",
              " Max.   :871.0   Max.   :275.0000                               Max.   :45211  \n",
              "                                                                               \n",
              "         C_job         C_marital        C_education    C_default   C_housing  \n",
              " blue-collar:9732   divorced: 5207   primary  : 6851   no :44396   no :20081  \n",
              " management :9458   married :27214   secondary:23202   yes:  815   yes:25130  \n",
              " technician :7597   single  :12790   tertiary :13301                          \n",
              " admin.     :5171                    unknown  : 1857                          \n",
              " services   :4154                                                             \n",
              " retired    :2264                                                             \n",
              " (Other)    :6835                                                             \n",
              " C_loan          C_contact         C_day          C_month        C_poutcome   \n",
              " no :37967   cellular :29285   20     : 2752   may    :13766   failure: 4901  \n",
              " yes: 7244   telephone: 2906   18     : 2308   jul    : 6895   other  : 1840  \n",
              "             unknown  :13020   21     : 2026   aug    : 6247   success: 1511  \n",
              "                               17     : 1939   jun    : 5341   unknown:36959  \n",
              "                               6      : 1932   nov    : 3970                  \n",
              "                               5      : 1910   apr    : 2932                  \n",
              "                               (Other):32344   (Other): 6060                  \n",
              "  C_y              yF        C_yF          age_60       balance_5000 \n",
              " no :39922   Min.   :0.000   0:39922   Min.   :18.00   Min.   :  -1  \n",
              " yes: 5289   1st Qu.:0.000   1: 5289   1st Qu.:33.00   1st Qu.:  72  \n",
              "             Median :0.000             Median :39.00   Median : 448  \n",
              "             Mean   :0.117             Mean   :40.68   Mean   :1085  \n",
              "             3rd Qu.:0.000             3rd Qu.:48.00   3rd Qu.:1428  \n",
              "             Max.   :1.000             Max.   :60.00   Max.   :5000  \n",
              "                                                                     \n",
              "  campaign_11      pdays_120       previous_11     \n",
              " Min.   : 1.00   Min.   : -1.00   Min.   : 0.0000  \n",
              " 1st Qu.: 1.00   1st Qu.: -1.00   1st Qu.: 0.0000  \n",
              " Median : 2.00   Median : -1.00   Median : 0.0000  \n",
              " Mean   : 2.61   Mean   : 19.59   Mean   : 0.5402  \n",
              " 3rd Qu.: 3.00   3rd Qu.: -1.00   3rd Qu.: 0.0000  \n",
              " Max.   :11.00   Max.   :120.00   Max.   :11.0000  \n",
              "                                                   \n",
              "       B_age.1              B_age.2              B_age.3      \n",
              " Min.   :0.0000000    Min.   :0.0000000    Min.   :0.0000000  \n",
              " 1st Qu.:0.1749271    1st Qu.:0.1984532    1st Qu.:0.0455539  \n",
              " Median :0.3563330    Median :0.2925575    Median :0.1250000  \n",
              " Mean   :0.2921939    Mean   :0.2841266    Mean   :0.2532662  \n",
              " 3rd Qu.:0.4302316    3rd Qu.:0.3968659    3rd Qu.:0.3644315  \n",
              " Max.   :0.4444444    Max.   :0.4444444    Max.   :1.0000000  \n",
              "                                                              \n",
              "     B_balance.1          B_balance.2          B_balance.3    \n",
              " Min.   :0.0000000    Min.   :0.0000000    Min.   :0.0000000  \n",
              " 1st Qu.:0.0053795    1st Qu.:0.0000202    1st Qu.:0.0000031  \n",
              " Median :0.1492131    Median :0.0121296    Median :0.0007237  \n",
              " Mean   :0.1773943    Mean   :0.0797731    Mean   :0.1048345  \n",
              " 3rd Qu.:0.3262020    3rd Qu.:0.1019023    3rd Qu.:0.0233306  \n",
              " Max.   :0.4444444    Max.   :0.4444444    Max.   :1.0000000  \n",
              "                                                              \n",
              "    B_campaign.1         B_campaign.2         B_campaign.3    \n",
              " Min.   :0.0000000    Min.   :0.000000     Min.   :0.0000000  \n",
              " 1st Qu.:0.0000000    1st Qu.:0.000000     1st Qu.:0.0000000  \n",
              " Median :0.2430000    Median :0.027000     Median :0.0010000  \n",
              " Mean   :0.1838152    Mean   :0.072357     Mean   :0.0514776  \n",
              " 3rd Qu.:0.3750000    3rd Qu.:0.096000     3rd Qu.:0.0080000  \n",
              " Max.   :0.4410000    Max.   :0.441000     Max.   :1.0000000  \n",
              "                                                              \n",
              "      B_pdays.1            B_pdays.2            B_pdays.3     \n",
              " Min.   :0.0000000    Min.   :0.0000000    Min.   :0.0000000  \n",
              " 1st Qu.:0.0000000    1st Qu.:0.0000000    1st Qu.:0.0000000  \n",
              " Median :0.0000000    Median :0.0000000    Median :0.0000000  \n",
              " Mean   :0.0057055    Mean   :0.0132141    Mean   :0.1594651  \n",
              " 3rd Qu.:0.0000000    3rd Qu.:0.0000000    3rd Qu.:0.0000000  \n",
              " Max.   :0.4444216    Max.   :0.4444216    Max.   :1.0000000  \n",
              "                                                              \n",
              "    B_previous.1         B_previous.2         B_previous.3    \n",
              " Min.   :0.0000000    Min.   :0.0000000    Min.   :0.0000000  \n",
              " 1st Qu.:0.0000000    1st Qu.:0.0000000    1st Qu.:0.0000000  \n",
              " Median :0.0000000    Median :0.0000000    Median :0.0000000  \n",
              " Mean   :0.0567327    Mean   :0.0234807    Mean   :0.0145424  \n",
              " 3rd Qu.:0.0000000    3rd Qu.:0.0000000    3rd Qu.:0.0000000  \n",
              " Max.   :0.4417731    Max.   :0.4417731    Max.   :1.0000000  \n",
              "                                                              "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "summary(samp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBbPXoX4RnGb"
      },
      "source": [
        "上記データをインサンプルデータとアウトサンプルデータに分割させる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjgdDEbmGRQU"
      },
      "outputs": [],
      "source": [
        "# インサンプル作成\n",
        "set.seed(3)\n",
        "samp_i <- samp %>% sample_frac(0.5)\n",
        "\n",
        "# アウトサンプル作成\n",
        "samp_o <- samp[!(samp$id %in% samp_i$id), ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FTsd5Y5ATuNI",
        "outputId": "f0a89bca-927c-4204-dc81-dc1438720b48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "22606"
            ],
            "text/markdown": "22606",
            "text/latex": "22606",
            "text/plain": [
              "[1] 22606"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "22605"
            ],
            "text/markdown": "22605",
            "text/latex": "22605",
            "text/plain": [
              "[1] 22605"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#各件数確認\n",
        "nrow(samp_i)\n",
        "nrow(samp_o)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av5K4D2_7fUs"
      },
      "source": [
        "# 02.モデル作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30GNmmZH9589"
      },
      "source": [
        "## 02-1.全投入版の式を作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9iZf0Y8rFWI"
      },
      "outputs": [],
      "source": [
        "#各変数（単独）を準備\n",
        "crossstring <-\n",
        "  \"B_age + C_marital+ C_education + B_balance + C_housing + C_loan + C_contact + C_day + C_month + B_campaign + B_pdays + B_previous + C_poutcome\"\n",
        "\n",
        "#各変数（組み合わせ）を準備\n",
        "for (i in 1:5) {\n",
        "  for (j in 1:8) {\n",
        "    w <- str_flatten(c(switch(i,\n",
        "         \"1\"  = (\"B_age\"),\n",
        "         \"2\"  = (\"B_balance\"),\n",
        "         \"3\"  = (\"B_campaign\"),\n",
        "         \"4\" = (\"B_pdays\"),\n",
        "         \"5\" = (\"B_previous\"))\n",
        ",\n",
        "        switch(j,\n",
        "           \"1\"  = (\"C_marital\"),\n",
        "           \"2\"  = (\"C_education\"),\n",
        "           \"3\"  = (\"C_housing\"),\n",
        "           \"4\" = (\"C_loan\"),\n",
        "           \"5\" = (\"C_contact\"),\n",
        "           \"6\" = (\"C_day\"),\n",
        "           \"7\" = (\"C_month\"),\n",
        "           \"8\" = (\"C_poutcome\"))),\" * \")\n",
        "\n",
        "    crossstring <- str_flatten(c(w,crossstring),\" + \") }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qhmKboDvJJA",
        "outputId": "9f17b82d-3b19-470e-f666-80b24273a967"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'B_previous * C_poutcome + B_previous * C_month + B_previous * C_day + B_previous * C_contact + B_previous * C_loan + B_previous * C_housing + B_previous * C_education + B_previous * C_marital + B_pdays * C_poutcome + B_pdays * C_month + B_pdays * C_day + B_pdays * C_contact + B_pdays * C_loan + B_pdays * C_housing + B_pdays * C_education + B_pdays * C_marital + B_campaign * C_poutcome + B_campaign * C_month + B_campaign * C_day + B_campaign * C_contact + B_campaign * C_loan + B_campaign * C_housing + B_campaign * C_education + B_campaign * C_marital + B_balance * C_poutcome + B_balance * C_month + B_balance * C_day + B_balance * C_contact + B_balance * C_loan + B_balance * C_housing + B_balance * C_education + B_balance * C_marital + B_age * C_poutcome + B_age * C_month + B_age * C_day + B_age * C_contact + B_age * C_loan + B_age * C_housing + B_age * C_education + B_age * C_marital + B_age + C_marital+ C_education + B_balance + C_housing + C_loan + C_contact + C_day + C_month + B_campaign + B_pdays + B_previous + C_poutcome'"
            ],
            "text/markdown": "'B_previous * C_poutcome + B_previous * C_month + B_previous * C_day + B_previous * C_contact + B_previous * C_loan + B_previous * C_housing + B_previous * C_education + B_previous * C_marital + B_pdays * C_poutcome + B_pdays * C_month + B_pdays * C_day + B_pdays * C_contact + B_pdays * C_loan + B_pdays * C_housing + B_pdays * C_education + B_pdays * C_marital + B_campaign * C_poutcome + B_campaign * C_month + B_campaign * C_day + B_campaign * C_contact + B_campaign * C_loan + B_campaign * C_housing + B_campaign * C_education + B_campaign * C_marital + B_balance * C_poutcome + B_balance * C_month + B_balance * C_day + B_balance * C_contact + B_balance * C_loan + B_balance * C_housing + B_balance * C_education + B_balance * C_marital + B_age * C_poutcome + B_age * C_month + B_age * C_day + B_age * C_contact + B_age * C_loan + B_age * C_housing + B_age * C_education + B_age * C_marital + B_age + C_marital+ C_education + B_balance + C_housing + C_loan + C_contact + C_day + C_month + B_campaign + B_pdays + B_previous + C_poutcome'",
            "text/latex": "'B\\_previous * C\\_poutcome + B\\_previous * C\\_month + B\\_previous * C\\_day + B\\_previous * C\\_contact + B\\_previous * C\\_loan + B\\_previous * C\\_housing + B\\_previous * C\\_education + B\\_previous * C\\_marital + B\\_pdays * C\\_poutcome + B\\_pdays * C\\_month + B\\_pdays * C\\_day + B\\_pdays * C\\_contact + B\\_pdays * C\\_loan + B\\_pdays * C\\_housing + B\\_pdays * C\\_education + B\\_pdays * C\\_marital + B\\_campaign * C\\_poutcome + B\\_campaign * C\\_month + B\\_campaign * C\\_day + B\\_campaign * C\\_contact + B\\_campaign * C\\_loan + B\\_campaign * C\\_housing + B\\_campaign * C\\_education + B\\_campaign * C\\_marital + B\\_balance * C\\_poutcome + B\\_balance * C\\_month + B\\_balance * C\\_day + B\\_balance * C\\_contact + B\\_balance * C\\_loan + B\\_balance * C\\_housing + B\\_balance * C\\_education + B\\_balance * C\\_marital + B\\_age * C\\_poutcome + B\\_age * C\\_month + B\\_age * C\\_day + B\\_age * C\\_contact + B\\_age * C\\_loan + B\\_age * C\\_housing + B\\_age * C\\_education + B\\_age * C\\_marital + B\\_age + C\\_marital+ C\\_education + B\\_balance + C\\_housing + C\\_loan + C\\_contact + C\\_day + C\\_month + B\\_campaign + B\\_pdays + B\\_previous + C\\_poutcome'",
            "text/plain": [
              "[1] \"B_previous * C_poutcome + B_previous * C_month + B_previous * C_day + B_previous * C_contact + B_previous * C_loan + B_previous * C_housing + B_previous * C_education + B_previous * C_marital + B_pdays * C_poutcome + B_pdays * C_month + B_pdays * C_day + B_pdays * C_contact + B_pdays * C_loan + B_pdays * C_housing + B_pdays * C_education + B_pdays * C_marital + B_campaign * C_poutcome + B_campaign * C_month + B_campaign * C_day + B_campaign * C_contact + B_campaign * C_loan + B_campaign * C_housing + B_campaign * C_education + B_campaign * C_marital + B_balance * C_poutcome + B_balance * C_month + B_balance * C_day + B_balance * C_contact + B_balance * C_loan + B_balance * C_housing + B_balance * C_education + B_balance * C_marital + B_age * C_poutcome + B_age * C_month + B_age * C_day + B_age * C_contact + B_age * C_loan + B_age * C_housing + B_age * C_education + B_age * C_marital + B_age + C_marital+ C_education + B_balance + C_housing + C_loan + C_contact + C_day + C_month + B_campaign + B_pdays + B_previous + C_poutcome\""
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#作成した数式を確認\n",
        "crossstring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjJSFlLM9Ca6"
      },
      "source": [
        "## 02-2.モデル作成（ニューラルネットワーク）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EYM6s-q9o3z",
        "outputId": "6a132ac9-c27d-439c-c4d1-83699e2db8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21162.209442 \n",
            "iter  10 value 8088.997198\n",
            "iter  20 value 7644.011974\n",
            "iter  30 value 7239.426810\n",
            "iter  40 value 6846.455064\n",
            "iter  50 value 6504.562807\n",
            "iter  60 value 6267.889420\n",
            "iter  70 value 6132.787735\n",
            "iter  80 value 6033.726582\n",
            "iter  90 value 5962.098198\n",
            "iter 100 value 5924.738705\n",
            "final  value 5924.738705 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13953.058031 \n",
            "iter  10 value 7460.223059\n",
            "iter  20 value 7060.714801\n",
            "iter  30 value 6662.116240\n",
            "iter  40 value 6360.383529\n",
            "iter  50 value 6182.255664\n",
            "iter  60 value 6077.538683\n",
            "iter  70 value 6020.256246\n",
            "iter  80 value 5978.713423\n",
            "iter  90 value 5935.027829\n",
            "iter 100 value 5902.742736\n",
            "final  value 5902.742736 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14426.393512 \n",
            "iter  10 value 8165.904598\n",
            "iter  20 value 7455.636837\n",
            "iter  30 value 7025.814730\n",
            "iter  40 value 6652.887752\n",
            "iter  50 value 6445.866970\n",
            "iter  60 value 6346.794301\n",
            "iter  70 value 6285.262499\n",
            "iter  80 value 6253.140390\n",
            "iter  90 value 6229.821961\n",
            "iter 100 value 6197.973468\n",
            "final  value 6197.973468 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17397.286726 \n",
            "iter  10 value 8063.730898\n",
            "iter  20 value 6675.614902\n",
            "iter  30 value 6453.022667\n",
            "iter  40 value 6342.947156\n",
            "iter  50 value 6294.972037\n",
            "iter  60 value 6216.006235\n",
            "iter  70 value 6131.342420\n",
            "iter  80 value 6060.284962\n",
            "iter  90 value 6018.456276\n",
            "iter 100 value 5986.047024\n",
            "final  value 5986.047024 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13377.679373 \n",
            "iter  10 value 7928.280032\n",
            "iter  20 value 6895.484803\n",
            "iter  30 value 6622.254982\n",
            "iter  40 value 6418.454938\n",
            "iter  50 value 6251.554096\n",
            "iter  60 value 6169.180593\n",
            "iter  70 value 6124.340205\n",
            "iter  80 value 6076.819048\n",
            "iter  90 value 6042.640781\n",
            "iter 100 value 6005.390132\n",
            "final  value 6005.390132 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21550.044021 \n",
            "iter  10 value 8030.758793\n",
            "iter  20 value 7668.457143\n",
            "iter  30 value 7466.481872\n",
            "iter  40 value 7250.908459\n",
            "iter  50 value 7085.305200\n",
            "iter  60 value 6616.050670\n",
            "iter  70 value 6372.022443\n",
            "iter  80 value 6221.811740\n",
            "iter  90 value 6140.533171\n",
            "iter 100 value 6086.428676\n",
            "final  value 6086.428676 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17291.619594 \n",
            "iter  10 value 8230.584070\n",
            "iter  20 value 7567.427170\n",
            "iter  30 value 6892.575054\n",
            "iter  40 value 6499.081313\n",
            "iter  50 value 6357.431216\n",
            "iter  60 value 6278.034541\n",
            "iter  70 value 6234.142571\n",
            "iter  80 value 6215.886890\n",
            "iter  90 value 6195.037816\n",
            "iter 100 value 6159.901549\n",
            "final  value 6159.901549 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14926.012525 \n",
            "iter  10 value 8153.722460\n",
            "iter  20 value 6854.349734\n",
            "iter  30 value 6616.241888\n",
            "iter  40 value 6531.666727\n",
            "iter  50 value 6466.431723\n",
            "iter  60 value 6392.800029\n",
            "iter  70 value 6358.165064\n",
            "iter  80 value 6320.834174\n",
            "iter  90 value 6291.671218\n",
            "iter 100 value 6234.075048\n",
            "final  value 6234.075048 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16049.302678 \n",
            "iter  10 value 7985.012247\n",
            "iter  20 value 7417.865248\n",
            "iter  30 value 6987.110696\n",
            "iter  40 value 6722.778329\n",
            "iter  50 value 6578.890027\n",
            "iter  60 value 6505.652955\n",
            "iter  70 value 6467.616171\n",
            "iter  80 value 6422.571370\n",
            "iter  90 value 6327.586474\n",
            "iter 100 value 6222.413098\n",
            "final  value 6222.413098 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13596.029725 \n",
            "iter  10 value 8121.674084\n",
            "iter  20 value 7782.529035\n",
            "iter  30 value 6827.053139\n",
            "iter  40 value 6626.807764\n",
            "iter  50 value 6524.033258\n",
            "iter  60 value 6461.070787\n",
            "iter  70 value 6382.879744\n",
            "iter  80 value 6319.367600\n",
            "iter  90 value 6243.390156\n",
            "iter 100 value 6201.330980\n",
            "final  value 6201.330980 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 22256.256487 \n",
            "iter  10 value 8230.604223\n",
            "iter  20 value 7561.068989\n",
            "iter  30 value 6842.446608\n",
            "iter  40 value 6444.887997\n",
            "iter  50 value 6299.443596\n",
            "iter  60 value 6213.182434\n",
            "iter  70 value 6169.264873\n",
            "iter  80 value 6149.558154\n",
            "iter  90 value 6131.726371\n",
            "iter 100 value 6105.670324\n",
            "final  value 6105.670324 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23954.756884 \n",
            "iter  10 value 7806.990198\n",
            "iter  20 value 7135.894892\n",
            "iter  30 value 6695.172542\n",
            "iter  40 value 6488.707659\n",
            "iter  50 value 6344.890825\n",
            "iter  60 value 6272.992488\n",
            "iter  70 value 6234.574384\n",
            "iter  80 value 6211.669802\n",
            "iter  90 value 6192.216393\n",
            "iter 100 value 6176.036532\n",
            "final  value 6176.036532 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 22257.463871 \n",
            "iter  10 value 8334.533830\n",
            "iter  20 value 7769.427048\n",
            "iter  30 value 6990.634592\n",
            "iter  40 value 6690.996492\n",
            "iter  50 value 6483.990307\n",
            "iter  60 value 6394.548223\n",
            "iter  70 value 6335.085504\n",
            "iter  80 value 6293.622962\n",
            "iter  90 value 6275.798258\n",
            "iter 100 value 6260.835702\n",
            "final  value 6260.835702 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11077.851466 \n",
            "iter  10 value 7622.794864\n",
            "iter  20 value 7016.063882\n",
            "iter  30 value 6585.234115\n",
            "iter  40 value 6437.921873\n",
            "iter  50 value 6352.188510\n",
            "iter  60 value 6281.243176\n",
            "iter  70 value 6250.334605\n",
            "iter  80 value 6230.850762\n",
            "iter  90 value 6208.295874\n",
            "iter 100 value 6180.666107\n",
            "final  value 6180.666107 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14919.414363 \n",
            "iter  10 value 8231.999811\n",
            "iter  20 value 7555.758494\n",
            "iter  30 value 6753.350426\n",
            "iter  40 value 6491.033960\n",
            "iter  50 value 6374.562285\n",
            "iter  60 value 6277.355152\n",
            "iter  70 value 6218.134050\n",
            "iter  80 value 6181.434694\n",
            "iter  90 value 6141.972007\n",
            "iter 100 value 6106.527430\n",
            "final  value 6106.527430 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15445.648740 \n",
            "iter  10 value 7930.090623\n",
            "iter  20 value 7916.030480\n",
            "iter  30 value 7874.998650\n",
            "iter  40 value 7663.243280\n",
            "iter  50 value 7347.338689\n",
            "iter  60 value 7268.341033\n",
            "iter  70 value 7236.422254\n",
            "iter  80 value 7075.571789\n",
            "iter  90 value 6720.621727\n",
            "iter 100 value 6506.511846\n",
            "final  value 6506.511846 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19919.631827 \n",
            "iter  10 value 8265.681184\n",
            "iter  20 value 7599.107048\n",
            "iter  30 value 7068.056221\n",
            "iter  40 value 6754.216734\n",
            "iter  50 value 6613.121337\n",
            "iter  60 value 6502.875410\n",
            "iter  70 value 6446.831613\n",
            "iter  80 value 6380.390970\n",
            "iter  90 value 6320.249239\n",
            "iter 100 value 6270.545480\n",
            "final  value 6270.545480 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19730.236997 \n",
            "iter  10 value 8228.022356\n",
            "iter  20 value 7494.066329\n",
            "iter  30 value 6938.607659\n",
            "iter  40 value 6636.994548\n",
            "iter  50 value 6446.238918\n",
            "iter  60 value 6355.908431\n",
            "iter  70 value 6296.912946\n",
            "iter  80 value 6261.335808\n",
            "iter  90 value 6226.682608\n",
            "iter 100 value 6202.486341\n",
            "final  value 6202.486341 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 22439.770287 \n",
            "iter  10 value 8021.872577\n",
            "iter  20 value 6981.278075\n",
            "iter  30 value 6731.936311\n",
            "iter  40 value 6577.174613\n",
            "iter  50 value 6505.350189\n",
            "iter  60 value 6474.549011\n",
            "iter  70 value 6450.250306\n",
            "iter  80 value 6427.456705\n",
            "iter  90 value 6406.223904\n",
            "iter 100 value 6385.197381\n",
            "final  value 6385.197381 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13734.036348 \n",
            "iter  10 value 7975.794963\n",
            "iter  20 value 7595.863530\n",
            "iter  30 value 7393.579607\n",
            "iter  40 value 6813.685283\n",
            "iter  50 value 6647.897433\n",
            "iter  60 value 6548.300296\n",
            "iter  70 value 6465.235596\n",
            "iter  80 value 6403.092405\n",
            "iter  90 value 6349.388711\n",
            "iter 100 value 6319.834774\n",
            "final  value 6319.834774 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14995.423538 \n",
            "iter  10 value 7328.504127\n",
            "iter  20 value 6635.368223\n",
            "iter  30 value 6341.632645\n",
            "iter  40 value 6186.797524\n",
            "iter  50 value 6082.772729\n",
            "iter  60 value 5992.927405\n",
            "iter  70 value 5912.346296\n",
            "iter  80 value 5856.457337\n",
            "iter  90 value 5815.456311\n",
            "iter 100 value 5779.187396\n",
            "final  value 5779.187396 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18312.679654 \n",
            "iter  10 value 7930.004325\n",
            "iter  20 value 7213.516853\n",
            "iter  30 value 6742.345644\n",
            "iter  40 value 6330.440232\n",
            "iter  50 value 6130.954249\n",
            "iter  60 value 6034.873235\n",
            "iter  70 value 5983.359705\n",
            "iter  80 value 5949.091811\n",
            "iter  90 value 5913.722722\n",
            "iter 100 value 5878.764602\n",
            "final  value 5878.764602 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11132.343676 \n",
            "iter  10 value 7803.377025\n",
            "iter  20 value 6899.469167\n",
            "iter  30 value 6474.601887\n",
            "iter  40 value 6291.549943\n",
            "iter  50 value 6178.627150\n",
            "iter  60 value 6105.718997\n",
            "iter  70 value 6032.573381\n",
            "iter  80 value 5985.323658\n",
            "iter  90 value 5954.175381\n",
            "iter 100 value 5903.989642\n",
            "final  value 5903.989642 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14626.686671 \n",
            "iter  10 value 7327.288555\n",
            "iter  20 value 6547.963046\n",
            "iter  30 value 6375.781517\n",
            "iter  40 value 6223.057561\n",
            "iter  50 value 6146.401259\n",
            "iter  60 value 6114.012177\n",
            "iter  70 value 6070.044049\n",
            "iter  80 value 6036.523992\n",
            "iter  90 value 6013.895749\n",
            "iter 100 value 5993.359547\n",
            "final  value 5993.359547 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10375.946500 \n",
            "iter  10 value 7578.458193\n",
            "iter  20 value 6858.097446\n",
            "iter  30 value 6463.837947\n",
            "iter  40 value 6311.953577\n",
            "iter  50 value 6197.878516\n",
            "iter  60 value 6131.397406\n",
            "iter  70 value 6091.488256\n",
            "iter  80 value 6051.958771\n",
            "iter  90 value 6006.073359\n",
            "iter 100 value 5972.259392\n",
            "final  value 5972.259392 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11724.757847 \n",
            "iter  10 value 7312.674942\n",
            "iter  20 value 7034.857269\n",
            "iter  30 value 6747.488269\n",
            "iter  40 value 6326.751963\n",
            "iter  50 value 6152.317836\n",
            "iter  60 value 6083.957812\n",
            "iter  70 value 6019.572899\n",
            "iter  80 value 5994.439854\n",
            "iter  90 value 5980.587986\n",
            "iter 100 value 5966.510534\n",
            "final  value 5966.510534 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10537.100097 \n",
            "iter  10 value 7542.388305\n",
            "iter  20 value 6757.083672\n",
            "iter  30 value 6414.523603\n",
            "iter  40 value 6297.361085\n",
            "iter  50 value 6192.528121\n",
            "iter  60 value 6109.816628\n",
            "iter  70 value 6059.676281\n",
            "iter  80 value 6031.910399\n",
            "iter  90 value 5991.967847\n",
            "iter 100 value 5961.029391\n",
            "final  value 5961.029391 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10623.660027 \n",
            "iter  10 value 7462.385444\n",
            "iter  20 value 6930.094504\n",
            "iter  30 value 6713.688816\n",
            "iter  40 value 6590.524112\n",
            "iter  50 value 6461.168819\n",
            "iter  60 value 6294.929682\n",
            "iter  70 value 6157.868207\n",
            "iter  80 value 6099.027898\n",
            "iter  90 value 6073.135962\n",
            "iter 100 value 6036.111651\n",
            "final  value 6036.111651 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24552.972471 \n",
            "iter  10 value 7954.657499\n",
            "iter  20 value 6750.328156\n",
            "iter  30 value 6482.371842\n",
            "iter  40 value 6376.174919\n",
            "iter  50 value 6271.420253\n",
            "iter  60 value 6185.712604\n",
            "iter  70 value 6128.319796\n",
            "iter  80 value 6093.540686\n",
            "iter  90 value 6054.274385\n",
            "iter 100 value 6019.336858\n",
            "final  value 6019.336858 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17686.902415 \n",
            "iter  10 value 7951.519649\n",
            "iter  20 value 7178.297590\n",
            "iter  30 value 6566.008794\n",
            "iter  40 value 6409.220268\n",
            "iter  50 value 6273.457872\n",
            "iter  60 value 6199.998575\n",
            "iter  70 value 6148.783404\n",
            "iter  80 value 6112.824424\n",
            "iter  90 value 6087.311601\n",
            "iter 100 value 6056.642937\n",
            "final  value 6056.642937 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15464.279750 \n",
            "iter  10 value 7954.544117\n",
            "iter  20 value 6666.853867\n",
            "iter  30 value 6289.284986\n",
            "iter  40 value 5989.886091\n",
            "iter  50 value 5861.000678\n",
            "iter  60 value 5809.418036\n",
            "iter  70 value 5789.828446\n",
            "iter  80 value 5777.145246\n",
            "iter  90 value 5766.904999\n",
            "iter 100 value 5759.411774\n",
            "final  value 5759.411774 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10584.949492 \n",
            "iter  10 value 7084.964513\n",
            "iter  20 value 6642.216579\n",
            "iter  30 value 6526.010631\n",
            "iter  40 value 6427.813079\n",
            "iter  50 value 6267.104839\n",
            "iter  60 value 6111.455732\n",
            "iter  70 value 6019.305639\n",
            "iter  80 value 5957.224039\n",
            "iter  90 value 5867.724999\n",
            "iter 100 value 5791.950549\n",
            "final  value 5791.950549 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12761.568630 \n",
            "iter  10 value 7925.867261\n",
            "iter  20 value 7206.976549\n",
            "iter  30 value 6760.463927\n",
            "iter  40 value 6359.383903\n",
            "iter  50 value 6156.096296\n",
            "iter  60 value 6020.342284\n",
            "iter  70 value 5961.646435\n",
            "iter  80 value 5876.652051\n",
            "iter  90 value 5817.321433\n",
            "iter 100 value 5778.890606\n",
            "final  value 5778.890606 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21165.231166 \n",
            "iter  10 value 7933.823904\n",
            "iter  20 value 7039.043376\n",
            "iter  30 value 6493.845314\n",
            "iter  40 value 6146.398989\n",
            "iter  50 value 6046.370324\n",
            "iter  60 value 5983.686330\n",
            "iter  70 value 5910.377120\n",
            "iter  80 value 5854.970507\n",
            "iter  90 value 5819.876963\n",
            "iter 100 value 5791.137179\n",
            "final  value 5791.137179 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17402.918401 \n",
            "iter  10 value 7957.429940\n",
            "iter  20 value 7364.016660\n",
            "iter  30 value 6569.373948\n",
            "iter  40 value 6352.755869\n",
            "iter  50 value 6225.887504\n",
            "iter  60 value 6090.473687\n",
            "iter  70 value 6001.953247\n",
            "iter  80 value 5928.520608\n",
            "iter  90 value 5886.347659\n",
            "iter 100 value 5861.691302\n",
            "final  value 5861.691302 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17199.563925 \n",
            "iter  10 value 7983.574431\n",
            "iter  20 value 7624.699082\n",
            "iter  30 value 7423.630148\n",
            "iter  40 value 7275.169676\n",
            "iter  50 value 6565.785644\n",
            "iter  60 value 6343.059827\n",
            "iter  70 value 6198.679224\n",
            "iter  80 value 6075.461434\n",
            "iter  90 value 5990.732091\n",
            "iter 100 value 5948.395289\n",
            "final  value 5948.395289 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14294.698160 \n",
            "iter  10 value 7916.002429\n",
            "iter  20 value 7273.681127\n",
            "iter  30 value 6426.085360\n",
            "iter  40 value 6225.174712\n",
            "iter  50 value 6129.374189\n",
            "iter  60 value 6054.699082\n",
            "iter  70 value 5993.173517\n",
            "iter  80 value 5944.482699\n",
            "iter  90 value 5906.982240\n",
            "iter 100 value 5876.032966\n",
            "final  value 5876.032966 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19081.919567 \n",
            "iter  10 value 7921.720541\n",
            "iter  20 value 6515.335895\n",
            "iter  30 value 6342.557354\n",
            "iter  40 value 6242.140356\n",
            "iter  50 value 6161.442953\n",
            "iter  60 value 6091.023443\n",
            "iter  70 value 6047.927168\n",
            "iter  80 value 5992.804477\n",
            "iter  90 value 5950.297119\n",
            "iter 100 value 5927.717456\n",
            "final  value 5927.717456 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15241.795094 \n",
            "iter  10 value 7930.490051\n",
            "iter  20 value 7870.071762\n",
            "iter  30 value 7678.944655\n",
            "iter  40 value 7105.992530\n",
            "iter  50 value 6743.813701\n",
            "iter  60 value 6436.780346\n",
            "iter  70 value 6251.504180\n",
            "iter  80 value 6131.014060\n",
            "iter  90 value 6080.479309\n",
            "iter 100 value 6042.345663\n",
            "final  value 6042.345663 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11717.995022 \n",
            "iter  10 value 7554.698198\n",
            "iter  20 value 7215.376755\n",
            "iter  30 value 7100.327368\n",
            "iter  40 value 7061.487775\n",
            "iter  50 value 7024.806080\n",
            "iter  60 value 6995.004008\n",
            "iter  70 value 6981.617368\n",
            "iter  80 value 6974.015616\n",
            "iter  90 value 6960.869338\n",
            "iter 100 value 6692.767892\n",
            "final  value 6692.767892 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20970.695074 \n",
            "iter  10 value 8161.845038\n",
            "iter  20 value 8101.538039\n",
            "iter  30 value 7320.210336\n",
            "iter  40 value 6918.428802\n",
            "iter  50 value 6565.974465\n",
            "iter  60 value 6406.164126\n",
            "iter  70 value 6326.013079\n",
            "iter  80 value 6267.289107\n",
            "iter  90 value 6226.601414\n",
            "iter 100 value 6205.950427\n",
            "final  value 6205.950427 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16777.050714 \n",
            "iter  10 value 8149.840489\n",
            "iter  20 value 7175.501313\n",
            "iter  30 value 6776.480851\n",
            "iter  40 value 6412.187479\n",
            "iter  50 value 6262.859085\n",
            "iter  60 value 6192.472353\n",
            "iter  70 value 6159.742671\n",
            "iter  80 value 6138.242917\n",
            "iter  90 value 6125.892707\n",
            "iter 100 value 6119.557260\n",
            "final  value 6119.557260 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15120.451222 \n",
            "iter  10 value 8155.336524\n",
            "iter  20 value 7313.318766\n",
            "iter  30 value 6774.903826\n",
            "iter  40 value 6504.819419\n",
            "iter  50 value 6390.704650\n",
            "iter  60 value 6280.240827\n",
            "iter  70 value 6198.834963\n",
            "iter  80 value 6145.957356\n",
            "iter  90 value 6095.866265\n",
            "iter 100 value 6056.732516\n",
            "final  value 6056.732516 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17967.109281 \n",
            "iter  10 value 8269.807721\n",
            "iter  20 value 7422.252143\n",
            "iter  30 value 6877.782573\n",
            "iter  40 value 6543.278092\n",
            "iter  50 value 6415.695639\n",
            "iter  60 value 6310.074002\n",
            "iter  70 value 6235.519543\n",
            "iter  80 value 6178.401106\n",
            "iter  90 value 6139.518301\n",
            "iter 100 value 6098.163865\n",
            "final  value 6098.163865 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23731.655056 \n",
            "iter  10 value 8276.220399\n",
            "iter  20 value 7443.013388\n",
            "iter  30 value 7043.707632\n",
            "iter  40 value 6833.394152\n",
            "iter  50 value 6652.540188\n",
            "iter  60 value 6449.902636\n",
            "iter  70 value 6338.895131\n",
            "iter  80 value 6231.128711\n",
            "iter  90 value 6179.914438\n",
            "iter 100 value 6155.423283\n",
            "final  value 6155.423283 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11189.804121 \n",
            "iter  10 value 7514.254069\n",
            "iter  20 value 7186.625461\n",
            "iter  30 value 6846.651238\n",
            "iter  40 value 6548.477628\n",
            "iter  50 value 6427.043315\n",
            "iter  60 value 6322.868408\n",
            "iter  70 value 6246.340339\n",
            "iter  80 value 6183.950318\n",
            "iter  90 value 6133.684323\n",
            "iter 100 value 6108.063380\n",
            "final  value 6108.063380 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13535.279948 \n",
            "iter  10 value 7091.724170\n",
            "iter  20 value 6695.240770\n",
            "iter  30 value 6538.421055\n",
            "iter  40 value 6408.306480\n",
            "iter  50 value 6332.650956\n",
            "iter  60 value 6277.190053\n",
            "iter  70 value 6238.581088\n",
            "iter  80 value 6206.890876\n",
            "iter  90 value 6173.279372\n",
            "iter 100 value 6151.323410\n",
            "final  value 6151.323410 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15596.210142 \n",
            "iter  10 value 8173.754853\n",
            "iter  20 value 6899.344971\n",
            "iter  30 value 6665.317142\n",
            "iter  40 value 6545.721938\n",
            "iter  50 value 6456.406662\n",
            "iter  60 value 6422.069044\n",
            "iter  70 value 6390.521544\n",
            "iter  80 value 6361.211044\n",
            "iter  90 value 6323.305627\n",
            "iter 100 value 6279.699491\n",
            "final  value 6279.699491 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24879.894986 \n",
            "iter  10 value 8081.058747\n",
            "iter  20 value 7583.097601\n",
            "iter  30 value 7135.044105\n",
            "iter  40 value 6864.260247\n",
            "iter  50 value 6718.686191\n",
            "iter  60 value 6585.359116\n",
            "iter  70 value 6500.956545\n",
            "iter  80 value 6454.136907\n",
            "iter  90 value 6424.803173\n",
            "iter 100 value 6395.708887\n",
            "final  value 6395.708887 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20133.712350 \n",
            "iter  10 value 7933.027485\n",
            "iter  20 value 7534.781467\n",
            "iter  30 value 7322.650048\n",
            "iter  40 value 7243.962851\n",
            "iter  50 value 7223.494738\n",
            "iter  60 value 6626.566658\n",
            "iter  70 value 6494.355770\n",
            "iter  80 value 6412.016268\n",
            "iter  90 value 6376.274056\n",
            "iter 100 value 6339.640026\n",
            "final  value 6339.640026 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17505.626980 \n",
            "iter  10 value 7222.723781\n",
            "iter  20 value 6619.700195\n",
            "iter  30 value 6347.584835\n",
            "iter  40 value 6170.740404\n",
            "iter  50 value 6084.625852\n",
            "iter  60 value 6000.127867\n",
            "iter  70 value 5937.397518\n",
            "iter  80 value 5902.714637\n",
            "iter  90 value 5869.839384\n",
            "iter 100 value 5854.481142\n",
            "final  value 5854.481142 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13721.728087 \n",
            "iter  10 value 8066.617777\n",
            "iter  20 value 7273.962191\n",
            "iter  30 value 6424.760316\n",
            "iter  40 value 6212.631606\n",
            "iter  50 value 6088.784157\n",
            "iter  60 value 6019.981225\n",
            "iter  70 value 5975.635488\n",
            "iter  80 value 5955.200701\n",
            "iter  90 value 5931.730572\n",
            "iter 100 value 5911.499527\n",
            "final  value 5911.499527 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16872.032493 \n",
            "iter  10 value 7876.022236\n",
            "iter  20 value 7120.648352\n",
            "iter  30 value 6529.241804\n",
            "iter  40 value 6230.015555\n",
            "iter  50 value 6106.375113\n",
            "iter  60 value 6064.383637\n",
            "iter  70 value 6022.829397\n",
            "iter  80 value 5978.009260\n",
            "iter  90 value 5927.227261\n",
            "iter 100 value 5871.423052\n",
            "final  value 5871.423052 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21715.324629 \n",
            "iter  10 value 8074.447110\n",
            "iter  20 value 6652.448388\n",
            "iter  30 value 6315.049088\n",
            "iter  40 value 6175.423578\n",
            "iter  50 value 6115.538012\n",
            "iter  60 value 6071.623576\n",
            "iter  70 value 6042.811383\n",
            "iter  80 value 6013.156182\n",
            "iter  90 value 5983.475284\n",
            "iter 100 value 5961.244335\n",
            "final  value 5961.244335 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14847.125931 \n",
            "iter  10 value 8079.562518\n",
            "iter  20 value 7552.103682\n",
            "iter  30 value 6987.217355\n",
            "iter  40 value 6553.351346\n",
            "iter  50 value 6255.256432\n",
            "iter  60 value 6165.968720\n",
            "iter  70 value 6091.664896\n",
            "iter  80 value 6018.223618\n",
            "iter  90 value 5972.767783\n",
            "iter 100 value 5932.359784\n",
            "final  value 5932.359784 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18078.158855 \n",
            "iter  10 value 8053.880368\n",
            "iter  20 value 6641.760523\n",
            "iter  30 value 6338.883859\n",
            "iter  40 value 6226.985611\n",
            "iter  50 value 6188.246023\n",
            "iter  60 value 6149.358341\n",
            "iter  70 value 6111.338955\n",
            "iter  80 value 6062.261730\n",
            "iter  90 value 6009.943322\n",
            "iter 100 value 5966.536550\n",
            "final  value 5966.536550 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15650.227780 \n",
            "iter  10 value 8073.826701\n",
            "iter  20 value 7616.236702\n",
            "iter  30 value 6632.178351\n",
            "iter  40 value 6306.778723\n",
            "iter  50 value 6191.653943\n",
            "iter  60 value 6128.492264\n",
            "iter  70 value 6065.111434\n",
            "iter  80 value 6020.115961\n",
            "iter  90 value 5994.967811\n",
            "iter 100 value 5958.598501\n",
            "final  value 5958.598501 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25194.577237 \n",
            "iter  10 value 8075.867656\n",
            "iter  20 value 6485.717858\n",
            "iter  30 value 6230.101751\n",
            "iter  40 value 6168.252073\n",
            "iter  50 value 6142.029934\n",
            "iter  60 value 6098.814697\n",
            "iter  70 value 6060.062213\n",
            "iter  80 value 6038.886140\n",
            "iter  90 value 6008.273839\n",
            "iter 100 value 5982.163442\n",
            "final  value 5982.163442 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17790.664966 \n",
            "iter  10 value 7697.878732\n",
            "iter  20 value 6658.903476\n",
            "iter  30 value 6449.213378\n",
            "iter  40 value 6282.648541\n",
            "iter  50 value 6196.464744\n",
            "iter  60 value 6168.007527\n",
            "iter  70 value 6145.520364\n",
            "iter  80 value 6109.620353\n",
            "iter  90 value 6057.016999\n",
            "iter 100 value 6021.274191\n",
            "final  value 6021.274191 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13190.673631 \n",
            "iter  10 value 7731.738436\n",
            "iter  20 value 7108.054705\n",
            "iter  30 value 6656.700541\n",
            "iter  40 value 6371.531401\n",
            "iter  50 value 6238.806414\n",
            "iter  60 value 6159.519480\n",
            "iter  70 value 6124.178579\n",
            "iter  80 value 6083.733148\n",
            "iter  90 value 6052.437919\n",
            "iter 100 value 6034.267871\n",
            "final  value 6034.267871 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 9998.652103 \n",
            "iter  10 value 6997.681622\n",
            "iter  20 value 6465.962121\n",
            "iter  30 value 6273.064426\n",
            "iter  40 value 6189.127349\n",
            "iter  50 value 6148.206687\n",
            "iter  60 value 6113.084399\n",
            "iter  70 value 6077.770490\n",
            "iter  80 value 6042.775612\n",
            "iter  90 value 5988.840481\n",
            "iter 100 value 5926.250228\n",
            "final  value 5926.250228 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17192.402446 \n",
            "iter  10 value 8155.206626\n",
            "iter  20 value 7206.566172\n",
            "iter  30 value 6544.874911\n",
            "iter  40 value 6383.473615\n",
            "iter  50 value 6259.148960\n",
            "iter  60 value 6150.667511\n",
            "iter  70 value 6076.669295\n",
            "iter  80 value 6032.059757\n",
            "iter  90 value 6002.003722\n",
            "iter 100 value 5975.990824\n",
            "final  value 5975.990824 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16089.708707 \n",
            "iter  10 value 8025.925722\n",
            "iter  20 value 7446.097793\n",
            "iter  30 value 7059.770695\n",
            "iter  40 value 6823.162581\n",
            "iter  50 value 6651.906928\n",
            "iter  60 value 6505.869520\n",
            "iter  70 value 6270.898720\n",
            "iter  80 value 6157.931960\n",
            "iter  90 value 6097.882210\n",
            "iter 100 value 6037.873100\n",
            "final  value 6037.873100 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17335.566941 \n",
            "iter  10 value 8151.550921\n",
            "iter  20 value 6910.556579\n",
            "iter  30 value 6489.214104\n",
            "iter  40 value 6387.404708\n",
            "iter  50 value 6320.433060\n",
            "iter  60 value 6258.032037\n",
            "iter  70 value 6217.420768\n",
            "iter  80 value 6183.149499\n",
            "iter  90 value 6165.647548\n",
            "iter 100 value 6157.631929\n",
            "final  value 6157.631929 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13228.451914 \n",
            "iter  10 value 8078.488338\n",
            "iter  20 value 6969.432466\n",
            "iter  30 value 6745.714983\n",
            "iter  40 value 6623.105661\n",
            "iter  50 value 6452.277374\n",
            "iter  60 value 6288.923111\n",
            "iter  70 value 6200.969317\n",
            "iter  80 value 6148.858909\n",
            "iter  90 value 6076.992903\n",
            "iter 100 value 6038.790709\n",
            "final  value 6038.790709 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16810.334409 \n",
            "iter  10 value 8134.709052\n",
            "iter  20 value 7720.026812\n",
            "iter  30 value 7209.328687\n",
            "iter  40 value 6709.400487\n",
            "iter  50 value 6400.397603\n",
            "iter  60 value 6245.692029\n",
            "iter  70 value 6177.385943\n",
            "iter  80 value 6120.484672\n",
            "iter  90 value 6073.615870\n",
            "iter 100 value 6043.000186\n",
            "final  value 6043.000186 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16608.081009 \n",
            "iter  10 value 7616.822948\n",
            "iter  20 value 7266.774148\n",
            "iter  30 value 6998.411464\n",
            "iter  40 value 6806.667926\n",
            "iter  50 value 6727.526481\n",
            "iter  60 value 6656.498678\n",
            "iter  70 value 6531.258433\n",
            "iter  80 value 6295.065961\n",
            "iter  90 value 6182.483427\n",
            "iter 100 value 6110.955972\n",
            "final  value 6110.955972 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11512.568689 \n",
            "iter  10 value 7512.832723\n",
            "iter  20 value 6957.485046\n",
            "iter  30 value 6497.022331\n",
            "iter  40 value 6358.672129\n",
            "iter  50 value 6245.262012\n",
            "iter  60 value 6173.236080\n",
            "iter  70 value 6132.324252\n",
            "iter  80 value 6083.705415\n",
            "iter  90 value 6055.373419\n",
            "iter 100 value 6036.643373\n",
            "final  value 6036.643373 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11464.137194 \n",
            "iter  10 value 7613.678075\n",
            "iter  20 value 7412.522304\n",
            "iter  30 value 7265.635994\n",
            "iter  40 value 7146.832245\n",
            "iter  50 value 6922.901553\n",
            "iter  60 value 6723.177502\n",
            "iter  70 value 6593.105018\n",
            "iter  80 value 6397.599626\n",
            "iter  90 value 6221.574570\n",
            "iter 100 value 6182.102280\n",
            "final  value 6182.102280 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12531.553977 \n",
            "iter  10 value 7903.819075\n",
            "iter  20 value 7462.283883\n",
            "iter  30 value 6824.274001\n",
            "iter  40 value 6566.065975\n",
            "iter  50 value 6334.069651\n",
            "iter  60 value 6250.595930\n",
            "iter  70 value 6215.431504\n",
            "iter  80 value 6191.899588\n",
            "iter  90 value 6161.812605\n",
            "iter 100 value 6139.142345\n",
            "final  value 6139.142345 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21139.055240 \n",
            "iter  10 value 8024.375171\n",
            "iter  20 value 7529.174503\n",
            "iter  30 value 6621.447636\n",
            "iter  40 value 6439.995762\n",
            "iter  50 value 6305.058121\n",
            "iter  60 value 6218.286741\n",
            "iter  70 value 6136.299810\n",
            "iter  80 value 6021.198128\n",
            "iter  90 value 5961.481931\n",
            "iter 100 value 5928.070470\n",
            "final  value 5928.070470 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12167.178349 \n",
            "iter  10 value 7149.072515\n",
            "iter  20 value 6646.160109\n",
            "iter  30 value 6507.794387\n",
            "iter  40 value 6398.918093\n",
            "iter  50 value 6255.800328\n",
            "iter  60 value 6173.140479\n",
            "iter  70 value 6115.589695\n",
            "iter  80 value 6084.721627\n",
            "iter  90 value 6061.720337\n",
            "iter 100 value 6040.068075\n",
            "final  value 6040.068075 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24290.540813 \n",
            "iter  10 value 8042.019702\n",
            "iter  20 value 6765.533024\n",
            "iter  30 value 6356.533617\n",
            "iter  40 value 6170.662202\n",
            "iter  50 value 6087.216760\n",
            "iter  60 value 6062.189904\n",
            "iter  70 value 6045.791541\n",
            "iter  80 value 6031.917353\n",
            "iter  90 value 6015.960527\n",
            "iter 100 value 5992.567495\n",
            "final  value 5992.567495 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13910.180272 \n",
            "iter  10 value 7666.815344\n",
            "iter  20 value 7171.460430\n",
            "iter  30 value 6742.950875\n",
            "iter  40 value 6475.764696\n",
            "iter  50 value 6275.293922\n",
            "iter  60 value 6149.807282\n",
            "iter  70 value 6082.763925\n",
            "iter  80 value 6037.905240\n",
            "iter  90 value 5992.366926\n",
            "iter 100 value 5949.798577\n",
            "final  value 5949.798577 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18030.661999 \n",
            "iter  10 value 8036.637303\n",
            "iter  20 value 7520.775409\n",
            "iter  30 value 6766.868486\n",
            "iter  40 value 6394.067755\n",
            "iter  50 value 6226.197626\n",
            "iter  60 value 6117.575083\n",
            "iter  70 value 6064.728042\n",
            "iter  80 value 6034.428322\n",
            "iter  90 value 6000.497533\n",
            "iter 100 value 5965.369117\n",
            "final  value 5965.369117 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13655.364634 \n",
            "iter  10 value 8020.896589\n",
            "iter  20 value 7231.904767\n",
            "iter  30 value 7043.310141\n",
            "iter  40 value 6784.756100\n",
            "iter  50 value 6469.337344\n",
            "iter  60 value 6248.004834\n",
            "iter  70 value 6148.214016\n",
            "iter  80 value 6105.619223\n",
            "iter  90 value 6051.589077\n",
            "iter 100 value 6007.420103\n",
            "final  value 6007.420103 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15108.243755 \n",
            "iter  10 value 8350.641197\n",
            "iter  20 value 7604.576950\n",
            "iter  30 value 6862.716088\n",
            "iter  40 value 6397.970494\n",
            "iter  50 value 6284.389987\n",
            "iter  60 value 6219.871576\n",
            "iter  70 value 6189.836644\n",
            "iter  80 value 6164.335396\n",
            "iter  90 value 6116.204396\n",
            "iter 100 value 6072.446891\n",
            "final  value 6072.446891 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13558.177840 \n",
            "iter  10 value 7549.942137\n",
            "iter  20 value 6834.589252\n",
            "iter  30 value 6565.135611\n",
            "iter  40 value 6385.548273\n",
            "iter  50 value 6225.313583\n",
            "iter  60 value 6164.919389\n",
            "iter  70 value 6127.763448\n",
            "iter  80 value 6099.098937\n",
            "iter  90 value 6064.657044\n",
            "iter 100 value 6038.623857\n",
            "final  value 6038.623857 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16507.523503 \n",
            "iter  10 value 8038.186423\n",
            "iter  20 value 7195.480635\n",
            "iter  30 value 6766.553497\n",
            "iter  40 value 6474.681766\n",
            "iter  50 value 6363.393160\n",
            "iter  60 value 6279.486108\n",
            "iter  70 value 6195.031217\n",
            "iter  80 value 6141.460965\n",
            "iter  90 value 6104.693594\n",
            "iter 100 value 6084.928552\n",
            "final  value 6084.928552 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 22971.235158 \n",
            "iter  10 value 8064.099873\n",
            "iter  20 value 7430.914317\n",
            "iter  30 value 7088.235818\n",
            "iter  40 value 6726.196670\n",
            "iter  50 value 6570.921035\n",
            "iter  60 value 6486.316622\n",
            "iter  70 value 6385.704719\n",
            "iter  80 value 6298.079649\n",
            "iter  90 value 6245.138909\n",
            "iter 100 value 6215.131647\n",
            "final  value 6215.131647 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15700.950124 \n",
            "iter  10 value 8124.471356\n",
            "iter  20 value 7756.146889\n",
            "iter  30 value 7150.317479\n",
            "iter  40 value 6706.099184\n",
            "iter  50 value 6357.340576\n",
            "iter  60 value 6130.003023\n",
            "iter  70 value 6005.522572\n",
            "iter  80 value 5936.828828\n",
            "iter  90 value 5888.354890\n",
            "iter 100 value 5855.167156\n",
            "final  value 5855.167156 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10562.466526 \n",
            "iter  10 value 7033.623003\n",
            "iter  20 value 6708.434486\n",
            "iter  30 value 6595.228770\n",
            "iter  40 value 6535.743568\n",
            "iter  50 value 6504.257261\n",
            "iter  60 value 6480.768600\n",
            "iter  70 value 6403.357607\n",
            "iter  80 value 6237.636668\n",
            "iter  90 value 6137.346351\n",
            "iter 100 value 6069.167066\n",
            "final  value 6069.167066 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10686.568066 \n",
            "iter  10 value 7436.310121\n",
            "iter  20 value 6730.028564\n",
            "iter  30 value 6565.597214\n",
            "iter  40 value 6450.061551\n",
            "iter  50 value 6328.645657\n",
            "iter  60 value 6273.922067\n",
            "iter  70 value 6247.717618\n",
            "iter  80 value 6213.212246\n",
            "iter  90 value 6164.348064\n",
            "iter 100 value 6121.777656\n",
            "final  value 6121.777656 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16186.025093 \n",
            "iter  10 value 8237.301710\n",
            "iter  20 value 7796.983572\n",
            "iter  30 value 7543.934416\n",
            "iter  40 value 7365.067412\n",
            "iter  50 value 6895.654402\n",
            "iter  60 value 6558.706431\n",
            "iter  70 value 6332.745604\n",
            "iter  80 value 6261.484655\n",
            "iter  90 value 6223.164698\n",
            "iter 100 value 6176.376034\n",
            "final  value 6176.376034 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16648.420337 \n",
            "iter  10 value 8135.487487\n",
            "iter  20 value 7282.725419\n",
            "iter  30 value 6856.821542\n",
            "iter  40 value 6549.097039\n",
            "iter  50 value 6390.394455\n",
            "iter  60 value 6292.941028\n",
            "iter  70 value 6257.801295\n",
            "iter  80 value 6236.865009\n",
            "iter  90 value 6220.938456\n",
            "iter 100 value 6196.108889\n",
            "final  value 6196.108889 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13901.723691 \n",
            "iter  10 value 7469.122604\n",
            "iter  20 value 6781.688950\n",
            "iter  30 value 6522.621250\n",
            "iter  40 value 6340.486893\n",
            "iter  50 value 6232.634943\n",
            "iter  60 value 6159.222189\n",
            "iter  70 value 6110.362065\n",
            "iter  80 value 6073.850110\n",
            "iter  90 value 6034.106289\n",
            "iter 100 value 6013.237694\n",
            "final  value 6013.237694 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16224.443315 \n",
            "iter  10 value 7616.399152\n",
            "iter  20 value 6837.879418\n",
            "iter  30 value 6633.496186\n",
            "iter  40 value 6501.071488\n",
            "iter  50 value 6409.702411\n",
            "iter  60 value 6329.266998\n",
            "iter  70 value 6278.375716\n",
            "iter  80 value 6230.092652\n",
            "iter  90 value 6176.302246\n",
            "iter 100 value 6105.443894\n",
            "final  value 6105.443894 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13141.919014 \n",
            "iter  10 value 7871.825462\n",
            "iter  20 value 7368.536619\n",
            "iter  30 value 6722.034048\n",
            "iter  40 value 6442.173235\n",
            "iter  50 value 6366.293524\n",
            "iter  60 value 6291.557864\n",
            "iter  70 value 6238.889111\n",
            "iter  80 value 6196.160082\n",
            "iter  90 value 6148.557448\n",
            "iter 100 value 6122.555749\n",
            "final  value 6122.555749 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12391.859071 \n",
            "iter  10 value 7864.447400\n",
            "iter  20 value 7230.038878\n",
            "iter  30 value 6730.275930\n",
            "iter  40 value 6438.506597\n",
            "iter  50 value 6295.361645\n",
            "iter  60 value 6239.286861\n",
            "iter  70 value 6198.915064\n",
            "iter  80 value 6168.495916\n",
            "iter  90 value 6141.929719\n",
            "iter 100 value 6120.688326\n",
            "final  value 6120.688326 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 22564.391548 \n",
            "iter  10 value 7853.767638\n",
            "iter  20 value 7458.530849\n",
            "iter  30 value 7197.926881\n",
            "iter  40 value 6868.161059\n",
            "iter  50 value 6641.532798\n",
            "iter  60 value 6445.838639\n",
            "iter  70 value 6321.299105\n",
            "iter  80 value 6264.382556\n",
            "iter  90 value 6218.482722\n",
            "iter 100 value 6190.706881\n",
            "final  value 6190.706881 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17537.187032 \n",
            "iter  10 value 7836.760076\n",
            "iter  20 value 7259.986864\n",
            "iter  30 value 6884.382023\n",
            "iter  40 value 6642.699246\n",
            "iter  50 value 6471.319974\n",
            "iter  60 value 6358.341722\n",
            "iter  70 value 6301.295939\n",
            "iter  80 value 6260.699530\n",
            "iter  90 value 6223.540116\n",
            "iter 100 value 6164.856051\n",
            "final  value 6164.856051 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15307.990451 \n",
            "iter  10 value 8298.959906\n",
            "iter  20 value 7349.218258\n",
            "iter  30 value 6854.033587\n",
            "iter  40 value 6600.849307\n",
            "iter  50 value 6447.971189\n",
            "iter  60 value 6347.584065\n",
            "iter  70 value 6266.734485\n",
            "iter  80 value 6204.693783\n",
            "iter  90 value 6168.290822\n",
            "iter 100 value 6133.743010\n",
            "final  value 6133.743010 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18365.543717 \n",
            "iter  10 value 8353.684295\n",
            "iter  20 value 7171.003395\n",
            "iter  30 value 6792.958898\n",
            "iter  40 value 6617.489216\n",
            "iter  50 value 6480.412957\n",
            "iter  60 value 6416.088682\n",
            "iter  70 value 6380.325935\n",
            "iter  80 value 6351.281711\n",
            "iter  90 value 6320.798518\n",
            "iter 100 value 6281.608394\n",
            "final  value 6281.608394 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14182.895679 \n",
            "iter  10 value 7727.136499\n",
            "iter  20 value 7397.298750\n",
            "iter  30 value 7168.766629\n",
            "iter  40 value 6936.630195\n",
            "iter  50 value 6780.900622\n",
            "iter  60 value 6546.913557\n",
            "iter  70 value 6425.096219\n",
            "iter  80 value 6329.278671\n",
            "iter  90 value 6279.554298\n",
            "iter 100 value 6240.385601\n",
            "final  value 6240.385601 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19915.833015 \n",
            "iter  10 value 8317.881834\n",
            "iter  20 value 7251.357074\n",
            "iter  30 value 6769.764691\n",
            "iter  40 value 6616.166160\n",
            "iter  50 value 6521.170099\n",
            "iter  60 value 6469.806511\n",
            "iter  70 value 6427.258022\n",
            "iter  80 value 6390.944597\n",
            "iter  90 value 6341.394048\n",
            "iter 100 value 6290.005357\n",
            "final  value 6290.005357 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12182.524301 \n",
            "iter  10 value 8320.442078\n",
            "iter  20 value 7727.567903\n",
            "iter  30 value 7117.815205\n",
            "iter  40 value 6833.307978\n",
            "iter  50 value 6663.706420\n",
            "iter  60 value 6539.892816\n",
            "iter  70 value 6492.104254\n",
            "iter  80 value 6416.299350\n",
            "iter  90 value 6359.485423\n",
            "iter 100 value 6310.702063\n",
            "final  value 6310.702063 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14902.931264 \n",
            "iter  10 value 8253.334547\n",
            "iter  20 value 7156.454061\n",
            "iter  30 value 6812.877050\n",
            "iter  40 value 6616.213327\n",
            "iter  50 value 6482.950198\n",
            "iter  60 value 6425.783074\n",
            "iter  70 value 6385.243670\n",
            "iter  80 value 6351.070792\n",
            "iter  90 value 6314.178121\n",
            "iter 100 value 6281.324990\n",
            "final  value 6281.324990 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13037.010839 \n",
            "iter  10 value 7968.660683\n",
            "iter  20 value 7526.317952\n",
            "iter  30 value 7177.032322\n",
            "iter  40 value 6888.534950\n",
            "iter  50 value 6664.959852\n",
            "iter  60 value 6554.440175\n",
            "iter  70 value 6454.829087\n",
            "iter  80 value 6403.526623\n",
            "iter  90 value 6369.137461\n",
            "iter 100 value 6335.448519\n",
            "final  value 6335.448519 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12013.669433 \n",
            "iter  10 value 7975.652558\n",
            "iter  20 value 7825.025991\n",
            "iter  30 value 7367.510309\n",
            "iter  40 value 6870.097900\n",
            "iter  50 value 6690.487981\n",
            "iter  60 value 6570.944552\n",
            "iter  70 value 6489.687640\n",
            "iter  80 value 6422.003333\n",
            "iter  90 value 6380.851822\n",
            "iter 100 value 6340.849880\n",
            "final  value 6340.849880 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25728.733616 \n",
            "iter  10 value 8312.897981\n",
            "iter  20 value 7542.541330\n",
            "iter  30 value 7133.851589\n",
            "iter  40 value 6908.525482\n",
            "iter  50 value 6815.087707\n",
            "iter  60 value 6772.273152\n",
            "iter  70 value 6735.480794\n",
            "iter  80 value 6700.271978\n",
            "iter  90 value 6659.957772\n",
            "iter 100 value 6565.939007\n",
            "final  value 6565.939007 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18614.015248 \n",
            "iter  10 value 8173.162687\n",
            "iter  20 value 7239.933454\n",
            "iter  30 value 6617.322362\n",
            "iter  40 value 6346.464212\n",
            "iter  50 value 6240.845320\n",
            "iter  60 value 6161.348819\n",
            "iter  70 value 6112.804124\n",
            "iter  80 value 6071.755011\n",
            "iter  90 value 6039.214806\n",
            "iter 100 value 6013.412370\n",
            "final  value 6013.412370 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21631.739661 \n",
            "iter  10 value 8081.810495\n",
            "iter  20 value 7650.406200\n",
            "iter  30 value 7404.671454\n",
            "iter  40 value 7040.308780\n",
            "iter  50 value 6687.634878\n",
            "iter  60 value 6424.796274\n",
            "iter  70 value 6244.950096\n",
            "iter  80 value 6144.112772\n",
            "iter  90 value 6099.618820\n",
            "iter 100 value 6060.940605\n",
            "final  value 6060.940605 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16826.273458 \n",
            "iter  10 value 7985.017817\n",
            "iter  20 value 7143.697695\n",
            "iter  30 value 6618.525458\n",
            "iter  40 value 6321.435716\n",
            "iter  50 value 6202.269064\n",
            "iter  60 value 6152.475087\n",
            "iter  70 value 6110.282828\n",
            "iter  80 value 6073.552662\n",
            "iter  90 value 6050.750997\n",
            "iter 100 value 6031.725267\n",
            "final  value 6031.725267 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13237.355758 \n",
            "iter  10 value 8187.739670\n",
            "iter  20 value 6941.817276\n",
            "iter  30 value 6538.928700\n",
            "iter  40 value 6336.871972\n",
            "iter  50 value 6248.297842\n",
            "iter  60 value 6206.576453\n",
            "iter  70 value 6165.941132\n",
            "iter  80 value 6136.504706\n",
            "iter  90 value 6082.522809\n",
            "iter 100 value 6044.584779\n",
            "final  value 6044.584779 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11143.163630 \n",
            "iter  10 value 7409.372215\n",
            "iter  20 value 6940.130727\n",
            "iter  30 value 6582.649814\n",
            "iter  40 value 6354.332186\n",
            "iter  50 value 6186.820694\n",
            "iter  60 value 6120.348417\n",
            "iter  70 value 6089.001750\n",
            "iter  80 value 6047.138222\n",
            "iter  90 value 6009.214121\n",
            "iter 100 value 5990.076325\n",
            "final  value 5990.076325 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16690.584946 \n",
            "iter  10 value 8128.615993\n",
            "iter  20 value 6926.943644\n",
            "iter  30 value 6614.587547\n",
            "iter  40 value 6444.440297\n",
            "iter  50 value 6288.051068\n",
            "iter  60 value 6202.395443\n",
            "iter  70 value 6135.469365\n",
            "iter  80 value 6088.458217\n",
            "iter  90 value 6052.398308\n",
            "iter 100 value 6026.279848\n",
            "final  value 6026.279848 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12616.844930 \n",
            "iter  10 value 7628.516238\n",
            "iter  20 value 7091.907809\n",
            "iter  30 value 6679.393684\n",
            "iter  40 value 6461.180271\n",
            "iter  50 value 6343.486638\n",
            "iter  60 value 6253.668093\n",
            "iter  70 value 6213.808873\n",
            "iter  80 value 6191.187293\n",
            "iter  90 value 6153.688445\n",
            "iter 100 value 6102.157353\n",
            "final  value 6102.157353 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21378.914073 \n",
            "iter  10 value 8540.005959\n",
            "iter  20 value 7973.120932\n",
            "iter  30 value 7425.531250\n",
            "iter  40 value 6900.886217\n",
            "iter  50 value 6512.619568\n",
            "iter  60 value 6297.349015\n",
            "iter  70 value 6216.320945\n",
            "iter  80 value 6177.768812\n",
            "iter  90 value 6143.664135\n",
            "iter 100 value 6106.570880\n",
            "final  value 6106.570880 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19134.403474 \n",
            "iter  10 value 8227.610106\n",
            "iter  20 value 7459.471012\n",
            "iter  30 value 6874.929624\n",
            "iter  40 value 6446.189880\n",
            "iter  50 value 6298.536121\n",
            "iter  60 value 6236.070530\n",
            "iter  70 value 6190.642565\n",
            "iter  80 value 6149.940922\n",
            "iter  90 value 6116.629057\n",
            "iter 100 value 6096.052375\n",
            "final  value 6096.052375 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14612.779352 \n",
            "iter  10 value 8082.271392\n",
            "iter  20 value 7773.214912\n",
            "iter  30 value 7510.015358\n",
            "iter  40 value 6930.685970\n",
            "iter  50 value 6616.575146\n",
            "iter  60 value 6491.007386\n",
            "iter  70 value 6438.723262\n",
            "iter  80 value 6387.015316\n",
            "iter  90 value 6277.336605\n",
            "iter 100 value 6224.138792\n",
            "final  value 6224.138792 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19023.720751 \n",
            "iter  10 value 7892.797433\n",
            "iter  20 value 7503.608512\n",
            "iter  30 value 7212.618074\n",
            "iter  40 value 7022.026374\n",
            "iter  50 value 6952.837933\n",
            "iter  60 value 6931.897628\n",
            "iter  70 value 6924.797351\n",
            "iter  80 value 6919.958119\n",
            "iter  90 value 6912.239702\n",
            "iter 100 value 6643.907433\n",
            "final  value 6643.907433 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25797.266929 \n",
            "iter  10 value 7734.922125\n",
            "iter  20 value 7136.375724\n",
            "iter  30 value 6786.931426\n",
            "iter  40 value 6491.309698\n",
            "iter  50 value 6345.189719\n",
            "iter  60 value 6215.319911\n",
            "iter  70 value 6111.315874\n",
            "iter  80 value 6033.341708\n",
            "iter  90 value 5998.989444\n",
            "iter 100 value 5973.767507\n",
            "final  value 5973.767507 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13473.004624 \n",
            "iter  10 value 8088.988269\n",
            "iter  20 value 6715.639042\n",
            "iter  30 value 6350.041709\n",
            "iter  40 value 6189.442893\n",
            "iter  50 value 6128.340971\n",
            "iter  60 value 6092.708330\n",
            "iter  70 value 6051.054574\n",
            "iter  80 value 6020.332555\n",
            "iter  90 value 5984.278648\n",
            "iter 100 value 5954.879006\n",
            "final  value 5954.879006 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13591.711365 \n",
            "iter  10 value 7548.391194\n",
            "iter  20 value 6869.412066\n",
            "iter  30 value 6674.439154\n",
            "iter  40 value 6448.232256\n",
            "iter  50 value 6321.138171\n",
            "iter  60 value 6271.055017\n",
            "iter  70 value 6210.922117\n",
            "iter  80 value 6146.608000\n",
            "iter  90 value 6104.889973\n",
            "iter 100 value 6041.425979\n",
            "final  value 6041.425979 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20206.939297 \n",
            "iter  10 value 8112.844301\n",
            "iter  20 value 7458.307765\n",
            "iter  30 value 7224.790214\n",
            "iter  40 value 6972.194693\n",
            "iter  50 value 6641.991970\n",
            "iter  60 value 6389.279571\n",
            "iter  70 value 6271.083227\n",
            "iter  80 value 6202.999440\n",
            "iter  90 value 6126.060474\n",
            "iter 100 value 6088.446997\n",
            "final  value 6088.446997 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11778.250309 \n",
            "iter  10 value 7735.237575\n",
            "iter  20 value 7277.095825\n",
            "iter  30 value 6641.047398\n",
            "iter  40 value 6361.345301\n",
            "iter  50 value 6257.083872\n",
            "iter  60 value 6204.747367\n",
            "iter  70 value 6159.015931\n",
            "iter  80 value 6114.922467\n",
            "iter  90 value 6087.584492\n",
            "iter 100 value 6059.191828\n",
            "final  value 6059.191828 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10710.796377 \n",
            "iter  10 value 7180.354232\n",
            "iter  20 value 6903.268966\n",
            "iter  30 value 6552.051342\n",
            "iter  40 value 6371.416852\n",
            "iter  50 value 6299.045032\n",
            "iter  60 value 6210.243947\n",
            "iter  70 value 6161.543744\n",
            "iter  80 value 6131.656325\n",
            "iter  90 value 6104.269417\n",
            "iter 100 value 6081.094544\n",
            "final  value 6081.094544 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24732.463233 \n",
            "iter  10 value 8214.696474\n",
            "iter  20 value 7503.680349\n",
            "iter  30 value 7165.415378\n",
            "iter  40 value 6786.316844\n",
            "iter  50 value 6570.336373\n",
            "iter  60 value 6501.157953\n",
            "iter  70 value 6456.395701\n",
            "iter  80 value 6314.400549\n",
            "iter  90 value 6208.814785\n",
            "iter 100 value 6157.820154\n",
            "final  value 6157.820154 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19820.377032 \n",
            "iter  10 value 8289.167204\n",
            "iter  20 value 6959.987603\n",
            "iter  30 value 6630.526739\n",
            "iter  40 value 6488.909091\n",
            "iter  50 value 6436.170889\n",
            "iter  60 value 6382.059473\n",
            "iter  70 value 6284.139359\n",
            "iter  80 value 6228.483671\n",
            "iter  90 value 6189.458119\n",
            "iter 100 value 6163.430077\n",
            "final  value 6163.430077 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21810.715807 \n",
            "iter  10 value 8355.498929\n",
            "iter  20 value 6876.502325\n",
            "iter  30 value 6553.950484\n",
            "iter  40 value 6467.058349\n",
            "iter  50 value 6420.411881\n",
            "iter  60 value 6394.457006\n",
            "iter  70 value 6365.786896\n",
            "iter  80 value 6347.432483\n",
            "iter  90 value 6319.042371\n",
            "iter 100 value 6271.737827\n",
            "final  value 6271.737827 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20132.282018 \n",
            "iter  10 value 8096.941761\n",
            "iter  20 value 7816.916761\n",
            "iter  30 value 7611.071182\n",
            "iter  40 value 7368.376377\n",
            "iter  50 value 7209.032858\n",
            "iter  60 value 7051.544995\n",
            "iter  70 value 6834.150150\n",
            "iter  80 value 6470.385452\n",
            "iter  90 value 6263.294238\n",
            "iter 100 value 6150.381483\n",
            "final  value 6150.381483 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17134.714461 \n",
            "iter  10 value 7723.105053\n",
            "iter  20 value 7263.251918\n",
            "iter  30 value 7094.850101\n",
            "iter  40 value 7052.712419\n",
            "iter  50 value 7042.718902\n",
            "iter  60 value 7037.906447\n",
            "iter  70 value 7031.049080\n",
            "iter  80 value 7021.658802\n",
            "iter  90 value 7016.452143\n",
            "iter 100 value 7011.615257\n",
            "final  value 7011.615257 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14153.559409 \n",
            "iter  10 value 8171.464950\n",
            "iter  20 value 7091.318045\n",
            "iter  30 value 6687.760717\n",
            "iter  40 value 6465.669368\n",
            "iter  50 value 6316.499577\n",
            "iter  60 value 6234.353141\n",
            "iter  70 value 6173.190786\n",
            "iter  80 value 6129.731182\n",
            "iter  90 value 6092.160249\n",
            "iter 100 value 6055.459529\n",
            "final  value 6055.459529 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 27533.696725 \n",
            "iter  10 value 7806.757392\n",
            "iter  20 value 6692.710490\n",
            "iter  30 value 6478.002734\n",
            "iter  40 value 6366.494200\n",
            "iter  50 value 6322.442966\n",
            "iter  60 value 6303.374779\n",
            "iter  70 value 6278.459494\n",
            "iter  80 value 6246.822768\n",
            "iter  90 value 6223.957424\n",
            "iter 100 value 6204.413873\n",
            "final  value 6204.413873 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12561.581107 \n",
            "iter  10 value 7836.137482\n",
            "iter  20 value 7125.902886\n",
            "iter  30 value 6778.091097\n",
            "iter  40 value 6591.410239\n",
            "iter  50 value 6468.983538\n",
            "iter  60 value 6408.940032\n",
            "iter  70 value 6361.617994\n",
            "iter  80 value 6331.455823\n",
            "iter  90 value 6309.175535\n",
            "iter 100 value 6274.797157\n",
            "final  value 6274.797157 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13035.451026 \n",
            "iter  10 value 7896.358842\n",
            "iter  20 value 7325.072928\n",
            "iter  30 value 6791.191643\n",
            "iter  40 value 6484.126992\n",
            "iter  50 value 6330.646885\n",
            "iter  60 value 6248.986622\n",
            "iter  70 value 6211.067846\n",
            "iter  80 value 6184.647249\n",
            "iter  90 value 6156.168843\n",
            "iter 100 value 6131.992395\n",
            "final  value 6131.992395 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13867.743725 \n",
            "iter  10 value 7577.191683\n",
            "iter  20 value 7201.887892\n",
            "iter  30 value 6845.577374\n",
            "iter  40 value 6564.870064\n",
            "iter  50 value 6433.650529\n",
            "iter  60 value 6335.449249\n",
            "iter  70 value 6274.956759\n",
            "iter  80 value 6224.935219\n",
            "iter  90 value 6195.797661\n",
            "iter 100 value 6172.800430\n",
            "final  value 6172.800430 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11373.852119 \n",
            "iter  10 value 7689.286468\n",
            "iter  20 value 7100.535268\n",
            "iter  30 value 6656.689606\n",
            "iter  40 value 6526.076313\n",
            "iter  50 value 6410.489553\n",
            "iter  60 value 6329.237340\n",
            "iter  70 value 6269.840987\n",
            "iter  80 value 6240.621880\n",
            "iter  90 value 6213.438580\n",
            "iter 100 value 6177.841637\n",
            "final  value 6177.841637 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14895.382954 \n",
            "iter  10 value 8174.763411\n",
            "iter  20 value 8097.168023\n",
            "iter  30 value 7957.696472\n",
            "iter  40 value 7912.829819\n",
            "iter  50 value 7902.378142\n",
            "iter  60 value 7894.161736\n",
            "iter  70 value 7880.242582\n",
            "iter  80 value 7703.225206\n",
            "iter  90 value 7181.474798\n",
            "iter 100 value 6856.133788\n",
            "final  value 6856.133788 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19571.756678 \n",
            "iter  10 value 8067.637497\n",
            "iter  20 value 6934.240770\n",
            "iter  30 value 6733.265576\n",
            "iter  40 value 6571.417602\n",
            "iter  50 value 6412.213327\n",
            "iter  60 value 6347.773944\n",
            "iter  70 value 6298.971141\n",
            "iter  80 value 6260.325083\n",
            "iter  90 value 6230.213924\n",
            "iter 100 value 6210.462987\n",
            "final  value 6210.462987 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14297.570981 \n",
            "iter  10 value 7725.957082\n",
            "iter  20 value 7190.532058\n",
            "iter  30 value 6792.967115\n",
            "iter  40 value 6476.682150\n",
            "iter  50 value 6266.052581\n",
            "iter  60 value 6158.184224\n",
            "iter  70 value 6111.999092\n",
            "iter  80 value 6073.712388\n",
            "iter  90 value 6046.698364\n",
            "iter 100 value 6032.614097\n",
            "final  value 6032.614097 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17957.658781 \n",
            "iter  10 value 7512.758338\n",
            "iter  20 value 6884.233010\n",
            "iter  30 value 6623.419085\n",
            "iter  40 value 6434.100928\n",
            "iter  50 value 6305.282692\n",
            "iter  60 value 6229.807762\n",
            "iter  70 value 6187.681177\n",
            "iter  80 value 6153.510099\n",
            "iter  90 value 6118.119671\n",
            "iter 100 value 6082.817361\n",
            "final  value 6082.817361 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11683.727736 \n",
            "iter  10 value 7606.898964\n",
            "iter  20 value 6904.602031\n",
            "iter  30 value 6521.912631\n",
            "iter  40 value 6350.822293\n",
            "iter  50 value 6273.871621\n",
            "iter  60 value 6237.211680\n",
            "iter  70 value 6218.508991\n",
            "iter  80 value 6196.426316\n",
            "iter  90 value 6149.563836\n",
            "iter 100 value 6086.616388\n",
            "final  value 6086.616388 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17257.077608 \n",
            "iter  10 value 8038.830082\n",
            "iter  20 value 6703.821366\n",
            "iter  30 value 6464.011548\n",
            "iter  40 value 6386.467536\n",
            "iter  50 value 6345.005062\n",
            "iter  60 value 6314.234273\n",
            "iter  70 value 6281.200101\n",
            "iter  80 value 6246.300778\n",
            "iter  90 value 6222.713220\n",
            "iter 100 value 6210.163500\n",
            "final  value 6210.163500 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23336.031476 \n",
            "iter  10 value 8143.749305\n",
            "iter  20 value 7005.774567\n",
            "iter  30 value 6501.638897\n",
            "iter  40 value 6393.058653\n",
            "iter  50 value 6309.925047\n",
            "iter  60 value 6259.314573\n",
            "iter  70 value 6208.631446\n",
            "iter  80 value 6163.419655\n",
            "iter  90 value 6121.435653\n",
            "iter 100 value 6090.240932\n",
            "final  value 6090.240932 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17445.971306 \n",
            "iter  10 value 7985.323979\n",
            "iter  20 value 6854.412215\n",
            "iter  30 value 6572.038038\n",
            "iter  40 value 6437.948356\n",
            "iter  50 value 6393.518635\n",
            "iter  60 value 6343.366069\n",
            "iter  70 value 6306.230210\n",
            "iter  80 value 6290.621056\n",
            "iter  90 value 6271.696116\n",
            "iter 100 value 6253.811249\n",
            "final  value 6253.811249 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18647.530701 \n",
            "iter  10 value 7928.492172\n",
            "iter  20 value 7507.793417\n",
            "iter  30 value 6976.511797\n",
            "iter  40 value 6672.053417\n",
            "iter  50 value 6514.486423\n",
            "iter  60 value 6413.197913\n",
            "iter  70 value 6329.834418\n",
            "iter  80 value 6284.784564\n",
            "iter  90 value 6254.518087\n",
            "iter 100 value 6238.859245\n",
            "final  value 6238.859245 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12778.138186 \n",
            "iter  10 value 7859.353972\n",
            "iter  20 value 7051.609857\n",
            "iter  30 value 6761.774200\n",
            "iter  40 value 6599.734156\n",
            "iter  50 value 6495.384745\n",
            "iter  60 value 6370.703787\n",
            "iter  70 value 6296.449763\n",
            "iter  80 value 6238.301711\n",
            "iter  90 value 6209.940536\n",
            "iter 100 value 6182.408408\n",
            "final  value 6182.408408 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12036.356078 \n",
            "iter  10 value 8010.483146\n",
            "iter  20 value 7126.527952\n",
            "iter  30 value 7012.894915\n",
            "iter  40 value 6862.867924\n",
            "iter  50 value 6767.007693\n",
            "iter  60 value 6707.703831\n",
            "iter  70 value 6657.022052\n",
            "iter  80 value 6462.545982\n",
            "iter  90 value 6333.803312\n",
            "iter 100 value 6296.589329\n",
            "final  value 6296.589329 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13795.347374 \n",
            "iter  10 value 8085.300124\n",
            "iter  20 value 6892.697718\n",
            "iter  30 value 6683.663410\n",
            "iter  40 value 6563.656561\n",
            "iter  50 value 6442.278599\n",
            "iter  60 value 6379.671065\n",
            "iter  70 value 6321.843891\n",
            "iter  80 value 6282.069597\n",
            "iter  90 value 6249.629671\n",
            "iter 100 value 6221.489618\n",
            "final  value 6221.489618 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11852.742308 \n",
            "iter  10 value 8021.527360\n",
            "iter  20 value 7488.727923\n",
            "iter  30 value 6912.291329\n",
            "iter  40 value 6430.798429\n",
            "iter  50 value 6251.117764\n",
            "iter  60 value 6150.817702\n",
            "iter  70 value 6086.748253\n",
            "iter  80 value 6047.285169\n",
            "iter  90 value 6007.712689\n",
            "iter 100 value 5979.551867\n",
            "final  value 5979.551867 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10612.129332 \n",
            "iter  10 value 6712.051036\n",
            "iter  20 value 6412.551878\n",
            "iter  30 value 6179.168785\n",
            "iter  40 value 6068.399374\n",
            "iter  50 value 6017.864686\n",
            "iter  60 value 5968.606032\n",
            "iter  70 value 5915.677698\n",
            "iter  80 value 5880.550519\n",
            "iter  90 value 5853.302097\n",
            "iter 100 value 5834.208069\n",
            "final  value 5834.208069 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11690.854441 \n",
            "iter  10 value 7686.360454\n",
            "iter  20 value 7016.067612\n",
            "iter  30 value 6551.061998\n",
            "iter  40 value 6270.019966\n",
            "iter  50 value 6163.402877\n",
            "iter  60 value 6120.729603\n",
            "iter  70 value 6101.379847\n",
            "iter  80 value 6077.462832\n",
            "iter  90 value 6043.702802\n",
            "iter 100 value 6018.924814\n",
            "final  value 6018.924814 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13135.012101 \n",
            "iter  10 value 7696.980846\n",
            "iter  20 value 6936.118507\n",
            "iter  30 value 6770.314974\n",
            "iter  40 value 6558.959154\n",
            "iter  50 value 6354.053944\n",
            "iter  60 value 6232.721083\n",
            "iter  70 value 6165.891863\n",
            "iter  80 value 6129.723243\n",
            "iter  90 value 6100.729147\n",
            "iter 100 value 6082.940716\n",
            "final  value 6082.940716 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21771.715349 \n",
            "iter  10 value 8051.293211\n",
            "iter  20 value 6658.796365\n",
            "iter  30 value 6374.112667\n",
            "iter  40 value 6264.353100\n",
            "iter  50 value 6171.115388\n",
            "iter  60 value 6133.989919\n",
            "iter  70 value 6075.705467\n",
            "iter  80 value 6037.050762\n",
            "iter  90 value 6014.558165\n",
            "iter 100 value 5985.236745\n",
            "final  value 5985.236745 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15601.536265 \n",
            "iter  10 value 7913.009663\n",
            "iter  20 value 6940.179089\n",
            "iter  30 value 6668.344290\n",
            "iter  40 value 6579.521788\n",
            "iter  50 value 6512.869562\n",
            "iter  60 value 6373.307968\n",
            "iter  70 value 6221.299714\n",
            "iter  80 value 6121.134984\n",
            "iter  90 value 6084.403066\n",
            "iter 100 value 6045.000026\n",
            "final  value 6045.000026 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20643.089979 \n",
            "iter  10 value 8030.711002\n",
            "iter  20 value 7727.077424\n",
            "iter  30 value 7219.243629\n",
            "iter  40 value 6829.073998\n",
            "iter  50 value 6531.717475\n",
            "iter  60 value 6355.811953\n",
            "iter  70 value 6238.768719\n",
            "iter  80 value 6158.353168\n",
            "iter  90 value 6104.709851\n",
            "iter 100 value 6073.295324\n",
            "final  value 6073.295324 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15832.292245 \n",
            "iter  10 value 8636.651524\n",
            "iter  20 value 7452.394537\n",
            "iter  30 value 6830.806932\n",
            "iter  40 value 6542.442104\n",
            "iter  50 value 6449.913212\n",
            "iter  60 value 6400.097226\n",
            "iter  70 value 6336.316680\n",
            "iter  80 value 6245.009746\n",
            "iter  90 value 6149.582365\n",
            "iter 100 value 6091.537202\n",
            "final  value 6091.537202 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17356.731825 \n",
            "iter  10 value 7772.556523\n",
            "iter  20 value 7275.301349\n",
            "iter  30 value 6853.860281\n",
            "iter  40 value 6567.647324\n",
            "iter  50 value 6383.897366\n",
            "iter  60 value 6268.840222\n",
            "iter  70 value 6212.853189\n",
            "iter  80 value 6172.851073\n",
            "iter  90 value 6131.009110\n",
            "iter 100 value 6101.483185\n",
            "final  value 6101.483185 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13402.048568 \n",
            "iter  10 value 7967.780472\n",
            "iter  20 value 6803.631752\n",
            "iter  30 value 6533.573055\n",
            "iter  40 value 6435.681923\n",
            "iter  50 value 6354.576862\n",
            "iter  60 value 6298.886485\n",
            "iter  70 value 6266.210190\n",
            "iter  80 value 6242.525919\n",
            "iter  90 value 6222.554307\n",
            "iter 100 value 6208.216292\n",
            "final  value 6208.216292 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13617.818311 \n",
            "iter  10 value 8140.421830\n",
            "iter  20 value 7383.848191\n",
            "iter  30 value 6636.228005\n",
            "iter  40 value 6302.083274\n",
            "iter  50 value 6144.676541\n",
            "iter  60 value 6074.901998\n",
            "iter  70 value 6049.727595\n",
            "iter  80 value 6026.608080\n",
            "iter  90 value 6002.147444\n",
            "iter 100 value 5966.718997\n",
            "final  value 5966.718997 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15617.058336 \n",
            "iter  10 value 8148.209336\n",
            "iter  20 value 7771.371748\n",
            "iter  30 value 7186.285589\n",
            "iter  40 value 6972.289718\n",
            "iter  50 value 6650.685014\n",
            "iter  60 value 6225.351467\n",
            "iter  70 value 6072.829856\n",
            "iter  80 value 5973.698846\n",
            "iter  90 value 5892.651076\n",
            "iter 100 value 5832.099658\n",
            "final  value 5832.099658 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13394.891115 \n",
            "iter  10 value 8151.096023\n",
            "iter  20 value 7106.948843\n",
            "iter  30 value 6560.599083\n",
            "iter  40 value 6286.407141\n",
            "iter  50 value 6119.156006\n",
            "iter  60 value 6051.873779\n",
            "iter  70 value 5998.783898\n",
            "iter  80 value 5934.264256\n",
            "iter  90 value 5888.318776\n",
            "iter 100 value 5853.638143\n",
            "final  value 5853.638143 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13182.495740 \n",
            "iter  10 value 8003.188997\n",
            "iter  20 value 6770.579289\n",
            "iter  30 value 6418.131501\n",
            "iter  40 value 6308.337494\n",
            "iter  50 value 6238.453300\n",
            "iter  60 value 6179.035341\n",
            "iter  70 value 6142.999881\n",
            "iter  80 value 6116.315958\n",
            "iter  90 value 6087.818939\n",
            "iter 100 value 6056.396895\n",
            "final  value 6056.396895 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14810.179406 \n",
            "iter  10 value 8150.280770\n",
            "iter  20 value 7530.635519\n",
            "iter  30 value 6822.048055\n",
            "iter  40 value 6572.059957\n",
            "iter  50 value 6445.381158\n",
            "iter  60 value 6348.124499\n",
            "iter  70 value 6235.313049\n",
            "iter  80 value 6131.418022\n",
            "iter  90 value 6071.132526\n",
            "iter 100 value 6026.945818\n",
            "final  value 6026.945818 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21835.956533 \n",
            "iter  10 value 8301.084382\n",
            "iter  20 value 7686.592608\n",
            "iter  30 value 7072.138790\n",
            "iter  40 value 6546.149795\n",
            "iter  50 value 6263.353347\n",
            "iter  60 value 6111.398338\n",
            "iter  70 value 6050.187227\n",
            "iter  80 value 6001.186059\n",
            "iter  90 value 5951.622855\n",
            "iter 100 value 5930.391282\n",
            "final  value 5930.391282 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16125.560745 \n",
            "iter  10 value 7954.985648\n",
            "iter  20 value 6693.846529\n",
            "iter  30 value 6476.712644\n",
            "iter  40 value 6322.586177\n",
            "iter  50 value 6256.806116\n",
            "iter  60 value 6220.178461\n",
            "iter  70 value 6202.328307\n",
            "iter  80 value 6188.639195\n",
            "iter  90 value 6168.639323\n",
            "iter 100 value 6126.886686\n",
            "final  value 6126.886686 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19451.765782 \n",
            "iter  10 value 8177.058456\n",
            "iter  20 value 7405.225743\n",
            "iter  30 value 7190.026806\n",
            "iter  40 value 7011.112761\n",
            "iter  50 value 6925.303190\n",
            "iter  60 value 6619.456392\n",
            "iter  70 value 6367.307897\n",
            "iter  80 value 6323.757050\n",
            "iter  90 value 6294.098574\n",
            "iter 100 value 6257.545398\n",
            "final  value 6257.545398 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15379.632878 \n",
            "iter  10 value 8164.282260\n",
            "iter  20 value 6779.713001\n",
            "iter  30 value 6438.163198\n",
            "iter  40 value 6330.233232\n",
            "iter  50 value 6246.666051\n",
            "iter  60 value 6165.383385\n",
            "iter  70 value 6128.091016\n",
            "iter  80 value 6095.547813\n",
            "iter  90 value 6073.334805\n",
            "iter 100 value 6052.022110\n",
            "final  value 6052.022110 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20164.671393 \n",
            "iter  10 value 8164.507252\n",
            "iter  20 value 6707.650951\n",
            "iter  30 value 6463.874785\n",
            "iter  40 value 6365.491134\n",
            "iter  50 value 6291.361606\n",
            "iter  60 value 6238.608192\n",
            "iter  70 value 6209.070022\n",
            "iter  80 value 6165.098497\n",
            "iter  90 value 6123.146407\n",
            "iter 100 value 6094.053245\n",
            "final  value 6094.053245 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14225.520727 \n",
            "iter  10 value 7628.350901\n",
            "iter  20 value 6778.688641\n",
            "iter  30 value 6519.965566\n",
            "iter  40 value 6406.135539\n",
            "iter  50 value 6325.019500\n",
            "iter  60 value 6243.952457\n",
            "iter  70 value 6133.849528\n",
            "iter  80 value 6054.779450\n",
            "iter  90 value 5988.103026\n",
            "iter 100 value 5935.033557\n",
            "final  value 5935.033557 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11989.639677 \n",
            "iter  10 value 7755.681311\n",
            "iter  20 value 7012.316439\n",
            "iter  30 value 6746.880497\n",
            "iter  40 value 6538.050673\n",
            "iter  50 value 6353.101794\n",
            "iter  60 value 6192.647342\n",
            "iter  70 value 6104.403009\n",
            "iter  80 value 6035.583712\n",
            "iter  90 value 5993.782143\n",
            "iter 100 value 5958.003894\n",
            "final  value 5958.003894 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14706.004648 \n",
            "iter  10 value 8182.788101\n",
            "iter  20 value 6652.653745\n",
            "iter  30 value 6431.781402\n",
            "iter  40 value 6299.215734\n",
            "iter  50 value 6195.499137\n",
            "iter  60 value 6115.005109\n",
            "iter  70 value 6070.503604\n",
            "iter  80 value 6035.262137\n",
            "iter  90 value 5999.197830\n",
            "iter 100 value 5978.861046\n",
            "final  value 5978.861046 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11107.800636 \n",
            "iter  10 value 6867.487961\n",
            "iter  20 value 6562.135718\n",
            "iter  30 value 6368.946229\n",
            "iter  40 value 6303.547624\n",
            "iter  50 value 6230.094881\n",
            "iter  60 value 6153.830730\n",
            "iter  70 value 6102.515750\n",
            "iter  80 value 6076.395065\n",
            "iter  90 value 6049.281923\n",
            "iter 100 value 6023.134152\n",
            "final  value 6023.134152 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17767.159660 \n",
            "iter  10 value 8220.312826\n",
            "iter  20 value 7014.612675\n",
            "iter  30 value 6645.646063\n",
            "iter  40 value 6471.681700\n",
            "iter  50 value 6359.192345\n",
            "iter  60 value 6300.747966\n",
            "iter  70 value 6280.811174\n",
            "iter  80 value 6270.605467\n",
            "iter  90 value 6261.587428\n",
            "iter 100 value 6223.661750\n",
            "final  value 6223.661750 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21086.339993 \n",
            "iter  10 value 8240.961180\n",
            "iter  20 value 6830.926611\n",
            "iter  30 value 6588.321022\n",
            "iter  40 value 6490.781898\n",
            "iter  50 value 6415.725574\n",
            "iter  60 value 6352.600352\n",
            "iter  70 value 6300.182603\n",
            "iter  80 value 6256.522469\n",
            "iter  90 value 6199.582140\n",
            "iter 100 value 6147.927578\n",
            "final  value 6147.927578 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25791.447039 \n",
            "iter  10 value 8214.125409\n",
            "iter  20 value 7501.778317\n",
            "iter  30 value 6978.336485\n",
            "iter  40 value 6603.991068\n",
            "iter  50 value 6501.844824\n",
            "iter  60 value 6450.198116\n",
            "iter  70 value 6430.642391\n",
            "iter  80 value 6405.642793\n",
            "iter  90 value 6362.619459\n",
            "iter 100 value 6345.601885\n",
            "final  value 6345.601885 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21130.725793 \n",
            "iter  10 value 8120.766497\n",
            "iter  20 value 7584.228316\n",
            "iter  30 value 6984.112705\n",
            "iter  40 value 6605.853764\n",
            "iter  50 value 6527.061153\n",
            "iter  60 value 6485.880379\n",
            "iter  70 value 6433.242711\n",
            "iter  80 value 6386.545135\n",
            "iter  90 value 6365.390104\n",
            "iter 100 value 6341.787113\n",
            "final  value 6341.787113 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19791.727777 \n",
            "iter  10 value 8062.195841\n",
            "iter  20 value 7438.452672\n",
            "iter  30 value 7067.286136\n",
            "iter  40 value 6715.639479\n",
            "iter  50 value 6565.762899\n",
            "iter  60 value 6436.591389\n",
            "iter  70 value 6344.919209\n",
            "iter  80 value 6283.655847\n",
            "iter  90 value 6250.468060\n",
            "iter 100 value 6222.492760\n",
            "final  value 6222.492760 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14099.680864 \n",
            "iter  10 value 8143.380414\n",
            "iter  20 value 6994.333837\n",
            "iter  30 value 6751.709126\n",
            "iter  40 value 6614.424006\n",
            "iter  50 value 6517.773141\n",
            "iter  60 value 6465.205707\n",
            "iter  70 value 6430.616980\n",
            "iter  80 value 6408.859323\n",
            "iter  90 value 6381.449048\n",
            "iter 100 value 6351.211924\n",
            "final  value 6351.211924 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14911.582993 \n",
            "iter  10 value 8257.140011\n",
            "iter  20 value 7963.996546\n",
            "iter  30 value 6848.192811\n",
            "iter  40 value 6570.852908\n",
            "iter  50 value 6485.865298\n",
            "iter  60 value 6407.865583\n",
            "iter  70 value 6359.531188\n",
            "iter  80 value 6322.081467\n",
            "iter  90 value 6291.193284\n",
            "iter 100 value 6259.089286\n",
            "final  value 6259.089286 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24397.771953 \n",
            "iter  10 value 8265.781407\n",
            "iter  20 value 7184.331785\n",
            "iter  30 value 6702.432169\n",
            "iter  40 value 6478.438449\n",
            "iter  50 value 6344.111068\n",
            "iter  60 value 6264.154049\n",
            "iter  70 value 6210.726689\n",
            "iter  80 value 6176.701155\n",
            "iter  90 value 6131.290210\n",
            "iter 100 value 6098.533468\n",
            "final  value 6098.533468 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17637.017227 \n",
            "iter  10 value 8271.233855\n",
            "iter  20 value 6986.886000\n",
            "iter  30 value 6693.551219\n",
            "iter  40 value 6516.499773\n",
            "iter  50 value 6457.093469\n",
            "iter  60 value 6427.895411\n",
            "iter  70 value 6398.844776\n",
            "iter  80 value 6384.857481\n",
            "iter  90 value 6377.754162\n",
            "iter 100 value 6366.155483\n",
            "final  value 6366.155483 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19117.424390 \n",
            "iter  10 value 8263.865148\n",
            "iter  20 value 7334.754944\n",
            "iter  30 value 6902.792065\n",
            "iter  40 value 6694.809967\n",
            "iter  50 value 6534.545617\n",
            "iter  60 value 6466.250089\n",
            "iter  70 value 6407.513096\n",
            "iter  80 value 6354.918264\n",
            "iter  90 value 6320.009819\n",
            "iter 100 value 6279.997607\n",
            "final  value 6279.997607 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11187.582267 \n",
            "iter  10 value 7386.365523\n",
            "iter  20 value 6866.207997\n",
            "iter  30 value 6666.623597\n",
            "iter  40 value 6523.496031\n",
            "iter  50 value 6437.194130\n",
            "iter  60 value 6384.873147\n",
            "iter  70 value 6352.399517\n",
            "iter  80 value 6306.030515\n",
            "iter  90 value 6271.151580\n",
            "iter 100 value 6238.725519\n",
            "final  value 6238.725519 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13057.412563 \n",
            "iter  10 value 8058.480992\n",
            "iter  20 value 7020.002850\n",
            "iter  30 value 6832.640145\n",
            "iter  40 value 6674.157451\n",
            "iter  50 value 6500.674104\n",
            "iter  60 value 6437.527091\n",
            "iter  70 value 6381.048168\n",
            "iter  80 value 6322.647705\n",
            "iter  90 value 6267.285906\n",
            "iter 100 value 6239.545862\n",
            "final  value 6239.545862 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14416.186127 \n",
            "iter  10 value 8210.229716\n",
            "iter  20 value 7213.566313\n",
            "iter  30 value 7058.038212\n",
            "iter  40 value 6981.643788\n",
            "iter  50 value 6862.066153\n",
            "iter  60 value 6661.428927\n",
            "iter  70 value 6574.456345\n",
            "iter  80 value 6485.493011\n",
            "iter  90 value 6408.905867\n",
            "iter 100 value 6362.143903\n",
            "final  value 6362.143903 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18549.739220 \n",
            "iter  10 value 8202.992323\n",
            "iter  20 value 7010.255549\n",
            "iter  30 value 6716.881956\n",
            "iter  40 value 6575.992087\n",
            "iter  50 value 6518.193184\n",
            "iter  60 value 6462.375466\n",
            "iter  70 value 6429.365497\n",
            "iter  80 value 6403.228416\n",
            "iter  90 value 6381.698470\n",
            "iter 100 value 6362.218670\n",
            "final  value 6362.218670 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20313.360856 \n",
            "iter  10 value 7970.092260\n",
            "iter  20 value 7421.442791\n",
            "iter  30 value 7143.604298\n",
            "iter  40 value 6846.067954\n",
            "iter  50 value 6704.659059\n",
            "iter  60 value 6637.193848\n",
            "iter  70 value 6577.793368\n",
            "iter  80 value 6546.767398\n",
            "iter  90 value 6517.193554\n",
            "iter 100 value 6499.475736\n",
            "final  value 6499.475736 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20717.613675 \n",
            "iter  10 value 8343.399840\n",
            "iter  20 value 7734.631418\n",
            "iter  30 value 7346.884411\n",
            "iter  40 value 7039.771561\n",
            "iter  50 value 6883.954685\n",
            "iter  60 value 6730.678127\n",
            "iter  70 value 6608.599313\n",
            "iter  80 value 6511.222748\n",
            "iter  90 value 6449.969825\n",
            "iter 100 value 6412.439386\n",
            "final  value 6412.439386 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19251.238839 \n",
            "iter  10 value 7884.259296\n",
            "iter  20 value 7286.557041\n",
            "iter  30 value 6711.065845\n",
            "iter  40 value 6295.104800\n",
            "iter  50 value 6058.404370\n",
            "iter  60 value 5952.020185\n",
            "iter  70 value 5872.967664\n",
            "iter  80 value 5833.234534\n",
            "iter  90 value 5811.930965\n",
            "iter 100 value 5792.156910\n",
            "final  value 5792.156910 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15628.592439 \n",
            "iter  10 value 7983.137619\n",
            "iter  20 value 7555.327781\n",
            "iter  30 value 7028.194304\n",
            "iter  40 value 6628.537284\n",
            "iter  50 value 6330.136969\n",
            "iter  60 value 6219.771661\n",
            "iter  70 value 6101.301099\n",
            "iter  80 value 5938.817164\n",
            "iter  90 value 5823.341900\n",
            "iter 100 value 5764.504606\n",
            "final  value 5764.504606 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18864.809102 \n",
            "iter  10 value 8363.725664\n",
            "iter  20 value 7741.687060\n",
            "iter  30 value 7252.793548\n",
            "iter  40 value 6872.574621\n",
            "iter  50 value 6582.731515\n",
            "iter  60 value 6265.928408\n",
            "iter  70 value 5999.751754\n",
            "iter  80 value 5910.432174\n",
            "iter  90 value 5884.085059\n",
            "iter 100 value 5871.112611\n",
            "final  value 5871.112611 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17672.089805 \n",
            "iter  10 value 7945.432709\n",
            "iter  20 value 7350.832315\n",
            "iter  30 value 6589.861474\n",
            "iter  40 value 6196.539625\n",
            "iter  50 value 6011.665428\n",
            "iter  60 value 5942.621118\n",
            "iter  70 value 5910.524255\n",
            "iter  80 value 5887.747303\n",
            "iter  90 value 5848.100545\n",
            "iter 100 value 5821.752182\n",
            "final  value 5821.752182 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17859.986408 \n",
            "iter  10 value 8376.957334\n",
            "iter  20 value 7584.680375\n",
            "iter  30 value 7016.590366\n",
            "iter  40 value 6484.937014\n",
            "iter  50 value 6086.159602\n",
            "iter  60 value 5960.757103\n",
            "iter  70 value 5899.360684\n",
            "iter  80 value 5857.625756\n",
            "iter  90 value 5820.242618\n",
            "iter 100 value 5793.685492\n",
            "final  value 5793.685492 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15874.680483 \n",
            "iter  10 value 8070.070498\n",
            "iter  20 value 7227.260216\n",
            "iter  30 value 6897.554185\n",
            "iter  40 value 6440.890342\n",
            "iter  50 value 6255.720316\n",
            "iter  60 value 6154.870559\n",
            "iter  70 value 6100.416260\n",
            "iter  80 value 6072.646645\n",
            "iter  90 value 6051.510573\n",
            "iter 100 value 5997.094427\n",
            "final  value 5997.094427 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18153.995725 \n",
            "iter  10 value 7915.228327\n",
            "iter  20 value 6380.288747\n",
            "iter  30 value 6172.942151\n",
            "iter  40 value 6099.147212\n",
            "iter  50 value 6069.447112\n",
            "iter  60 value 6056.314949\n",
            "iter  70 value 6035.619149\n",
            "iter  80 value 6019.084620\n",
            "iter  90 value 6011.002895\n",
            "iter 100 value 5994.664254\n",
            "final  value 5994.664254 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18821.561909 \n",
            "iter  10 value 7868.705003\n",
            "iter  20 value 7019.424495\n",
            "iter  30 value 6631.071029\n",
            "iter  40 value 6356.592413\n",
            "iter  50 value 6189.325173\n",
            "iter  60 value 6089.275145\n",
            "iter  70 value 6047.117834\n",
            "iter  80 value 6030.742475\n",
            "iter  90 value 6016.091544\n",
            "iter 100 value 5997.728647\n",
            "final  value 5997.728647 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11019.998956 \n",
            "iter  10 value 7144.785843\n",
            "iter  20 value 6746.541810\n",
            "iter  30 value 6366.650015\n",
            "iter  40 value 6128.525307\n",
            "iter  50 value 6040.293517\n",
            "iter  60 value 5985.918225\n",
            "iter  70 value 5941.058186\n",
            "iter  80 value 5911.726189\n",
            "iter  90 value 5880.072333\n",
            "iter 100 value 5862.830649\n",
            "final  value 5862.830649 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13812.757523 \n",
            "iter  10 value 8034.637037\n",
            "iter  20 value 6636.694359\n",
            "iter  30 value 6348.379859\n",
            "iter  40 value 6156.035804\n",
            "iter  50 value 6046.894318\n",
            "iter  60 value 6006.541757\n",
            "iter  70 value 5977.755211\n",
            "iter  80 value 5952.107801\n",
            "iter  90 value 5935.935911\n",
            "iter 100 value 5914.055226\n",
            "final  value 5914.055226 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19739.042680 \n",
            "iter  10 value 7949.861700\n",
            "iter  20 value 7825.748580\n",
            "iter  30 value 6560.865293\n",
            "iter  40 value 6262.703635\n",
            "iter  50 value 5968.334707\n",
            "iter  60 value 5902.023619\n",
            "iter  70 value 5872.137819\n",
            "iter  80 value 5853.495990\n",
            "iter  90 value 5828.727117\n",
            "iter 100 value 5799.509567\n",
            "final  value 5799.509567 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11103.333314 \n",
            "iter  10 value 7779.648166\n",
            "iter  20 value 7280.728877\n",
            "iter  30 value 6933.804358\n",
            "iter  40 value 6603.897194\n",
            "iter  50 value 6329.328492\n",
            "iter  60 value 6141.678504\n",
            "iter  70 value 6066.821907\n",
            "iter  80 value 6008.303985\n",
            "iter  90 value 5952.328582\n",
            "iter 100 value 5904.868516\n",
            "final  value 5904.868516 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23324.098323 \n",
            "iter  10 value 7958.450993\n",
            "iter  20 value 6983.382451\n",
            "iter  30 value 6491.559326\n",
            "iter  40 value 6241.460165\n",
            "iter  50 value 6139.777689\n",
            "iter  60 value 6066.652733\n",
            "iter  70 value 6010.835680\n",
            "iter  80 value 5958.435421\n",
            "iter  90 value 5910.020664\n",
            "iter 100 value 5853.333112\n",
            "final  value 5853.333112 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25599.789250 \n",
            "iter  10 value 7957.885732\n",
            "iter  20 value 6738.608682\n",
            "iter  30 value 6332.457073\n",
            "iter  40 value 6206.251098\n",
            "iter  50 value 6158.261192\n",
            "iter  60 value 6130.680514\n",
            "iter  70 value 6109.237725\n",
            "iter  80 value 6090.494082\n",
            "iter  90 value 6070.757179\n",
            "iter 100 value 6057.127226\n",
            "final  value 6057.127226 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19877.044942 \n",
            "iter  10 value 7940.118235\n",
            "iter  20 value 6516.418103\n",
            "iter  30 value 6302.879368\n",
            "iter  40 value 6212.086209\n",
            "iter  50 value 6173.903946\n",
            "iter  60 value 6155.027037\n",
            "iter  70 value 6131.010433\n",
            "iter  80 value 6111.708359\n",
            "iter  90 value 6098.998866\n",
            "iter 100 value 6091.379818\n",
            "final  value 6091.379818 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16939.023774 \n",
            "iter  10 value 7805.076896\n",
            "iter  20 value 6521.419487\n",
            "iter  30 value 6343.985217\n",
            "iter  40 value 6248.185587\n",
            "iter  50 value 6218.721544\n",
            "iter  60 value 6198.829943\n",
            "iter  70 value 6175.581703\n",
            "iter  80 value 6160.348490\n",
            "iter  90 value 6149.103307\n",
            "iter 100 value 6138.472309\n",
            "final  value 6138.472309 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 9339.051417 \n",
            "iter  10 value 7216.550323\n",
            "iter  20 value 6612.058084\n",
            "iter  30 value 6387.500353\n",
            "iter  40 value 6230.788443\n",
            "iter  50 value 6134.638144\n",
            "iter  60 value 6059.381633\n",
            "iter  70 value 6007.381468\n",
            "iter  80 value 5969.705718\n",
            "iter  90 value 5944.021161\n",
            "iter 100 value 5925.264208\n",
            "final  value 5925.264208 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16241.884566 \n",
            "iter  10 value 7938.056895\n",
            "iter  20 value 7869.705050\n",
            "iter  30 value 7667.189795\n",
            "iter  40 value 7576.828021\n",
            "iter  50 value 7506.359756\n",
            "iter  60 value 6593.340667\n",
            "iter  70 value 6324.182213\n",
            "iter  80 value 6207.902625\n",
            "iter  90 value 6172.201259\n",
            "iter 100 value 6154.186952\n",
            "final  value 6154.186952 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23295.173059 \n",
            "iter  10 value 7961.840945\n",
            "iter  20 value 7430.883530\n",
            "iter  30 value 7084.716614\n",
            "iter  40 value 6729.206050\n",
            "iter  50 value 6525.121756\n",
            "iter  60 value 6390.729263\n",
            "iter  70 value 6321.060523\n",
            "iter  80 value 6243.705733\n",
            "iter  90 value 6192.935376\n",
            "iter 100 value 6159.232413\n",
            "final  value 6159.232413 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18330.742593 \n",
            "iter  10 value 8417.683700\n",
            "iter  20 value 7296.844805\n",
            "iter  30 value 6668.122457\n",
            "iter  40 value 6398.110516\n",
            "iter  50 value 6296.646358\n",
            "iter  60 value 6235.280864\n",
            "iter  70 value 6154.257917\n",
            "iter  80 value 6098.104491\n",
            "iter  90 value 6056.895052\n",
            "iter 100 value 6024.216819\n",
            "final  value 6024.216819 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21700.994600 \n",
            "iter  10 value 7964.482737\n",
            "iter  20 value 7886.668249\n",
            "iter  30 value 7730.814021\n",
            "iter  40 value 7443.355850\n",
            "iter  50 value 7292.878250\n",
            "iter  60 value 7232.442599\n",
            "iter  70 value 7167.997003\n",
            "iter  80 value 7084.136831\n",
            "iter  90 value 6908.926682\n",
            "iter 100 value 6289.320502\n",
            "final  value 6289.320502 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14447.511504 \n",
            "iter  10 value 7977.258829\n",
            "iter  20 value 6921.343350\n",
            "iter  30 value 6463.893676\n",
            "iter  40 value 6251.122624\n",
            "iter  50 value 6141.525450\n",
            "iter  60 value 6026.574837\n",
            "iter  70 value 5956.238076\n",
            "iter  80 value 5895.765215\n",
            "iter  90 value 5864.506126\n",
            "iter 100 value 5836.116882\n",
            "final  value 5836.116882 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16144.926071 \n",
            "iter  10 value 7937.386365\n",
            "iter  20 value 7512.835568\n",
            "iter  30 value 6785.887264\n",
            "iter  40 value 6399.739444\n",
            "iter  50 value 6227.256359\n",
            "iter  60 value 6128.750592\n",
            "iter  70 value 6033.218581\n",
            "iter  80 value 5973.316534\n",
            "iter  90 value 5940.110428\n",
            "iter 100 value 5915.598837\n",
            "final  value 5915.598837 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13296.938571 \n",
            "iter  10 value 7908.192339\n",
            "iter  20 value 6496.676735\n",
            "iter  30 value 6273.622143\n",
            "iter  40 value 6193.934928\n",
            "iter  50 value 6099.118154\n",
            "iter  60 value 6008.874358\n",
            "iter  70 value 5962.500113\n",
            "iter  80 value 5931.639379\n",
            "iter  90 value 5891.426076\n",
            "iter 100 value 5846.043278\n",
            "final  value 5846.043278 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13341.928102 \n",
            "iter  10 value 7529.675290\n",
            "iter  20 value 7087.858635\n",
            "iter  30 value 6631.827739\n",
            "iter  40 value 6419.617287\n",
            "iter  50 value 6325.773950\n",
            "iter  60 value 6277.620192\n",
            "iter  70 value 6237.205765\n",
            "iter  80 value 6181.427899\n",
            "iter  90 value 6107.438749\n",
            "iter 100 value 6022.649522\n",
            "final  value 6022.649522 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16849.687054 \n",
            "iter  10 value 7915.699690\n",
            "iter  20 value 6469.144048\n",
            "iter  30 value 6268.981781\n",
            "iter  40 value 6158.592124\n",
            "iter  50 value 6056.133647\n",
            "iter  60 value 5991.231121\n",
            "iter  70 value 5945.103828\n",
            "iter  80 value 5913.728892\n",
            "iter  90 value 5891.527751\n",
            "iter 100 value 5867.927240\n",
            "final  value 5867.927240 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21197.105465 \n",
            "iter  10 value 8125.725571\n",
            "iter  20 value 7386.215356\n",
            "iter  30 value 6852.244857\n",
            "iter  40 value 6642.078834\n",
            "iter  50 value 6364.111172\n",
            "iter  60 value 6203.518054\n",
            "iter  70 value 6119.508104\n",
            "iter  80 value 6053.047217\n",
            "iter  90 value 6022.563707\n",
            "iter 100 value 5995.752117\n",
            "final  value 5995.752117 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16482.618482 \n",
            "iter  10 value 7320.583882\n",
            "iter  20 value 6679.753969\n",
            "iter  30 value 6370.021891\n",
            "iter  40 value 6238.777492\n",
            "iter  50 value 6156.396321\n",
            "iter  60 value 6060.359674\n",
            "iter  70 value 5994.217489\n",
            "iter  80 value 5963.547506\n",
            "iter  90 value 5940.005563\n",
            "iter 100 value 5911.292971\n",
            "final  value 5911.292971 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 9508.543537 \n",
            "iter  10 value 7083.015989\n",
            "iter  20 value 6510.434585\n",
            "iter  30 value 6293.846346\n",
            "iter  40 value 6179.035460\n",
            "iter  50 value 6083.502324\n",
            "iter  60 value 6028.206258\n",
            "iter  70 value 5994.898695\n",
            "iter  80 value 5972.237439\n",
            "iter  90 value 5945.500601\n",
            "iter 100 value 5926.601280\n",
            "final  value 5926.601280 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19704.251083 \n",
            "iter  10 value 8022.611017\n",
            "iter  20 value 7645.438119\n",
            "iter  30 value 7282.084801\n",
            "iter  40 value 6498.541866\n",
            "iter  50 value 6209.237824\n",
            "iter  60 value 6108.701547\n",
            "iter  70 value 6063.501300\n",
            "iter  80 value 6024.799631\n",
            "iter  90 value 5993.295003\n",
            "iter 100 value 5972.226914\n",
            "final  value 5972.226914 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 9760.018244 \n",
            "iter  10 value 6920.847623\n",
            "iter  20 value 6435.915979\n",
            "iter  30 value 6223.808243\n",
            "iter  40 value 6131.028789\n",
            "iter  50 value 6051.304008\n",
            "iter  60 value 5997.229980\n",
            "iter  70 value 5944.624259\n",
            "iter  80 value 5899.107209\n",
            "iter  90 value 5874.675527\n",
            "iter 100 value 5863.123683\n",
            "final  value 5863.123683 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24349.753103 \n",
            "iter  10 value 8017.171487\n",
            "iter  20 value 6584.031104\n",
            "iter  30 value 6247.803928\n",
            "iter  40 value 6097.281133\n",
            "iter  50 value 6002.555384\n",
            "iter  60 value 5949.828147\n",
            "iter  70 value 5926.031178\n",
            "iter  80 value 5904.422052\n",
            "iter  90 value 5886.290053\n",
            "iter 100 value 5874.116515\n",
            "final  value 5874.116515 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14365.381219 \n",
            "iter  10 value 8018.812876\n",
            "iter  20 value 7116.432080\n",
            "iter  30 value 6744.382145\n",
            "iter  40 value 6563.603730\n",
            "iter  50 value 6427.188892\n",
            "iter  60 value 6344.707602\n",
            "iter  70 value 6295.249533\n",
            "iter  80 value 6261.569255\n",
            "iter  90 value 6159.845369\n",
            "iter 100 value 6063.457741\n",
            "final  value 6063.457741 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14056.653824 \n",
            "iter  10 value 7506.485078\n",
            "iter  20 value 6983.485631\n",
            "iter  30 value 6590.162792\n",
            "iter  40 value 6312.370248\n",
            "iter  50 value 6181.815257\n",
            "iter  60 value 6115.157123\n",
            "iter  70 value 6079.543755\n",
            "iter  80 value 6063.011938\n",
            "iter  90 value 6054.405455\n",
            "iter 100 value 6045.891061\n",
            "final  value 6045.891061 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20782.899413 \n",
            "iter  10 value 8132.792767\n",
            "iter  20 value 7999.655245\n",
            "iter  30 value 7610.008490\n",
            "iter  40 value 6875.131259\n",
            "iter  50 value 6352.022552\n",
            "iter  60 value 6210.113130\n",
            "iter  70 value 6145.177687\n",
            "iter  80 value 6116.109924\n",
            "iter  90 value 6074.461212\n",
            "iter 100 value 6029.852773\n",
            "final  value 6029.852773 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15715.350165 \n",
            "iter  10 value 7856.272377\n",
            "iter  20 value 7409.469686\n",
            "iter  30 value 7075.633562\n",
            "iter  40 value 6996.702874\n",
            "iter  50 value 6932.561002\n",
            "iter  60 value 6562.737544\n",
            "iter  70 value 6376.396350\n",
            "iter  80 value 6247.192997\n",
            "iter  90 value 6155.650047\n",
            "iter 100 value 6092.530847\n",
            "final  value 6092.530847 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17245.220887 \n",
            "iter  10 value 8059.508004\n",
            "iter  20 value 7494.741718\n",
            "iter  30 value 6842.279650\n",
            "iter  40 value 6527.803819\n",
            "iter  50 value 6452.804442\n",
            "iter  60 value 6428.759827\n",
            "iter  70 value 6413.108539\n",
            "iter  80 value 6377.007532\n",
            "iter  90 value 6216.378200\n",
            "iter 100 value 6136.557018\n",
            "final  value 6136.557018 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 25490.861684 \n",
            "iter  10 value 8019.613676\n",
            "iter  20 value 7434.935602\n",
            "iter  30 value 6961.536625\n",
            "iter  40 value 6610.670745\n",
            "iter  50 value 6415.631518\n",
            "iter  60 value 6294.655247\n",
            "iter  70 value 6194.563108\n",
            "iter  80 value 6122.902731\n",
            "iter  90 value 6070.827046\n",
            "iter 100 value 6040.428577\n",
            "final  value 6040.428577 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11899.159967 \n",
            "iter  10 value 7326.836529\n",
            "iter  20 value 6746.223819\n",
            "iter  30 value 6444.865491\n",
            "iter  40 value 6251.851026\n",
            "iter  50 value 6151.513584\n",
            "iter  60 value 6109.524793\n",
            "iter  70 value 6055.234893\n",
            "iter  80 value 6016.862540\n",
            "iter  90 value 5994.040913\n",
            "iter 100 value 5978.590513\n",
            "final  value 5978.590513 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11963.702041 \n",
            "iter  10 value 7551.104733\n",
            "iter  20 value 6965.363787\n",
            "iter  30 value 6518.078732\n",
            "iter  40 value 6343.457873\n",
            "iter  50 value 6227.268026\n",
            "iter  60 value 6153.235371\n",
            "iter  70 value 6112.556888\n",
            "iter  80 value 6079.028630\n",
            "iter  90 value 6050.240958\n",
            "iter 100 value 6030.386875\n",
            "final  value 6030.386875 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20367.781108 \n",
            "iter  10 value 8042.931249\n",
            "iter  20 value 7112.612297\n",
            "iter  30 value 6369.248503\n",
            "iter  40 value 6144.027416\n",
            "iter  50 value 6043.134308\n",
            "iter  60 value 5989.087033\n",
            "iter  70 value 5921.560036\n",
            "iter  80 value 5857.322433\n",
            "iter  90 value 5810.246673\n",
            "iter 100 value 5772.979711\n",
            "final  value 5772.979711 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18089.030866 \n",
            "iter  10 value 7973.647594\n",
            "iter  20 value 6761.741825\n",
            "iter  30 value 6375.509335\n",
            "iter  40 value 6178.867714\n",
            "iter  50 value 6103.557284\n",
            "iter  60 value 6066.978468\n",
            "iter  70 value 6046.887908\n",
            "iter  80 value 6024.175892\n",
            "iter  90 value 5997.372527\n",
            "iter 100 value 5978.364117\n",
            "final  value 5978.364117 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21532.631019 \n",
            "iter  10 value 7952.915437\n",
            "iter  20 value 7889.962604\n",
            "iter  30 value 7771.651872\n",
            "iter  40 value 7417.932638\n",
            "iter  50 value 7013.270957\n",
            "iter  60 value 6474.104384\n",
            "iter  70 value 6247.882819\n",
            "iter  80 value 6151.431932\n",
            "iter  90 value 6098.224891\n",
            "iter 100 value 6056.772355\n",
            "final  value 6056.772355 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19262.279459 \n",
            "iter  10 value 8031.672105\n",
            "iter  20 value 7724.471660\n",
            "iter  30 value 6687.430762\n",
            "iter  40 value 6315.551831\n",
            "iter  50 value 6227.088428\n",
            "iter  60 value 6133.261031\n",
            "iter  70 value 6046.680557\n",
            "iter  80 value 5993.019764\n",
            "iter  90 value 5947.373174\n",
            "iter 100 value 5907.500255\n",
            "final  value 5907.500255 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11636.171007 \n",
            "iter  10 value 7593.955568\n",
            "iter  20 value 7030.026006\n",
            "iter  30 value 6567.409611\n",
            "iter  40 value 6372.808116\n",
            "iter  50 value 6262.617503\n",
            "iter  60 value 6152.821554\n",
            "iter  70 value 6100.280800\n",
            "iter  80 value 6056.633989\n",
            "iter  90 value 5997.953592\n",
            "iter 100 value 5966.127061\n",
            "final  value 5966.127061 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16104.410880 \n",
            "iter  10 value 8037.769047\n",
            "iter  20 value 6752.919646\n",
            "iter  30 value 6414.377783\n",
            "iter  40 value 6307.437787\n",
            "iter  50 value 6259.186882\n",
            "iter  60 value 6235.248597\n",
            "iter  70 value 6209.058302\n",
            "iter  80 value 6194.590383\n",
            "iter  90 value 6186.832427\n",
            "iter 100 value 6180.122127\n",
            "final  value 6180.122127 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17095.995906 \n",
            "iter  10 value 7919.849585\n",
            "iter  20 value 7652.063920\n",
            "iter  30 value 7266.713548\n",
            "iter  40 value 6757.736603\n",
            "iter  50 value 6469.059188\n",
            "iter  60 value 6332.545750\n",
            "iter  70 value 6276.126915\n",
            "iter  80 value 6245.255590\n",
            "iter  90 value 6216.650071\n",
            "iter 100 value 6192.808336\n",
            "final  value 6192.808336 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11525.034898 \n",
            "iter  10 value 7505.683432\n",
            "iter  20 value 7090.436039\n",
            "iter  30 value 6710.955292\n",
            "iter  40 value 6559.307400\n",
            "iter  50 value 6443.989503\n",
            "iter  60 value 6328.230362\n",
            "iter  70 value 6246.040711\n",
            "iter  80 value 6186.528399\n",
            "iter  90 value 6126.874793\n",
            "iter 100 value 6066.656380\n",
            "final  value 6066.656380 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14729.105578 \n",
            "iter  10 value 7785.080746\n",
            "iter  20 value 7211.896378\n",
            "iter  30 value 6828.806272\n",
            "iter  40 value 6565.723816\n",
            "iter  50 value 6330.625631\n",
            "iter  60 value 6244.372306\n",
            "iter  70 value 6190.165496\n",
            "iter  80 value 6156.823431\n",
            "iter  90 value 6114.943053\n",
            "iter 100 value 6078.853065\n",
            "final  value 6078.853065 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23202.448113 \n",
            "iter  10 value 8030.532298\n",
            "iter  20 value 7015.415128\n",
            "iter  30 value 6635.044424\n",
            "iter  40 value 6442.687060\n",
            "iter  50 value 6377.424968\n",
            "iter  60 value 6341.630507\n",
            "iter  70 value 6310.781204\n",
            "iter  80 value 6280.683253\n",
            "iter  90 value 6188.693004\n",
            "iter 100 value 6139.698110\n",
            "final  value 6139.698110 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20498.833117 \n",
            "iter  10 value 8154.635758\n",
            "iter  20 value 7756.304694\n",
            "iter  30 value 7430.089616\n",
            "iter  40 value 7200.566179\n",
            "iter  50 value 6980.508621\n",
            "iter  60 value 6723.215921\n",
            "iter  70 value 6442.365741\n",
            "iter  80 value 6271.147308\n",
            "iter  90 value 6142.336249\n",
            "iter 100 value 6079.816585\n",
            "final  value 6079.816585 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12887.423892 \n",
            "iter  10 value 6995.140173\n",
            "iter  20 value 6669.055815\n",
            "iter  30 value 6242.695639\n",
            "iter  40 value 6082.693755\n",
            "iter  50 value 6002.390908\n",
            "iter  60 value 5962.023032\n",
            "iter  70 value 5940.951079\n",
            "iter  80 value 5924.325629\n",
            "iter  90 value 5912.603173\n",
            "iter 100 value 5899.336682\n",
            "final  value 5899.336682 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12506.077314 \n",
            "iter  10 value 7964.178432\n",
            "iter  20 value 7683.454451\n",
            "iter  30 value 7272.549395\n",
            "iter  40 value 6858.856487\n",
            "iter  50 value 6463.399878\n",
            "iter  60 value 6251.370654\n",
            "iter  70 value 6168.987513\n",
            "iter  80 value 6100.291240\n",
            "iter  90 value 6046.676645\n",
            "iter 100 value 6005.446791\n",
            "final  value 6005.446791 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16367.306959 \n",
            "iter  10 value 7726.398751\n",
            "iter  20 value 6938.815742\n",
            "iter  30 value 6578.519774\n",
            "iter  40 value 6331.042412\n",
            "iter  50 value 6204.907167\n",
            "iter  60 value 6122.649566\n",
            "iter  70 value 6077.189700\n",
            "iter  80 value 6038.268553\n",
            "iter  90 value 6010.300067\n",
            "iter 100 value 5981.228984\n",
            "final  value 5981.228984 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13720.684119 \n",
            "iter  10 value 7461.370515\n",
            "iter  20 value 6798.452575\n",
            "iter  30 value 6641.712072\n",
            "iter  40 value 6541.439536\n",
            "iter  50 value 6412.105437\n",
            "iter  60 value 6315.308943\n",
            "iter  70 value 6267.379680\n",
            "iter  80 value 6246.489562\n",
            "iter  90 value 6234.235813\n",
            "iter 100 value 6225.395063\n",
            "final  value 6225.395063 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24861.274082 \n",
            "iter  10 value 8011.227167\n",
            "iter  20 value 7600.539785\n",
            "iter  30 value 7227.254354\n",
            "iter  40 value 6849.546202\n",
            "iter  50 value 6660.345429\n",
            "iter  60 value 6506.003006\n",
            "iter  70 value 6360.739721\n",
            "iter  80 value 6294.977334\n",
            "iter  90 value 6242.817059\n",
            "iter 100 value 6190.002021\n",
            "final  value 6190.002021 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13781.258227 \n",
            "iter  10 value 8086.859935\n",
            "iter  20 value 7398.552721\n",
            "iter  30 value 6940.425263\n",
            "iter  40 value 6676.717637\n",
            "iter  50 value 6417.504888\n",
            "iter  60 value 6271.521081\n",
            "iter  70 value 6188.293784\n",
            "iter  80 value 6159.548203\n",
            "iter  90 value 6128.882299\n",
            "iter 100 value 6100.023854\n",
            "final  value 6100.023854 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21498.767962 \n",
            "iter  10 value 8181.477562\n",
            "iter  20 value 6924.422494\n",
            "iter  30 value 6686.766900\n",
            "iter  40 value 6509.809437\n",
            "iter  50 value 6420.148869\n",
            "iter  60 value 6381.948458\n",
            "iter  70 value 6306.842915\n",
            "iter  80 value 6247.477084\n",
            "iter  90 value 6225.569791\n",
            "iter 100 value 6182.441683\n",
            "final  value 6182.441683 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 9723.279266 \n",
            "iter  10 value 7700.099894\n",
            "iter  20 value 7207.590787\n",
            "iter  30 value 6825.931484\n",
            "iter  40 value 6489.240164\n",
            "iter  50 value 6323.287577\n",
            "iter  60 value 6256.180163\n",
            "iter  70 value 6218.882199\n",
            "iter  80 value 6199.789115\n",
            "iter  90 value 6160.390802\n",
            "iter 100 value 6135.503400\n",
            "final  value 6135.503400 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15208.911569 \n",
            "iter  10 value 7935.328982\n",
            "iter  20 value 7279.385395\n",
            "iter  30 value 6869.246625\n",
            "iter  40 value 6529.891473\n",
            "iter  50 value 6372.746294\n",
            "iter  60 value 6290.570599\n",
            "iter  70 value 6241.122653\n",
            "iter  80 value 6208.314597\n",
            "iter  90 value 6174.790994\n",
            "iter 100 value 6153.964498\n",
            "final  value 6153.964498 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15659.860923 \n",
            "iter  10 value 7680.571493\n",
            "iter  20 value 7242.775804\n",
            "iter  30 value 6846.371223\n",
            "iter  40 value 6474.933097\n",
            "iter  50 value 6208.381863\n",
            "iter  60 value 6000.235125\n",
            "iter  70 value 5901.181619\n",
            "iter  80 value 5840.632133\n",
            "iter  90 value 5816.398805\n",
            "iter 100 value 5807.431610\n",
            "final  value 5807.431610 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14132.882715 \n",
            "iter  10 value 7979.209364\n",
            "iter  20 value 6982.716248\n",
            "iter  30 value 6571.667106\n",
            "iter  40 value 6385.282827\n",
            "iter  50 value 6171.719896\n",
            "iter  60 value 6013.650412\n",
            "iter  70 value 5916.071869\n",
            "iter  80 value 5850.074749\n",
            "iter  90 value 5811.477596\n",
            "iter 100 value 5768.973214\n",
            "final  value 5768.973214 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.2 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15041.319630 \n",
            "iter  10 value 7983.490602\n",
            "iter  20 value 7434.379967\n",
            "iter  30 value 6735.822044\n",
            "iter  40 value 6376.806466\n",
            "iter  50 value 6257.593181\n",
            "iter  60 value 6148.805940\n",
            "iter  70 value 6089.338106\n",
            "iter  80 value 6064.865564\n",
            "iter  90 value 6052.839800\n",
            "iter 100 value 6027.422347\n",
            "final  value 6027.422347 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.3 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 27410.012113 \n",
            "iter  10 value 8127.811870\n",
            "iter  20 value 6710.273455\n",
            "iter  30 value 6228.508528\n",
            "iter  40 value 6086.976806\n",
            "iter  50 value 6016.589876\n",
            "iter  60 value 5966.400675\n",
            "iter  70 value 5933.272687\n",
            "iter  80 value 5893.231970\n",
            "iter  90 value 5848.961714\n",
            "iter 100 value 5826.022409\n",
            "final  value 5826.022409 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.4 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12999.811736 \n",
            "iter  10 value 7577.525984\n",
            "iter  20 value 6827.719071\n",
            "iter  30 value 6468.638002\n",
            "iter  40 value 6313.098928\n",
            "iter  50 value 6214.123874\n",
            "iter  60 value 6135.511132\n",
            "iter  70 value 6072.716554\n",
            "iter  80 value 6005.843505\n",
            "iter  90 value 5947.710355\n",
            "iter 100 value 5907.289916\n",
            "final  value 5907.289916 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.5 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11010.231746 \n",
            "iter  10 value 7164.084864\n",
            "iter  20 value 6848.681856\n",
            "iter  30 value 6589.956061\n",
            "iter  40 value 6324.894164\n",
            "iter  50 value 6177.848835\n",
            "iter  60 value 6116.802486\n",
            "iter  70 value 6097.113594\n",
            "iter  80 value 6088.718559\n",
            "iter  90 value 6080.132300\n",
            "iter 100 value 6048.787640\n",
            "final  value 6048.787640 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.6 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15056.412318 \n",
            "iter  10 value 8020.107137\n",
            "iter  20 value 7381.018394\n",
            "iter  30 value 6653.772980\n",
            "iter  40 value 6381.355954\n",
            "iter  50 value 6200.920405\n",
            "iter  60 value 6106.150365\n",
            "iter  70 value 6050.405386\n",
            "iter  80 value 6006.923010\n",
            "iter  90 value 5984.472934\n",
            "iter 100 value 5955.900033\n",
            "final  value 5955.900033 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.7 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19018.823288 \n",
            "iter  10 value 7968.582388\n",
            "iter  20 value 7660.731806\n",
            "iter  30 value 7288.895464\n",
            "iter  40 value 7122.080744\n",
            "iter  50 value 6886.223832\n",
            "iter  60 value 6452.957782\n",
            "iter  70 value 6223.177173\n",
            "iter  80 value 6085.226799\n",
            "iter  90 value 6037.146403\n",
            "iter 100 value 6010.455653\n",
            "final  value 6010.455653 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.8 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17745.285263 \n",
            "iter  10 value 7943.894728\n",
            "iter  20 value 7560.315553\n",
            "iter  30 value 6932.099805\n",
            "iter  40 value 6644.750245\n",
            "iter  50 value 6422.933353\n",
            "iter  60 value 6297.098341\n",
            "iter  70 value 6186.992788\n",
            "iter  80 value 6125.746186\n",
            "iter  90 value 6099.406836\n",
            "iter 100 value 6083.244683\n",
            "final  value 6083.244683 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.9 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 24812.454763 \n",
            "iter  10 value 8011.520789\n",
            "iter  20 value 6735.766986\n",
            "iter  30 value 6506.870909\n",
            "iter  40 value 6339.694948\n",
            "iter  50 value 6229.762176\n",
            "iter  60 value 6152.676634\n",
            "iter  70 value 6090.853304\n",
            "iter  80 value 6039.503413\n",
            "iter  90 value 6003.835162\n",
            "iter 100 value 5982.099776\n",
            "final  value 5982.099776 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=2, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (1731) weights\n",
            "”\n",
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=1.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n",
            "Warning message in train.default(x, y, weights = w, ...):\n",
            "“missing values found in aggregated results”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18602.973935 \n",
            "iter  10 value 8140.593327\n",
            "iter  20 value 7490.441799\n",
            "iter  30 value 7051.312407\n",
            "iter  40 value 6782.597637\n",
            "iter  50 value 6637.165998\n",
            "iter  60 value 6531.034925\n",
            "iter  70 value 6435.669301\n",
            "iter  80 value 6392.653268\n",
            "iter  90 value 6366.527351\n",
            "iter 100 value 6350.974052\n",
            "final  value 6350.974052 \n",
            "stopped after 100 iterations\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークによる予測\n",
        "modelNnet <- train(\n",
        "  as.formula(paste(\"C_yF ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "  method = \"nnet\",\n",
        "  tuneGrid = expand.grid(size=c(1:3), decay=seq(0.1, 1, 0.1)),\n",
        "  linout = FALSE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "Q84lAUAk4axW",
        "outputId": "af0aec81-716b-4384-f21b-e11fc0f8ed01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Neural Network \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  size  decay  Accuracy   Kappa    \n",
              "  1     0.1    0.8846433  0.2956777\n",
              "  1     0.2    0.8857914  0.2828503\n",
              "  1     0.3    0.8869665  0.2866577\n",
              "  1     0.4    0.8872872  0.2824882\n",
              "  1     0.5    0.8878129  0.2787549\n",
              "  1     0.6    0.8878876  0.2793309\n",
              "  1     0.7    0.8888102  0.2816786\n",
              "  1     0.8    0.8884053  0.2778506\n",
              "  1     0.9    0.8887857  0.2667860\n",
              "  1     1.0    0.8885714  0.2739284\n",
              "  2     0.1          NaN        NaN\n",
              "  2     0.2          NaN        NaN\n",
              "  2     0.3          NaN        NaN\n",
              "  2     0.4          NaN        NaN\n",
              "  2     0.5          NaN        NaN\n",
              "  2     0.6          NaN        NaN\n",
              "  2     0.7          NaN        NaN\n",
              "  2     0.8          NaN        NaN\n",
              "  2     0.9          NaN        NaN\n",
              "  2     1.0          NaN        NaN\n",
              "  3     0.1          NaN        NaN\n",
              "  3     0.2          NaN        NaN\n",
              "  3     0.3          NaN        NaN\n",
              "  3     0.4          NaN        NaN\n",
              "  3     0.5          NaN        NaN\n",
              "  3     0.6          NaN        NaN\n",
              "  3     0.7          NaN        NaN\n",
              "  3     0.8          NaN        NaN\n",
              "  3     0.9          NaN        NaN\n",
              "  3     1.0          NaN        NaN\n",
              "\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final values used for the model were size = 1 and decay = 0.7."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RZyy0kiCKTVQ",
        "outputId": "08c990e9-3bda-4693-f791-c68a15a0d025"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "56.616325907709"
            ],
            "text/latex": "56.616325907709",
            "text/markdown": "56.616325907709",
            "text/plain": [
              "[1] 56.61633"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnet_out_result_data <- data.frame(samp_o,predict(modelNnet,samp_o,type=\"prob\"))\n",
        "write.table(modelNnet_out_result_data, file = \"/content/modelNnet_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelNnet, file = \"/content/modelNnet.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelNnet_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelNnet_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkUOWoLH9N02"
      },
      "source": [
        "## 02-3.モデル作成（勾配ブースティング）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e4B-8Fg-Zq-"
      },
      "outputs": [],
      "source": [
        "modelXgboostTree <- train(\n",
        "  as.formula(paste(\"C_yF ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "  method = \"xgbTree\",\n",
        "  tuneLength = 2,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV_7WgoXRynQ"
      },
      "outputs": [],
      "source": [
        "modelXgboostTree_out_result_data <- data.frame(samp_o,predict(modelXgboostTree ,samp_o,type=\"prob\"))\n",
        "write.table(modelXgboostTree_out_result_data, file = \"/content/modelXgboostTree_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelXgboostTree, file = \"/content/modelXgboostTree.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelXgboostTree_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelXgboostTree_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwbNoGyQ9U39"
      },
      "source": [
        "## 02-4.モデル作成（サポートベクターマシン）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4AT5F1--dIR"
      },
      "outputs": [],
      "source": [
        "modelSVM <- train(\n",
        "  as.formula(paste(\"C_y ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "　trControl = trainControl(classProbs =  TRUE),\n",
        "  method = \"svmRadial\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANtYEF_RTCpg"
      },
      "outputs": [],
      "source": [
        "modelSVM_out_result_data <- data.frame(samp_o,predict(modelSVM,samp_o,type=\"prob\"))\n",
        "write.table(modelSVM_out_result_data, file = \"/content/modelSVM_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelSVM, file = \"/content/modelSVM.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelSVM_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"yes\"\n",
        "sortPred <- modelSVM_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqry0uevWrL-"
      },
      "source": [
        "## 02-5.モデル作成_ステップワイズ（勾配ブースティング）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPZyv0QyWrL_",
        "outputId": "73d317b0-21b1-4f3c-8584-f95935274090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:26:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:26:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:27:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:28:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:29:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:30:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:31:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:32:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:33:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:34:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:35:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:36:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:37:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:38:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:39:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:40:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:41:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:42:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:43:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:44:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:45:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:46:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:47:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:48:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:49:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:50:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:51:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:52:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:53:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[03:54:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n"
          ]
        }
      ],
      "source": [
        "modelXgboostTree_sw <- train(\n",
        "  C_yF ~ B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age,\n",
        "  data = samp_i,\n",
        "  method = \"xgbTree\",\n",
        "  tuneLength = 2,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "3iNIpNVlD6oU",
        "outputId": "f6050093-44df-43a5-cb95-0a70fcb5e356"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "eXtreme Gradient Boosting \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  eta  max_depth  colsample_bytree  subsample  nrounds  Accuracy   Kappa    \n",
              "  0.3  1          0.6               0.5         50      0.8945283  0.2283933\n",
              "  0.3  1          0.6               0.5        100      0.8941828  0.2431750\n",
              "  0.3  1          0.6               1.0         50      0.8944888  0.2209975\n",
              "  0.3  1          0.6               1.0        100      0.8942326  0.2310038\n",
              "  0.3  1          0.8               0.5         50      0.8942626  0.2260452\n",
              "  0.3  1          0.8               0.5        100      0.8940573  0.2419322\n",
              "  0.3  1          0.8               1.0         50      0.8943585  0.2197172\n",
              "  0.3  1          0.8               1.0        100      0.8942666  0.2310372\n",
              "  0.3  2          0.6               0.5         50      0.8935617  0.2427665\n",
              "  0.3  2          0.6               0.5        100      0.8923793  0.2533934\n",
              "  0.3  2          0.6               1.0         50      0.8943984  0.2389408\n",
              "  0.3  2          0.6               1.0        100      0.8935492  0.2509274\n",
              "  0.3  2          0.8               0.5         50      0.8935256  0.2428893\n",
              "  0.3  2          0.8               0.5        100      0.8929489  0.2555477\n",
              "  0.3  2          0.8               1.0         50      0.8941703  0.2369235\n",
              "  0.3  2          0.8               1.0        100      0.8933688  0.2497163\n",
              "  0.4  1          0.6               0.5         50      0.8940539  0.2358134\n",
              "  0.4  1          0.6               0.5        100      0.8936450  0.2479786\n",
              "  0.4  1          0.6               1.0         50      0.8942669  0.2266374\n",
              "  0.4  1          0.6               1.0        100      0.8942281  0.2388345\n",
              "  0.4  1          0.8               0.5         50      0.8939555  0.2324617\n",
              "  0.4  1          0.8               0.5        100      0.8935464  0.2476114\n",
              "  0.4  1          0.8               1.0         50      0.8942428  0.2265654\n",
              "  0.4  1          0.8               1.0        100      0.8942120  0.2383860\n",
              "  0.4  2          0.6               0.5         50      0.8930976  0.2513874\n",
              "  0.4  2          0.6               0.5        100      0.8921526  0.2593999\n",
              "  0.4  2          0.6               1.0         50      0.8934548  0.2442484\n",
              "  0.4  2          0.6               1.0        100      0.8928926  0.2544871\n",
              "  0.4  2          0.8               0.5         50      0.8929426  0.2532144\n",
              "  0.4  2          0.8               0.5        100      0.8920923  0.2636561\n",
              "  0.4  2          0.8               1.0         50      0.8936977  0.2456272\n",
              "  0.4  2          0.8               1.0        100      0.8925982  0.2531344\n",
              "\n",
              "Tuning parameter 'gamma' was held constant at a value of 0\n",
              "Tuning\n",
              " parameter 'min_child_weight' was held constant at a value of 1\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final values used for the model were nrounds = 50, max_depth = 1, eta\n",
              " = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample\n",
              " = 0.5."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelXgboostTree_sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GdLRUjU2WrL_",
        "outputId": "d00c9554-0902-4063-fc76-5a9a4a7bbca5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "54.1402158147428"
            ],
            "text/latex": "54.1402158147428",
            "text/markdown": "54.1402158147428",
            "text/plain": [
              "[1] 54.14022"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelXgboostTree_sw_out_result_data <- data.frame(samp_o,predict(modelXgboostTree_sw ,samp_o,type=\"prob\"))\n",
        "write.table(modelXgboostTree_sw_out_result_data, file = \"/content/modelXgboostTree_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelXgboostTree_sw, file = \"/content/modelXgboostTree_sw.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelXgboostTree_sw_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelXgboostTree_sw_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjO1Vrk3WrL_"
      },
      "source": [
        "## 02-6.モデル作成_ステップワイズ（サポートベクターマシン）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBftis4bWrMA"
      },
      "outputs": [],
      "source": [
        "modelSVM_sw <- train(\n",
        "    C_y ~ B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age,\n",
        "  data = samp_i,\n",
        "　trControl = trainControl(classProbs =  TRUE),\n",
        "  tuneLength = 2,\n",
        "  method = \"svmRadial\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZkitXyrWrMA"
      },
      "outputs": [],
      "source": [
        "modelSVM_sw_out_result_data <- data.frame(samp_o,predict(modelSVM_sw,samp_o,type=\"prob\"))\n",
        "write.table(modelSVM_sw_out_result_data, file = \"/content/modelSVM_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelSVM_sw, file = \"/content/modelSVM_sw.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelSVM_sw_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"yes\"\n",
        "sortPred <- modelSVM_sw_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlTWk9UCIhIF"
      },
      "source": [
        "## 02-7.モデル作成_ステップワイズ（ランダムフォレスト）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftanwJ5WIhIG"
      },
      "outputs": [],
      "source": [
        "modelRF_sw <- train(\n",
        "    C_yF ~ B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age,\n",
        "  data = samp_i,\n",
        "  tuneLength = 2,\n",
        "  method = \"rf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelRF_sw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "zwm7SBLFpybA",
        "outputId": "b0fd0963-4a2f-4810-97d7-e6eb650d4d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Random Forest \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  mtry  Accuracy   Kappa    \n",
              "    2   0.8915909  0.2159415\n",
              "  197   0.8829614  0.2572147\n",
              "\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final value used for the model was mtry = 2."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55da94d7-ce69-416e-8a4e-a20c525e0cdb",
        "id": "EnMfLafwmksX"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "46.3007604548829"
            ],
            "text/markdown": "46.3007604548829",
            "text/latex": "46.3007604548829",
            "text/plain": [
              "[1] 46.30076"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "modelRF_sw_out_result_data <- data.frame(samp_o,predict(modelRF_sw,samp_o,type=\"prob\"))\n",
        "write.table(modelRF_sw_out_result_data, file = \"/content/modelRF_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelRF_sw, file = \"/content/modelRF_sw.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelRF_sw_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelRF_sw_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omVl9N6c7esI"
      },
      "source": [
        "## 02-7.モデル作成_tuneLength2（ディープラーニング）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iQJVvWu7esJ",
        "outputId": "7b1c47a1-cc92-42a3-dc25-9134d3887800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "“model fit failed for Resample11: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n",
            "Warning message in train.default(x, y, weights = w, ...):\n",
            "“missing values found in aggregated results”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modelDnn_t2 <- train(\n",
        "  as.formula(paste(\"C_yF ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "  tuneLength = 2,\n",
        "  method = \"dnn\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FziOYggag0HV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "e4851f4a-ad8c-4c04-b5b7-64cf5d036012"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Stacked AutoEncoder Deep Neural Network \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  layer1  layer2  layer3  hidden_dropout  visible_dropout  Accuracy   Kappa\n",
              "  1       0       0       0.0             0.0              0.8822745    0  \n",
              "  1       0       0       0.0             0.7              0.8822745    0  \n",
              "  1       0       0       0.7             0.0              0.8822745    0  \n",
              "  1       0       0       0.7             0.7              0.8822745    0  \n",
              "  1       0       1       0.0             0.0              0.8822745    0  \n",
              "  1       0       1       0.0             0.7                    NaN  NaN  \n",
              "  1       0       1       0.7             0.0              0.8822745    0  \n",
              "  1       0       1       0.7             0.7                    NaN  NaN  \n",
              "  1       1       0       0.0             0.0              0.8822745    0  \n",
              "  1       1       0       0.0             0.7                    NaN  NaN  \n",
              "  1       1       0       0.7             0.0              0.8822745    0  \n",
              "  1       1       0       0.7             0.7                    NaN  NaN  \n",
              "  1       1       1       0.0             0.0              0.8822745    0  \n",
              "  1       1       1       0.0             0.7                    NaN  NaN  \n",
              "  1       1       1       0.7             0.0              0.8822745    0  \n",
              "  1       1       1       0.7             0.7                    NaN  NaN  \n",
              "  2       0       0       0.0             0.0              0.8822745    0  \n",
              "  2       0       0       0.0             0.7              0.8822745    0  \n",
              "  2       0       0       0.7             0.0              0.8822745    0  \n",
              "  2       0       0       0.7             0.7              0.8822745    0  \n",
              "  2       0       1       0.0             0.0              0.8822745    0  \n",
              "  2       0       1       0.0             0.7              0.8822745    0  \n",
              "  2       0       1       0.7             0.0              0.8822745    0  \n",
              "  2       0       1       0.7             0.7              0.8822745    0  \n",
              "  2       1       0       0.0             0.0              0.8822745    0  \n",
              "  2       1       0       0.0             0.7              0.8822745    0  \n",
              "  2       1       0       0.7             0.0              0.8822745    0  \n",
              "  2       1       0       0.7             0.7              0.8822745    0  \n",
              "  2       1       1       0.0             0.0              0.8822745    0  \n",
              "  2       1       1       0.0             0.7                    NaN  NaN  \n",
              "  2       1       1       0.7             0.0              0.8822745    0  \n",
              "  2       1       1       0.7             0.7                    NaN  NaN  \n",
              "\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final values used for the model were layer1 = 1, layer2 = 0, layer3 =\n",
              " 0, hidden_dropout = 0 and visible_dropout = 0."
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "modelDnn_t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtfUCIKd7esJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "475e6d3f-ca6e-4d1d-8002-565dcfe80ece"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "44.4382740507316"
            ],
            "text/markdown": "44.4382740507316",
            "text/latex": "44.4382740507316",
            "text/plain": [
              "[1] 44.43827"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "modelDnn_t2_out_result_data <- data.frame(samp_o,predict(modelDnn_t2,samp_o,type=\"prob\"))\n",
        "write.table(modelDnn_t2_out_result_data, file = \"/content/modelDnn_t2_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelDnn_t2, file = \"/content/modelDnn_t2.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelDnn_t2_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelDnn_t2_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muIlU7y01WeX"
      },
      "source": [
        "## 02-7.モデル作成_tuneLength5（ディープラーニング）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byv7_mBY1WeY"
      },
      "outputs": [],
      "source": [
        "modelDnn_t5 <- train(\n",
        "  as.formula(paste(\"C_yF ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "  tuneLength = 5,\n",
        "  method = \"dnn\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FQVu8181WeY"
      },
      "outputs": [],
      "source": [
        "modelDnn_t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C56MlM0B1WeZ"
      },
      "outputs": [],
      "source": [
        "modelDnn_t5_out_result_data <- data.frame(samp_o,predict(modelDnn_t5_out_result_data,samp_o,type=\"prob\"))\n",
        "write.table(modelDnn_t5_out_result_data, file = \"/content/modelDnn_t5_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelDnn_t5, file = \"/content/modelDnn_t5.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelDnn_t5_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelDnn_t5_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGGYn8QgfuWt"
      },
      "source": [
        "# 99-1.切断しないように"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "qGgi29KHf14O",
        "outputId": "668fa0f3-3e24-4521-8980-450294e4137f"
      },
      "outputs": [
        {
          "ename": "ERROR",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected SPECIAL\n1: %%\n    ^\nTraceback:\n"
          ]
        }
      ],
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwPxJtz5SeS6"
      },
      "source": [
        "# 99-2.モデル保存のテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcD1MYEtS0-2"
      },
      "outputs": [],
      "source": [
        "#モデル作成_ステップワイズ結果版_50%\n",
        "mbs <- glm(yF  ~\n",
        "             B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age\n",
        "           , data=samp_i,family=binomial(link=logit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "hkkLZFtKS4Rw",
        "outputId": "99cf4f6b-721b-4a1a-8815-bee9d04c6a17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in gzfile(file, mode):\n",
            "“cannot open compressed file 'https://github.com/PortugalJip2022/Portugal2022/test.git', probable reason 'No such file or directory'”\n"
          ]
        },
        {
          "ename": "ERROR",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "Error in gzfile(file, mode): cannot open the connection\nTraceback:\n",
            "1. saveRDS(mbs, file = \"https://github.com/PortugalJip2022/Portugal2022/test.git\")",
            "2. gzfile(file, mode)"
          ]
        }
      ],
      "source": [
        "saveRDS(mbs, file = \"/content/mbs.obj\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqpwKDV4Wl5x"
      },
      "source": [
        "# 99-3.predictのテスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6YF12OWZUHH"
      },
      "source": [
        "## 99-3-1.precitテスト_ニューラル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnJMLwICWsrv"
      },
      "outputs": [],
      "source": [
        "# ニューラルネットワークによる予測\n",
        "modelNnetTest <- train(\n",
        "  C_yF ~ C_poutcome + C_month:B_pdays,\n",
        "  data = samp_i,\n",
        "  method = \"nnet\",\n",
        "  tuneLength = 4,\n",
        "  linout = FALSE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIE2qT2EWs5D"
      },
      "outputs": [],
      "source": [
        "modelNnetTest_out_result <- predict(modelNnetTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nMqJgtl0ibNk",
        "outputId": "73863a6a-12a8-4760-940b-7d2745639b1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>2</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>12</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>17</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>30</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>48</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>51</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>54</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>58</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>59</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>61</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>63</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>64</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>66</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>69</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>74</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45158</th><td>0.7499441</td><td>0.25005586</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>0.2942253</td><td>0.70577472</td></tr>\n",
              "\t<tr><th scope=row>45165</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>0.7250175</td><td>0.27498248</td></tr>\n",
              "\t<tr><th scope=row>45167</th><td>0.6501053</td><td>0.34989472</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>0.2459378</td><td>0.75406224</td></tr>\n",
              "\t<tr><th scope=row>45170</th><td>0.9556334</td><td>0.04436658</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>0.9556334</td><td>0.04436658</td></tr>\n",
              "\t<tr><th scope=row>45174</th><td>0.8597910</td><td>0.14020896</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>0.2985996</td><td>0.70140044</td></tr>\n",
              "\t<tr><th scope=row>45180</th><td>0.8241147</td><td>0.17588533</td></tr>\n",
              "\t<tr><th scope=row>45181</th><td>0.7326401</td><td>0.26735988</td></tr>\n",
              "\t<tr><th scope=row>45183</th><td>0.6501053</td><td>0.34989472</td></tr>\n",
              "\t<tr><th scope=row>45186</th><td>0.2985996</td><td>0.70140044</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45190</th><td>0.7499441</td><td>0.25005586</td></tr>\n",
              "\t<tr><th scope=row>45191</th><td>0.6501053</td><td>0.34989472</td></tr>\n",
              "\t<tr><th scope=row>45192</th><td>0.9556334</td><td>0.04436658</td></tr>\n",
              "\t<tr><th scope=row>45193</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>0.9451617</td><td>0.05483832</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45202</th><td>0.6501053</td><td>0.34989472</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45205</th><td>0.6570297</td><td>0.34297031</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>0.9064976</td><td>0.09350237</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>0.6501053</td><td>0.34989472</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>0.9451617</td><td>0.05483832</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n  & <dbl> & <dbl>\\\\\n\\hline\n\t2 & 0.9064976 & 0.09350237\\\\\n\t4 & 0.9064976 & 0.09350237\\\\\n\t8 & 0.9064976 & 0.09350237\\\\\n\t10 & 0.9064976 & 0.09350237\\\\\n\t12 & 0.9064976 & 0.09350237\\\\\n\t14 & 0.9064976 & 0.09350237\\\\\n\t16 & 0.9064976 & 0.09350237\\\\\n\t17 & 0.9064976 & 0.09350237\\\\\n\t18 & 0.9064976 & 0.09350237\\\\\n\t22 & 0.9064976 & 0.09350237\\\\\n\t24 & 0.9064976 & 0.09350237\\\\\n\t30 & 0.9064976 & 0.09350237\\\\\n\t31 & 0.9064976 & 0.09350237\\\\\n\t32 & 0.9064976 & 0.09350237\\\\\n\t34 & 0.9064976 & 0.09350237\\\\\n\t36 & 0.9064976 & 0.09350237\\\\\n\t41 & 0.9064976 & 0.09350237\\\\\n\t45 & 0.9064976 & 0.09350237\\\\\n\t46 & 0.9064976 & 0.09350237\\\\\n\t48 & 0.9064976 & 0.09350237\\\\\n\t51 & 0.9064976 & 0.09350237\\\\\n\t54 & 0.9064976 & 0.09350237\\\\\n\t58 & 0.9064976 & 0.09350237\\\\\n\t59 & 0.9064976 & 0.09350237\\\\\n\t61 & 0.9064976 & 0.09350237\\\\\n\t63 & 0.9064976 & 0.09350237\\\\\n\t64 & 0.9064976 & 0.09350237\\\\\n\t66 & 0.9064976 & 0.09350237\\\\\n\t69 & 0.9064976 & 0.09350237\\\\\n\t74 & 0.9064976 & 0.09350237\\\\\n\t⋮ & ⋮ & ⋮\\\\\n\t45158 & 0.7499441 & 0.25005586\\\\\n\t45162 & 0.9064976 & 0.09350237\\\\\n\t45163 & 0.2942253 & 0.70577472\\\\\n\t45165 & 0.9064976 & 0.09350237\\\\\n\t45166 & 0.7250175 & 0.27498248\\\\\n\t45167 & 0.6501053 & 0.34989472\\\\\n\t45169 & 0.2459378 & 0.75406224\\\\\n\t45170 & 0.9556334 & 0.04436658\\\\\n\t45172 & 0.9556334 & 0.04436658\\\\\n\t45174 & 0.8597910 & 0.14020896\\\\\n\t45175 & 0.2985996 & 0.70140044\\\\\n\t45180 & 0.8241147 & 0.17588533\\\\\n\t45181 & 0.7326401 & 0.26735988\\\\\n\t45183 & 0.6501053 & 0.34989472\\\\\n\t45186 & 0.2985996 & 0.70140044\\\\\n\t45188 & 0.9064976 & 0.09350237\\\\\n\t45190 & 0.7499441 & 0.25005586\\\\\n\t45191 & 0.6501053 & 0.34989472\\\\\n\t45192 & 0.9556334 & 0.04436658\\\\\n\t45193 & 0.9064976 & 0.09350237\\\\\n\t45198 & 0.9064976 & 0.09350237\\\\\n\t45200 & 0.9451617 & 0.05483832\\\\\n\t45201 & 0.9064976 & 0.09350237\\\\\n\t45202 & 0.6501053 & 0.34989472\\\\\n\t45203 & 0.9064976 & 0.09350237\\\\\n\t45204 & 0.9064976 & 0.09350237\\\\\n\t45205 & 0.6570297 & 0.34297031\\\\\n\t45207 & 0.9064976 & 0.09350237\\\\\n\t45209 & 0.6501053 & 0.34989472\\\\\n\t45211 & 0.9451617 & 0.05483832\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; |\n|---|---|---|\n| 2 | 0.9064976 | 0.09350237 |\n| 4 | 0.9064976 | 0.09350237 |\n| 8 | 0.9064976 | 0.09350237 |\n| 10 | 0.9064976 | 0.09350237 |\n| 12 | 0.9064976 | 0.09350237 |\n| 14 | 0.9064976 | 0.09350237 |\n| 16 | 0.9064976 | 0.09350237 |\n| 17 | 0.9064976 | 0.09350237 |\n| 18 | 0.9064976 | 0.09350237 |\n| 22 | 0.9064976 | 0.09350237 |\n| 24 | 0.9064976 | 0.09350237 |\n| 30 | 0.9064976 | 0.09350237 |\n| 31 | 0.9064976 | 0.09350237 |\n| 32 | 0.9064976 | 0.09350237 |\n| 34 | 0.9064976 | 0.09350237 |\n| 36 | 0.9064976 | 0.09350237 |\n| 41 | 0.9064976 | 0.09350237 |\n| 45 | 0.9064976 | 0.09350237 |\n| 46 | 0.9064976 | 0.09350237 |\n| 48 | 0.9064976 | 0.09350237 |\n| 51 | 0.9064976 | 0.09350237 |\n| 54 | 0.9064976 | 0.09350237 |\n| 58 | 0.9064976 | 0.09350237 |\n| 59 | 0.9064976 | 0.09350237 |\n| 61 | 0.9064976 | 0.09350237 |\n| 63 | 0.9064976 | 0.09350237 |\n| 64 | 0.9064976 | 0.09350237 |\n| 66 | 0.9064976 | 0.09350237 |\n| 69 | 0.9064976 | 0.09350237 |\n| 74 | 0.9064976 | 0.09350237 |\n| ⋮ | ⋮ | ⋮ |\n| 45158 | 0.7499441 | 0.25005586 |\n| 45162 | 0.9064976 | 0.09350237 |\n| 45163 | 0.2942253 | 0.70577472 |\n| 45165 | 0.9064976 | 0.09350237 |\n| 45166 | 0.7250175 | 0.27498248 |\n| 45167 | 0.6501053 | 0.34989472 |\n| 45169 | 0.2459378 | 0.75406224 |\n| 45170 | 0.9556334 | 0.04436658 |\n| 45172 | 0.9556334 | 0.04436658 |\n| 45174 | 0.8597910 | 0.14020896 |\n| 45175 | 0.2985996 | 0.70140044 |\n| 45180 | 0.8241147 | 0.17588533 |\n| 45181 | 0.7326401 | 0.26735988 |\n| 45183 | 0.6501053 | 0.34989472 |\n| 45186 | 0.2985996 | 0.70140044 |\n| 45188 | 0.9064976 | 0.09350237 |\n| 45190 | 0.7499441 | 0.25005586 |\n| 45191 | 0.6501053 | 0.34989472 |\n| 45192 | 0.9556334 | 0.04436658 |\n| 45193 | 0.9064976 | 0.09350237 |\n| 45198 | 0.9064976 | 0.09350237 |\n| 45200 | 0.9451617 | 0.05483832 |\n| 45201 | 0.9064976 | 0.09350237 |\n| 45202 | 0.6501053 | 0.34989472 |\n| 45203 | 0.9064976 | 0.09350237 |\n| 45204 | 0.9064976 | 0.09350237 |\n| 45205 | 0.6570297 | 0.34297031 |\n| 45207 | 0.9064976 | 0.09350237 |\n| 45209 | 0.6501053 | 0.34989472 |\n| 45211 | 0.9451617 | 0.05483832 |\n\n",
            "text/plain": [
              "      0         1         \n",
              "2     0.9064976 0.09350237\n",
              "4     0.9064976 0.09350237\n",
              "8     0.9064976 0.09350237\n",
              "10    0.9064976 0.09350237\n",
              "12    0.9064976 0.09350237\n",
              "14    0.9064976 0.09350237\n",
              "16    0.9064976 0.09350237\n",
              "17    0.9064976 0.09350237\n",
              "18    0.9064976 0.09350237\n",
              "22    0.9064976 0.09350237\n",
              "24    0.9064976 0.09350237\n",
              "30    0.9064976 0.09350237\n",
              "31    0.9064976 0.09350237\n",
              "32    0.9064976 0.09350237\n",
              "34    0.9064976 0.09350237\n",
              "36    0.9064976 0.09350237\n",
              "41    0.9064976 0.09350237\n",
              "45    0.9064976 0.09350237\n",
              "46    0.9064976 0.09350237\n",
              "48    0.9064976 0.09350237\n",
              "51    0.9064976 0.09350237\n",
              "54    0.9064976 0.09350237\n",
              "58    0.9064976 0.09350237\n",
              "59    0.9064976 0.09350237\n",
              "61    0.9064976 0.09350237\n",
              "63    0.9064976 0.09350237\n",
              "64    0.9064976 0.09350237\n",
              "66    0.9064976 0.09350237\n",
              "69    0.9064976 0.09350237\n",
              "74    0.9064976 0.09350237\n",
              "⋮     ⋮         ⋮         \n",
              "45158 0.7499441 0.25005586\n",
              "45162 0.9064976 0.09350237\n",
              "45163 0.2942253 0.70577472\n",
              "45165 0.9064976 0.09350237\n",
              "45166 0.7250175 0.27498248\n",
              "45167 0.6501053 0.34989472\n",
              "45169 0.2459378 0.75406224\n",
              "45170 0.9556334 0.04436658\n",
              "45172 0.9556334 0.04436658\n",
              "45174 0.8597910 0.14020896\n",
              "45175 0.2985996 0.70140044\n",
              "45180 0.8241147 0.17588533\n",
              "45181 0.7326401 0.26735988\n",
              "45183 0.6501053 0.34989472\n",
              "45186 0.2985996 0.70140044\n",
              "45188 0.9064976 0.09350237\n",
              "45190 0.7499441 0.25005586\n",
              "45191 0.6501053 0.34989472\n",
              "45192 0.9556334 0.04436658\n",
              "45193 0.9064976 0.09350237\n",
              "45198 0.9064976 0.09350237\n",
              "45200 0.9451617 0.05483832\n",
              "45201 0.9064976 0.09350237\n",
              "45202 0.6501053 0.34989472\n",
              "45203 0.9064976 0.09350237\n",
              "45204 0.9064976 0.09350237\n",
              "45205 0.6570297 0.34297031\n",
              "45207 0.9064976 0.09350237\n",
              "45209 0.6501053 0.34989472\n",
              "45211 0.9451617 0.05483832"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnetTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "m9l5RddWLV5z",
        "outputId": "532d3787-9446-47ce-fc4d-dafa8704b969"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "27.7989318202264"
            ],
            "text/latex": "27.7989318202264",
            "text/markdown": "27.7989318202264",
            "text/plain": [
              "[1] 27.79893"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnetTest_out_result_data <- data.frame(samp_o,predict(modelNnetTest,samp_o,type=\"prob\"))\n",
        "write.table(modelNnetTest_out_result_data, file = \"/content/modelNnetTest_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelNnetTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelNnetTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLF4iJzZZiT1"
      },
      "source": [
        "## 99-3-2.precitテスト_勾配ブースティング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb7etTB-mAXQ",
        "outputId": "c2efbf0e-39c8-4d3b-f7af-575a57c9b01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:11:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:11:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:12:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:13:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:14:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:15:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:17] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:31] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:54] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:58] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:16:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:01] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:06] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:14] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:22] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:25] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:34] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:43] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:50] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:56] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:57] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:17:59] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:00] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:02] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:03] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:04] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:05] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:07] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:08] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:09] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:10] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:11] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:12] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:13] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:15] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:16] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:18] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:19] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:20] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:21] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:23] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:24] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:26] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:27] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:28] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:29] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:30] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:32] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:33] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:35] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:36] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:37] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:38] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:39] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:40] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:41] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:42] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:44] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:45] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:46] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:47] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:48] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:49] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:51] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:52] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:53] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n",
            "[04:18:55] WARNING: amalgamation/../src/c_api/c_api.cc:785: `ntree_limit` is deprecated, use `iteration_range` instead.\n"
          ]
        }
      ],
      "source": [
        "modelXgboostTreeTest <- train(\n",
        "  C_yF ~ C_poutcome + C_month:B_pdays,\n",
        "  data = samp_i,\n",
        "  method = \"xgbTree\",\n",
        "  tuneLength = 2,\n",
        "#  trControl = myTrainingControl,\n",
        "#  metric=\"Sens\"\n",
        "  )\n",
        "\n",
        " modelXgboostTreeTest_out_result <- predict(modelXgboostTreeTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q1eYtksnoRt4",
        "outputId": "5dce1440-3ae5-493b-b4ad-77cb488fc38f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><td>0.7384978</td><td>0.26150221</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.2476192</td><td>0.75238079</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.6936676</td><td>0.30633241</td></tr>\n",
              "\t<tr><td>0.6349288</td><td>0.36507124</td></tr>\n",
              "\t<tr><td>0.3733211</td><td>0.62667885</td></tr>\n",
              "\t<tr><td>0.9372003</td><td>0.06279969</td></tr>\n",
              "\t<tr><td>0.9372003</td><td>0.06279969</td></tr>\n",
              "\t<tr><td>0.9147828</td><td>0.08521718</td></tr>\n",
              "\t<tr><td>0.2476192</td><td>0.75238079</td></tr>\n",
              "\t<tr><td>0.8363792</td><td>0.16362083</td></tr>\n",
              "\t<tr><td>0.8926205</td><td>0.10737950</td></tr>\n",
              "\t<tr><td>0.6349288</td><td>0.36507124</td></tr>\n",
              "\t<tr><td>0.2476192</td><td>0.75238079</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.7384978</td><td>0.26150221</td></tr>\n",
              "\t<tr><td>0.6349288</td><td>0.36507124</td></tr>\n",
              "\t<tr><td>0.9372003</td><td>0.06279969</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9228770</td><td>0.07712305</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.6349288</td><td>0.36507124</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.8926205</td><td>0.10737950</td></tr>\n",
              "\t<tr><td>0.9057794</td><td>0.09422058</td></tr>\n",
              "\t<tr><td>0.6349288</td><td>0.36507124</td></tr>\n",
              "\t<tr><td>0.9228770</td><td>0.07712305</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{ll}\n 0 & 1\\\\\n <dbl> & <dbl>\\\\\n\\hline\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t ⋮ & ⋮\\\\\n\t 0.7384978 & 0.26150221\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.2476192 & 0.75238079\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.6936676 & 0.30633241\\\\\n\t 0.6349288 & 0.36507124\\\\\n\t 0.3733211 & 0.62667885\\\\\n\t 0.9372003 & 0.06279969\\\\\n\t 0.9372003 & 0.06279969\\\\\n\t 0.9147828 & 0.08521718\\\\\n\t 0.2476192 & 0.75238079\\\\\n\t 0.8363792 & 0.16362083\\\\\n\t 0.8926205 & 0.10737950\\\\\n\t 0.6349288 & 0.36507124\\\\\n\t 0.2476192 & 0.75238079\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.7384978 & 0.26150221\\\\\n\t 0.6349288 & 0.36507124\\\\\n\t 0.9372003 & 0.06279969\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9228770 & 0.07712305\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.6349288 & 0.36507124\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.8926205 & 0.10737950\\\\\n\t 0.9057794 & 0.09422058\\\\\n\t 0.6349288 & 0.36507124\\\\\n\t 0.9228770 & 0.07712305\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| 0 &lt;dbl&gt; | 1 &lt;dbl&gt; |\n|---|---|\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| ⋮ | ⋮ |\n| 0.7384978 | 0.26150221 |\n| 0.9057794 | 0.09422058 |\n| 0.2476192 | 0.75238079 |\n| 0.9057794 | 0.09422058 |\n| 0.6936676 | 0.30633241 |\n| 0.6349288 | 0.36507124 |\n| 0.3733211 | 0.62667885 |\n| 0.9372003 | 0.06279969 |\n| 0.9372003 | 0.06279969 |\n| 0.9147828 | 0.08521718 |\n| 0.2476192 | 0.75238079 |\n| 0.8363792 | 0.16362083 |\n| 0.8926205 | 0.10737950 |\n| 0.6349288 | 0.36507124 |\n| 0.2476192 | 0.75238079 |\n| 0.9057794 | 0.09422058 |\n| 0.7384978 | 0.26150221 |\n| 0.6349288 | 0.36507124 |\n| 0.9372003 | 0.06279969 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.9228770 | 0.07712305 |\n| 0.9057794 | 0.09422058 |\n| 0.6349288 | 0.36507124 |\n| 0.9057794 | 0.09422058 |\n| 0.9057794 | 0.09422058 |\n| 0.8926205 | 0.10737950 |\n| 0.9057794 | 0.09422058 |\n| 0.6349288 | 0.36507124 |\n| 0.9228770 | 0.07712305 |\n\n",
            "text/plain": [
              "      0         1         \n",
              "1     0.9057794 0.09422058\n",
              "2     0.9057794 0.09422058\n",
              "3     0.9057794 0.09422058\n",
              "4     0.9057794 0.09422058\n",
              "5     0.9057794 0.09422058\n",
              "6     0.9057794 0.09422058\n",
              "7     0.9057794 0.09422058\n",
              "8     0.9057794 0.09422058\n",
              "9     0.9057794 0.09422058\n",
              "10    0.9057794 0.09422058\n",
              "11    0.9057794 0.09422058\n",
              "12    0.9057794 0.09422058\n",
              "13    0.9057794 0.09422058\n",
              "14    0.9057794 0.09422058\n",
              "15    0.9057794 0.09422058\n",
              "16    0.9057794 0.09422058\n",
              "17    0.9057794 0.09422058\n",
              "18    0.9057794 0.09422058\n",
              "19    0.9057794 0.09422058\n",
              "20    0.9057794 0.09422058\n",
              "21    0.9057794 0.09422058\n",
              "22    0.9057794 0.09422058\n",
              "23    0.9057794 0.09422058\n",
              "24    0.9057794 0.09422058\n",
              "25    0.9057794 0.09422058\n",
              "26    0.9057794 0.09422058\n",
              "27    0.9057794 0.09422058\n",
              "28    0.9057794 0.09422058\n",
              "29    0.9057794 0.09422058\n",
              "30    0.9057794 0.09422058\n",
              "⋮     ⋮         ⋮         \n",
              "22576 0.7384978 0.26150221\n",
              "22577 0.9057794 0.09422058\n",
              "22578 0.2476192 0.75238079\n",
              "22579 0.9057794 0.09422058\n",
              "22580 0.6936676 0.30633241\n",
              "22581 0.6349288 0.36507124\n",
              "22582 0.3733211 0.62667885\n",
              "22583 0.9372003 0.06279969\n",
              "22584 0.9372003 0.06279969\n",
              "22585 0.9147828 0.08521718\n",
              "22586 0.2476192 0.75238079\n",
              "22587 0.8363792 0.16362083\n",
              "22588 0.8926205 0.10737950\n",
              "22589 0.6349288 0.36507124\n",
              "22590 0.2476192 0.75238079\n",
              "22591 0.9057794 0.09422058\n",
              "22592 0.7384978 0.26150221\n",
              "22593 0.6349288 0.36507124\n",
              "22594 0.9372003 0.06279969\n",
              "22595 0.9057794 0.09422058\n",
              "22596 0.9057794 0.09422058\n",
              "22597 0.9228770 0.07712305\n",
              "22598 0.9057794 0.09422058\n",
              "22599 0.6349288 0.36507124\n",
              "22600 0.9057794 0.09422058\n",
              "22601 0.9057794 0.09422058\n",
              "22602 0.8926205 0.10737950\n",
              "22603 0.9057794 0.09422058\n",
              "22604 0.6349288 0.36507124\n",
              "22605 0.9228770 0.07712305"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelXgboostTreeTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "E1acumuSOZcD",
        "outputId": "9494173c-6c58-4c16-dc6a-737c61b7c721"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "28.0400506403523"
            ],
            "text/latex": "28.0400506403523",
            "text/markdown": "28.0400506403523",
            "text/plain": [
              "[1] 28.04005"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelXgboostTreeTest_out_result_data <- data.frame(samp_o,predict(modelXgboostTreeTest,samp_o,type=\"prob\"))\n",
        "write.table(modelXgboostTreeTest_out_result_data, file = \"/content/modelXgboostTreeTest_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelXgboostTreeTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelXgboostTreeTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGibYbQmZqN7"
      },
      "source": [
        "## 99-3-3.precitテスト_SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM6z8ovjoudq",
        "outputId": "003f4fcf-37a5-4fc3-fb3a-6f2d453b791f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "line search fails -1.700877 0.5525292 1.467667e-05 1.394695e-05 -6.619439e-08 -6.457041e-08 -1.872074e-12"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in method$predict(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class prediction calculations failed; returning NAs”\n",
            "Warning message in method$prob(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class probability calculations failed; returning NAs”\n",
            "Warning message in data.frame(..., check.names = FALSE):\n",
            "“row names were found from a short variable and have been discarded”\n",
            "Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”\n",
            "Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”\n",
            "Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "line search fails -1.927894 0.2826865 1.548476e-05 -1.529824e-05 -6.064051e-09 1.829515e-09 -1.218887e-13"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in method$predict(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class prediction calculations failed; returning NAs”\n",
            "Warning message in method$prob(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class probability calculations failed; returning NAs”\n",
            "Warning message in data.frame(..., check.names = FALSE):\n",
            "“row names were found from a short variable and have been discarded”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "line search fails -1.639627 0.5779993 1.496559e-05 1.442221e-05 -5.674069e-08 -5.574376e-08 -1.653106e-12"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in method$predict(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class prediction calculations failed; returning NAs”\n",
            "Warning message in method$prob(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class probability calculations failed; returning NAs”\n",
            "Warning message in data.frame(..., check.names = FALSE):\n",
            "“row names were found from a short variable and have been discarded”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "line search fails -1.864012 0.3479001 1.474525e-05 1.412889e-05 -8.686692e-08 -8.470203e-08 -2.47762e-12"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in method$predict(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class prediction calculations failed; returning NAs”\n",
            "Warning message in method$prob(modelFit = modelFit, newdata = newdata, submodels = param):\n",
            "“kernlab class probability calculations failed; returning NAs”\n",
            "Warning message in data.frame(..., check.names = FALSE):\n",
            "“row names were found from a short variable and have been discarded”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n"
          ]
        }
      ],
      "source": [
        "modelSVMTest <- train(\n",
        "  C_y ~ C_poutcome + C_month:B_pdays,\n",
        "  data = samp_i,\n",
        "  method = \"svmRadial\",\n",
        "  trControl = trainControl(classProbs =  TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdP1NS5HJ4tz"
      },
      "outputs": [],
      "source": [
        "modelSVMTest_out_result <- predict(modelSVMTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X2g_v88dKbNY",
        "outputId": "8e2f20ba-f094-4dd0-fd9e-e9e955e5e12f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>no</th><th scope=col>yes</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><td>0.8999131</td><td>0.10008689</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.2438733</td><td>0.75612667</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000684</td><td>0.09993162</td></tr>\n",
              "\t<tr><td>0.9001559</td><td>0.09984415</td></tr>\n",
              "\t<tr><td>0.7885354</td><td>0.21146462</td></tr>\n",
              "\t<tr><td>0.9000994</td><td>0.09990059</td></tr>\n",
              "\t<tr><td>0.9000994</td><td>0.09990059</td></tr>\n",
              "\t<tr><td>0.9001335</td><td>0.09986649</td></tr>\n",
              "\t<tr><td>0.2277135</td><td>0.77228646</td></tr>\n",
              "\t<tr><td>0.9001113</td><td>0.09988866</td></tr>\n",
              "\t<tr><td>0.7696627</td><td>0.23033729</td></tr>\n",
              "\t<tr><td>0.9001559</td><td>0.09984415</td></tr>\n",
              "\t<tr><td>0.2277135</td><td>0.77228646</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.8999131</td><td>0.10008689</td></tr>\n",
              "\t<tr><td>0.9001559</td><td>0.09984415</td></tr>\n",
              "\t<tr><td>0.9000994</td><td>0.09990059</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9001330</td><td>0.09986702</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9001559</td><td>0.09984415</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.6904024</td><td>0.30959763</td></tr>\n",
              "\t<tr><td>0.9000961</td><td>0.09990395</td></tr>\n",
              "\t<tr><td>0.9001559</td><td>0.09984415</td></tr>\n",
              "\t<tr><td>0.9001330</td><td>0.09986702</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{ll}\n no & yes\\\\\n <dbl> & <dbl>\\\\\n\\hline\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t ⋮ & ⋮\\\\\n\t 0.8999131 & 0.10008689\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.2438733 & 0.75612667\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000684 & 0.09993162\\\\\n\t 0.9001559 & 0.09984415\\\\\n\t 0.7885354 & 0.21146462\\\\\n\t 0.9000994 & 0.09990059\\\\\n\t 0.9000994 & 0.09990059\\\\\n\t 0.9001335 & 0.09986649\\\\\n\t 0.2277135 & 0.77228646\\\\\n\t 0.9001113 & 0.09988866\\\\\n\t 0.7696627 & 0.23033729\\\\\n\t 0.9001559 & 0.09984415\\\\\n\t 0.2277135 & 0.77228646\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.8999131 & 0.10008689\\\\\n\t 0.9001559 & 0.09984415\\\\\n\t 0.9000994 & 0.09990059\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9001330 & 0.09986702\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9001559 & 0.09984415\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.6904024 & 0.30959763\\\\\n\t 0.9000961 & 0.09990395\\\\\n\t 0.9001559 & 0.09984415\\\\\n\t 0.9001330 & 0.09986702\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| no &lt;dbl&gt; | yes &lt;dbl&gt; |\n|---|---|\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| ⋮ | ⋮ |\n| 0.8999131 | 0.10008689 |\n| 0.9000961 | 0.09990395 |\n| 0.2438733 | 0.75612667 |\n| 0.9000961 | 0.09990395 |\n| 0.9000684 | 0.09993162 |\n| 0.9001559 | 0.09984415 |\n| 0.7885354 | 0.21146462 |\n| 0.9000994 | 0.09990059 |\n| 0.9000994 | 0.09990059 |\n| 0.9001335 | 0.09986649 |\n| 0.2277135 | 0.77228646 |\n| 0.9001113 | 0.09988866 |\n| 0.7696627 | 0.23033729 |\n| 0.9001559 | 0.09984415 |\n| 0.2277135 | 0.77228646 |\n| 0.9000961 | 0.09990395 |\n| 0.8999131 | 0.10008689 |\n| 0.9001559 | 0.09984415 |\n| 0.9000994 | 0.09990059 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.9001330 | 0.09986702 |\n| 0.9000961 | 0.09990395 |\n| 0.9001559 | 0.09984415 |\n| 0.9000961 | 0.09990395 |\n| 0.9000961 | 0.09990395 |\n| 0.6904024 | 0.30959763 |\n| 0.9000961 | 0.09990395 |\n| 0.9001559 | 0.09984415 |\n| 0.9001330 | 0.09986702 |\n\n",
            "text/plain": [
              "      no        yes       \n",
              "1     0.9000961 0.09990395\n",
              "2     0.9000961 0.09990395\n",
              "3     0.9000961 0.09990395\n",
              "4     0.9000961 0.09990395\n",
              "5     0.9000961 0.09990395\n",
              "6     0.9000961 0.09990395\n",
              "7     0.9000961 0.09990395\n",
              "8     0.9000961 0.09990395\n",
              "9     0.9000961 0.09990395\n",
              "10    0.9000961 0.09990395\n",
              "11    0.9000961 0.09990395\n",
              "12    0.9000961 0.09990395\n",
              "13    0.9000961 0.09990395\n",
              "14    0.9000961 0.09990395\n",
              "15    0.9000961 0.09990395\n",
              "16    0.9000961 0.09990395\n",
              "17    0.9000961 0.09990395\n",
              "18    0.9000961 0.09990395\n",
              "19    0.9000961 0.09990395\n",
              "20    0.9000961 0.09990395\n",
              "21    0.9000961 0.09990395\n",
              "22    0.9000961 0.09990395\n",
              "23    0.9000961 0.09990395\n",
              "24    0.9000961 0.09990395\n",
              "25    0.9000961 0.09990395\n",
              "26    0.9000961 0.09990395\n",
              "27    0.9000961 0.09990395\n",
              "28    0.9000961 0.09990395\n",
              "29    0.9000961 0.09990395\n",
              "30    0.9000961 0.09990395\n",
              "⋮     ⋮         ⋮         \n",
              "22576 0.8999131 0.10008689\n",
              "22577 0.9000961 0.09990395\n",
              "22578 0.2438733 0.75612667\n",
              "22579 0.9000961 0.09990395\n",
              "22580 0.9000684 0.09993162\n",
              "22581 0.9001559 0.09984415\n",
              "22582 0.7885354 0.21146462\n",
              "22583 0.9000994 0.09990059\n",
              "22584 0.9000994 0.09990059\n",
              "22585 0.9001335 0.09986649\n",
              "22586 0.2277135 0.77228646\n",
              "22587 0.9001113 0.09988866\n",
              "22588 0.7696627 0.23033729\n",
              "22589 0.9001559 0.09984415\n",
              "22590 0.2277135 0.77228646\n",
              "22591 0.9000961 0.09990395\n",
              "22592 0.8999131 0.10008689\n",
              "22593 0.9001559 0.09984415\n",
              "22594 0.9000994 0.09990059\n",
              "22595 0.9000961 0.09990395\n",
              "22596 0.9000961 0.09990395\n",
              "22597 0.9001330 0.09986702\n",
              "22598 0.9000961 0.09990395\n",
              "22599 0.9001559 0.09984415\n",
              "22600 0.9000961 0.09990395\n",
              "22601 0.9000961 0.09990395\n",
              "22602 0.6904024 0.30959763\n",
              "22603 0.9000961 0.09990395\n",
              "22604 0.9001559 0.09984415\n",
              "22605 0.9001330 0.09986702"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelSVMTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8rUvxN7DP5xk",
        "outputId": "e0a0c717-1713-4128-c662-d29937773a1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "19.6752616164303"
            ],
            "text/latex": "19.6752616164303",
            "text/markdown": "19.6752616164303",
            "text/plain": [
              "[1] 19.67526"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelSVMTest_out_result_data <- data.frame(samp_o,predict(modelSVMTest,samp_o,type=\"prob\"))\n",
        "write.table(modelSVMTest_out_result_data, file = \"/content/modelSVMTest_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelSVMTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"yes\"\n",
        "sortPred <- modelSVMTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39HLO2X4-_re"
      },
      "source": [
        "## 99-3-4.モデル作成（ニューラルネットワーク）_ハイパーパラメータ調整"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bslmnqhe-_rf",
        "outputId": "05e5ea9b-ea22-47f8-a930-2fb8e83a5341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18049.026133 \n",
            "iter  10 value 7859.992907\n",
            "iter  20 value 7454.798877\n",
            "iter  30 value 6961.562129\n",
            "iter  40 value 6628.482926\n",
            "iter  50 value 6390.376222\n",
            "iter  60 value 6204.875159\n",
            "iter  70 value 6089.089668\n",
            "iter  80 value 5988.986513\n",
            "iter  90 value 5880.348126\n",
            "iter 100 value 5778.560756\n",
            "final  value 5778.560756 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12484.077024 \n",
            "iter  10 value 8181.237127\n",
            "iter  20 value 6801.156636\n",
            "iter  30 value 6391.092373\n",
            "iter  40 value 6166.603942\n",
            "iter  50 value 6092.669347\n",
            "iter  60 value 6052.118921\n",
            "iter  70 value 6030.516958\n",
            "iter  80 value 6006.751771\n",
            "iter  90 value 5985.494592\n",
            "iter 100 value 5969.467058\n",
            "final  value 5969.467058 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample01: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19339.122402 \n",
            "final  value 8229.289016 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13756.099717 \n",
            "iter  10 value 7437.654520\n",
            "iter  20 value 6983.467109\n",
            "iter  30 value 6770.196626\n",
            "iter  40 value 6599.436867\n",
            "iter  50 value 6400.984644\n",
            "iter  60 value 6281.950359\n",
            "iter  70 value 6150.332749\n",
            "iter  80 value 6081.556748\n",
            "iter  90 value 6018.098083\n",
            "iter 100 value 5956.016344\n",
            "final  value 5956.016344 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample02: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20675.015955 \n",
            "final  value 8152.746193 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12579.740588 \n",
            "iter  10 value 7783.257118\n",
            "iter  20 value 6979.894673\n",
            "iter  30 value 6464.246156\n",
            "iter  40 value 6337.959673\n",
            "iter  50 value 6256.701592\n",
            "iter  60 value 6190.674358\n",
            "iter  70 value 6112.719134\n",
            "iter  80 value 6046.232051\n",
            "iter  90 value 5942.599976\n",
            "iter 100 value 5873.419839\n",
            "final  value 5873.419839 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample03: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15061.529845 \n",
            "iter  10 value 8303.235769\n",
            "final  value 8303.226539 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10943.505429 \n",
            "iter  10 value 7362.263713\n",
            "iter  20 value 6722.328633\n",
            "iter  30 value 6513.434360\n",
            "iter  40 value 6387.545460\n",
            "iter  50 value 6310.445205\n",
            "iter  60 value 6241.928526\n",
            "iter  70 value 6136.235807\n",
            "iter  80 value 6039.177178\n",
            "iter  90 value 5988.869348\n",
            "iter 100 value 5950.669921\n",
            "final  value 5950.669921 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample04: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16222.942623 \n",
            "iter  10 value 7966.840116\n",
            "iter  20 value 6711.665692\n",
            "iter  30 value 6282.419697\n",
            "iter  40 value 6043.251280\n",
            "iter  50 value 5899.419585\n",
            "iter  60 value 5779.372296\n",
            "iter  70 value 5708.473849\n",
            "iter  80 value 5643.315549\n",
            "iter  90 value 5589.164338\n",
            "iter 100 value 5565.150908\n",
            "final  value 5565.150908 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14714.111929 \n",
            "iter  10 value 8160.534923\n",
            "iter  20 value 7454.479733\n",
            "iter  30 value 7114.075022\n",
            "iter  40 value 6578.966898\n",
            "iter  50 value 6451.117382\n",
            "iter  60 value 6385.179885\n",
            "iter  70 value 6346.944534\n",
            "iter  80 value 6285.735126\n",
            "iter  90 value 6253.783024\n",
            "iter 100 value 6232.882223\n",
            "final  value 6232.882223 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample05: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15992.492731 \n",
            "iter  10 value 8008.280144\n",
            "iter  20 value 7122.192130\n",
            "iter  30 value 6458.991985\n",
            "iter  40 value 6209.442200\n",
            "iter  50 value 5987.809047\n",
            "iter  60 value 5830.411853\n",
            "iter  70 value 5719.208438\n",
            "iter  80 value 5625.384367\n",
            "iter  90 value 5531.545086\n",
            "iter 100 value 5460.628426\n",
            "final  value 5460.628426 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 17583.777415 \n",
            "iter  10 value 8420.330929\n",
            "iter  20 value 7963.088853\n",
            "iter  30 value 7448.998416\n",
            "iter  40 value 7045.772929\n",
            "iter  50 value 6793.712775\n",
            "iter  60 value 6607.045887\n",
            "iter  70 value 6449.468083\n",
            "iter  80 value 6332.358188\n",
            "iter  90 value 6222.352679\n",
            "iter 100 value 6127.517448\n",
            "final  value 6127.517448 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample06: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14033.987213 \n",
            "iter  10 value 7149.395459\n",
            "iter  20 value 6394.851016\n",
            "iter  30 value 6103.048127\n",
            "iter  40 value 5997.647162\n",
            "iter  50 value 5919.592563\n",
            "iter  60 value 5852.647826\n",
            "iter  70 value 5779.854533\n",
            "iter  80 value 5743.597243\n",
            "iter  90 value 5722.657619\n",
            "iter 100 value 5718.226982\n",
            "final  value 5718.226982 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11793.387192 \n",
            "iter  10 value 7996.524004\n",
            "iter  20 value 6924.585488\n",
            "iter  30 value 6386.773489\n",
            "iter  40 value 6213.167738\n",
            "iter  50 value 6105.386715\n",
            "iter  60 value 6014.966776\n",
            "iter  70 value 5934.679969\n",
            "iter  80 value 5859.629026\n",
            "iter  90 value 5781.164871\n",
            "iter 100 value 5728.589317\n",
            "final  value 5728.589317 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample07: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12221.399692 \n",
            "iter  10 value 7365.247861\n",
            "iter  20 value 6568.387845\n",
            "iter  30 value 6265.674519\n",
            "iter  40 value 6105.741438\n",
            "iter  50 value 6015.438750\n",
            "iter  60 value 5926.840610\n",
            "iter  70 value 5836.949933\n",
            "iter  80 value 5774.729131\n",
            "iter  90 value 5761.549167\n",
            "iter 100 value 5759.409343\n",
            "final  value 5759.409343 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10688.208883 \n",
            "iter  10 value 7978.050289\n",
            "iter  20 value 7298.598551\n",
            "iter  30 value 6704.080777\n",
            "iter  40 value 6413.589186\n",
            "iter  50 value 6282.609534\n",
            "iter  60 value 6196.693247\n",
            "iter  70 value 6126.134079\n",
            "iter  80 value 6062.343031\n",
            "iter  90 value 6014.993549\n",
            "iter 100 value 5980.137964\n",
            "final  value 5980.137964 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample08: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12632.989951 \n",
            "final  value 8038.814869 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16628.410683 \n",
            "iter  10 value 7463.117858\n",
            "iter  20 value 6935.231242\n",
            "iter  30 value 6583.168554\n",
            "iter  40 value 6322.820467\n",
            "iter  50 value 6175.760195\n",
            "iter  60 value 6108.273145\n",
            "iter  70 value 6074.081294\n",
            "iter  80 value 6037.220170\n",
            "iter  90 value 6006.237055\n",
            "iter 100 value 5993.311709\n",
            "final  value 5993.311709 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample09: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13127.011904 \n",
            "iter  10 value 7300.160117\n",
            "iter  20 value 6657.299200\n",
            "iter  30 value 6299.387062\n",
            "iter  40 value 6017.098868\n",
            "iter  50 value 5849.281402\n",
            "iter  60 value 5746.929600\n",
            "iter  70 value 5662.756380\n",
            "iter  80 value 5549.281530\n",
            "iter  90 value 5430.888523\n",
            "iter 100 value 5272.707536\n",
            "final  value 5272.707536 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11220.125910 \n",
            "iter  10 value 7401.243312\n",
            "iter  20 value 6787.279628\n",
            "iter  30 value 6562.416977\n",
            "iter  40 value 6404.633842\n",
            "iter  50 value 6325.467463\n",
            "iter  60 value 6248.506214\n",
            "iter  70 value 6153.281807\n",
            "iter  80 value 6068.892959\n",
            "iter  90 value 6030.099566\n",
            "iter 100 value 5994.299681\n",
            "final  value 5994.299681 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample10: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10489.845044 \n",
            "iter  10 value 7034.987117\n",
            "iter  20 value 6229.872432\n",
            "iter  30 value 5973.686513\n",
            "iter  40 value 5826.507833\n",
            "iter  50 value 5700.882227\n",
            "iter  60 value 5597.658587\n",
            "iter  70 value 5482.131691\n",
            "iter  80 value 5377.348414\n",
            "iter  90 value 5243.951701\n",
            "iter 100 value 5166.225448\n",
            "final  value 5166.225448 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13683.793271 \n",
            "iter  10 value 8074.270772\n",
            "iter  20 value 6864.648957\n",
            "iter  30 value 6393.179020\n",
            "iter  40 value 6229.975936\n",
            "iter  50 value 6107.301948\n",
            "iter  60 value 6022.641190\n",
            "iter  70 value 5973.847458\n",
            "iter  80 value 5936.828884\n",
            "iter  90 value 5914.624338\n",
            "iter 100 value 5898.605267\n",
            "final  value 5898.605267 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample11: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19909.114447 \n",
            "iter  10 value 8069.255877\n",
            "iter  20 value 7741.090789\n",
            "iter  30 value 7360.762841\n",
            "iter  40 value 7080.124630\n",
            "iter  50 value 6785.412645\n",
            "iter  60 value 6614.585616\n",
            "iter  70 value 6469.964990\n",
            "iter  80 value 6343.053602\n",
            "iter  90 value 6251.501387\n",
            "iter 100 value 6149.042130\n",
            "final  value 6149.042130 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15662.959220 \n",
            "iter  10 value 8197.367937\n",
            "iter  20 value 7269.327968\n",
            "iter  30 value 6603.592608\n",
            "iter  40 value 6300.032497\n",
            "iter  50 value 6174.553404\n",
            "iter  60 value 6131.591914\n",
            "iter  70 value 6113.427125\n",
            "iter  80 value 6098.692397\n",
            "iter  90 value 6078.367215\n",
            "iter 100 value 6056.726565\n",
            "final  value 6056.726565 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample12: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13577.348518 \n",
            "iter  10 value 8140.527995\n",
            "iter  20 value 7550.177394\n",
            "iter  30 value 6740.293139\n",
            "iter  40 value 6409.125646\n",
            "iter  50 value 6220.061053\n",
            "iter  60 value 6104.157934\n",
            "iter  70 value 6019.186125\n",
            "iter  80 value 5926.610939\n",
            "iter  90 value 5854.930271\n",
            "iter 100 value 5839.563638\n",
            "final  value 5839.563638 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12145.550843 \n",
            "iter  10 value 7779.317667\n",
            "iter  20 value 7389.988162\n",
            "iter  30 value 6934.188153\n",
            "iter  40 value 6589.279184\n",
            "iter  50 value 6323.276400\n",
            "iter  60 value 6199.270632\n",
            "iter  70 value 6131.602308\n",
            "iter  80 value 6088.921018\n",
            "iter  90 value 6044.106952\n",
            "iter 100 value 6008.543731\n",
            "final  value 6008.543731 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample13: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11000.010064 \n",
            "iter  10 value 7405.638347\n",
            "iter  20 value 6652.058090\n",
            "iter  30 value 6347.330360\n",
            "iter  40 value 6090.408506\n",
            "iter  50 value 5933.351050\n",
            "iter  60 value 5817.090339\n",
            "iter  70 value 5701.572485\n",
            "iter  80 value 5591.443147\n",
            "iter  90 value 5477.583662\n",
            "iter 100 value 5441.300481\n",
            "final  value 5441.300481 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 21331.314803 \n",
            "iter  10 value 8148.885410\n",
            "iter  20 value 7329.987036\n",
            "iter  30 value 6698.391471\n",
            "iter  40 value 6433.408461\n",
            "iter  50 value 6306.571990\n",
            "iter  60 value 6229.630022\n",
            "iter  70 value 6167.876707\n",
            "iter  80 value 6115.093174\n",
            "iter  90 value 6062.548192\n",
            "iter 100 value 6016.921953\n",
            "final  value 6016.921953 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample14: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19053.181258 \n",
            "final  value 8225.275749 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14296.694469 \n",
            "iter  10 value 8229.283837\n",
            "iter  20 value 7249.968724\n",
            "iter  30 value 6649.893412\n",
            "iter  40 value 6365.347358\n",
            "iter  50 value 6196.947200\n",
            "iter  60 value 6137.879600\n",
            "iter  70 value 6106.263750\n",
            "iter  80 value 6081.172824\n",
            "iter  90 value 6040.019347\n",
            "iter 100 value 5993.544790\n",
            "final  value 5993.544790 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample15: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 26362.419733 \n",
            "final  value 8049.043550 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 23143.604291 \n",
            "iter  10 value 8056.846566\n",
            "iter  20 value 7774.612910\n",
            "iter  30 value 7289.140119\n",
            "iter  40 value 6836.315985\n",
            "iter  50 value 6550.970280\n",
            "iter  60 value 6212.780933\n",
            "iter  70 value 6017.808203\n",
            "iter  80 value 5923.152304\n",
            "iter  90 value 5880.258051\n",
            "iter 100 value 5857.444746\n",
            "final  value 5857.444746 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample16: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11160.168504 \n",
            "iter  10 value 7114.413156\n",
            "iter  20 value 6716.077198\n",
            "iter  30 value 6466.065519\n",
            "iter  40 value 6324.408994\n",
            "iter  50 value 6216.679456\n",
            "iter  60 value 6151.942052\n",
            "iter  70 value 6092.757269\n",
            "iter  80 value 6037.796041\n",
            "iter  90 value 5986.277555\n",
            "iter 100 value 5964.886707\n",
            "final  value 5964.886707 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 20869.484067 \n",
            "iter  10 value 8171.227703\n",
            "iter  20 value 7603.114252\n",
            "iter  30 value 6683.961363\n",
            "iter  40 value 6358.848030\n",
            "iter  50 value 6153.440422\n",
            "iter  60 value 6088.161960\n",
            "iter  70 value 6065.064035\n",
            "iter  80 value 6047.174999\n",
            "iter  90 value 6030.441021\n",
            "iter 100 value 6001.908226\n",
            "final  value 6001.908226 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample17: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12822.907374 \n",
            "iter  10 value 7241.909685\n",
            "iter  20 value 6712.679113\n",
            "iter  30 value 6406.116620\n",
            "iter  40 value 6297.892518\n",
            "iter  50 value 6209.931370\n",
            "iter  60 value 6151.627322\n",
            "iter  70 value 6105.178920\n",
            "iter  80 value 6059.633782\n",
            "iter  90 value 6030.218531\n",
            "iter 100 value 6016.980635\n",
            "final  value 6016.980635 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10543.868668 \n",
            "iter  10 value 7151.647004\n",
            "iter  20 value 6691.618733\n",
            "iter  30 value 6529.735021\n",
            "iter  40 value 6414.297796\n",
            "iter  50 value 6303.379016\n",
            "iter  60 value 6225.765911\n",
            "iter  70 value 6174.971636\n",
            "iter  80 value 6136.338065\n",
            "iter  90 value 6099.925987\n",
            "iter 100 value 6043.824601\n",
            "final  value 6043.824601 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample18: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19836.799319 \n",
            "final  value 7956.599910 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 16389.855636 \n",
            "iter  10 value 7969.086084\n",
            "iter  20 value 7748.647840\n",
            "iter  30 value 7247.479303\n",
            "iter  40 value 7018.314804\n",
            "iter  50 value 6885.520605\n",
            "iter  60 value 6790.111700\n",
            "iter  70 value 6342.607874\n",
            "iter  80 value 6138.823271\n",
            "iter  90 value 5992.864140\n",
            "iter 100 value 5913.819116\n",
            "final  value 5913.819116 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample19: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15042.026516 \n",
            "iter  10 value 7662.298187\n",
            "iter  20 value 6859.088651\n",
            "iter  30 value 6386.866187\n",
            "iter  40 value 6196.414096\n",
            "iter  50 value 6089.551280\n",
            "iter  60 value 5994.673667\n",
            "iter  70 value 5904.518457\n",
            "iter  80 value 5798.978472\n",
            "iter  90 value 5722.772278\n",
            "iter 100 value 5684.417710\n",
            "final  value 5684.417710 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 19944.821261 \n",
            "iter  10 value 8251.728581\n",
            "iter  20 value 7643.386894\n",
            "iter  30 value 7311.523060\n",
            "iter  40 value 6936.839069\n",
            "iter  50 value 6610.121234\n",
            "iter  60 value 6417.386264\n",
            "iter  70 value 6320.673335\n",
            "iter  80 value 6258.878679\n",
            "iter  90 value 6214.804621\n",
            "iter 100 value 6183.717589\n",
            "final  value 6183.717589 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample20: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 12447.035074 \n",
            "final  value 8179.001156 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14766.697435 \n",
            "iter  10 value 6833.285312\n",
            "iter  20 value 6433.356914\n",
            "iter  30 value 6208.463441\n",
            "iter  40 value 6113.812413\n",
            "iter  50 value 6046.511317\n",
            "iter  60 value 5995.427427\n",
            "iter  70 value 5947.867596\n",
            "iter  80 value 5908.817999\n",
            "iter  90 value 5881.647885\n",
            "iter 100 value 5859.371235\n",
            "final  value 5859.371235 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample21: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11516.502475 \n",
            "final  value 7979.279731 \n",
            "converged\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18385.625761 \n",
            "iter  10 value 7987.002918\n",
            "iter  20 value 7385.030251\n",
            "iter  30 value 6472.855398\n",
            "iter  40 value 6255.483711\n",
            "iter  50 value 6180.479429\n",
            "iter  60 value 6133.398008\n",
            "iter  70 value 6085.687607\n",
            "iter  80 value 6039.562587\n",
            "iter  90 value 5979.798902\n",
            "iter 100 value 5941.219766\n",
            "final  value 5941.219766 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample22: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 15267.225752 \n",
            "iter  10 value 8084.247878\n",
            "iter  20 value 7711.674829\n",
            "iter  30 value 7440.773823\n",
            "iter  40 value 7059.280808\n",
            "iter  50 value 6727.076749\n",
            "iter  60 value 6512.347296\n",
            "iter  70 value 6301.849090\n",
            "iter  80 value 6153.586366\n",
            "iter  90 value 5994.093066\n",
            "iter 100 value 5877.951745\n",
            "final  value 5877.951745 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 10649.663636 \n",
            "iter  10 value 8183.380005\n",
            "iter  20 value 7156.169599\n",
            "iter  30 value 6601.198115\n",
            "iter  40 value 6389.051096\n",
            "iter  50 value 6293.251749\n",
            "iter  60 value 6247.701925\n",
            "iter  70 value 6206.656255\n",
            "iter  80 value 6167.609752\n",
            "iter  90 value 6143.869905\n",
            "iter 100 value 6117.988732\n",
            "final  value 6117.988732 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample23: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 18872.012766 \n",
            "iter  10 value 8034.238602\n",
            "iter  20 value 6727.968608\n",
            "iter  30 value 6275.049647\n",
            "iter  40 value 5941.104502\n",
            "iter  50 value 5777.706613\n",
            "iter  60 value 5668.987208\n",
            "iter  70 value 5564.821272\n",
            "iter  80 value 5460.396284\n",
            "iter  90 value 5310.776215\n",
            "iter 100 value 5152.940596\n",
            "final  value 5152.940596 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13780.099659 \n",
            "iter  10 value 8076.203370\n",
            "iter  20 value 7667.276852\n",
            "iter  30 value 6800.177973\n",
            "iter  40 value 6462.303384\n",
            "iter  50 value 6271.381387\n",
            "iter  60 value 6122.857490\n",
            "iter  70 value 6031.324034\n",
            "iter  80 value 5922.905302\n",
            "iter  90 value 5868.216452\n",
            "iter 100 value 5836.145703\n",
            "final  value 5836.145703 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample24: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 13382.374391 \n",
            "iter  10 value 7470.340412\n",
            "iter  20 value 7133.895207\n",
            "iter  30 value 6829.580331\n",
            "iter  40 value 6687.288952\n",
            "iter  50 value 6556.909088\n",
            "iter  60 value 6398.025022\n",
            "iter  70 value 6205.785095\n",
            "iter  80 value 6071.584529\n",
            "iter  90 value 6020.406668\n",
            "iter 100 value 6011.651954\n",
            "final  value 6011.651954 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.0 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 11869.228222 \n",
            "iter  10 value 7452.869710\n",
            "iter  20 value 7227.821958\n",
            "iter  30 value 6943.345567\n",
            "iter  40 value 6377.175476\n",
            "iter  50 value 6030.837792\n",
            "iter  60 value 5896.125869\n",
            "iter  70 value 5811.547164\n",
            "iter  80 value 5778.368639\n",
            "iter  90 value 5762.808503\n",
            "iter 100 value 5756.726259\n",
            "final  value 5756.726259 \n",
            "stopped after 100 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“model fit failed for Resample25: size=3, decay=0.1 Error in nnet.default(x, y, w, entropy = TRUE, ...) : \n",
            "  too many (2596) weights\n",
            "”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n",
            "Warning message in train.default(x, y, weights = w, ...):\n",
            "“missing values found in aggregated results”\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# weights:  866\n",
            "initial  value 14347.067231 \n",
            "iter  10 value 7523.119832\n",
            "iter  20 value 6878.257255\n",
            "iter  30 value 6542.895354\n",
            "iter  40 value 6418.689641\n",
            "iter  50 value 6337.414258\n",
            "iter  60 value 6273.861324\n",
            "iter  70 value 6229.046788\n",
            "iter  80 value 6196.844967\n",
            "iter  90 value 6166.147217\n",
            "iter 100 value 6148.992118\n",
            "final  value 6148.992118 \n",
            "stopped after 100 iterations\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークによる予測\n",
        "modelNnet_CHECK <- train(\n",
        "  as.formula(paste(\"C_yF ~ \",crossstring, sep=\"\")),\n",
        "  data = samp_i,\n",
        "  method = \"nnet\",\n",
        "  tuneLength = 2,\n",
        "  linout = FALSE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "k-aX4J7n-_rg",
        "outputId": "8f7cbf92-1b62-4998-8cce-af18bbcf600b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Neural Network \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  size  decay  Accuracy   Kappa    \n",
              "  1     0.0    0.8747927  0.1653380\n",
              "  1     0.1    0.8866785  0.2999275\n",
              "  3     0.0          NaN        NaN\n",
              "  3     0.1          NaN        NaN\n",
              "\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final values used for the model were size = 1 and decay = 0.1."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnet_CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "37XRYQ60-_rg",
        "outputId": "e4a03af5-e048-4cc1-f9b7-12584db2342f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "54.0358120743243"
            ],
            "text/latex": "54.0358120743243",
            "text/markdown": "54.0358120743243",
            "text/plain": [
              "[1] 54.03581"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNnet_out_result_data_CHECK <- data.frame(samp_o,predict(modelNnet_CHECK,samp_o,type=\"prob\"))\n",
        "write.table(modelNnet_out_result_data_CHECK, file = \"/content/modelNnet_out_result_data_CHECK.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelNnet_CHECK, file = \"/content/modelNnet_CHECK.obj\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelNnet_out_result_data_CHECK[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelNnet_out_result_data_CHECK[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpLT0G9f7pjN"
      },
      "source": [
        "## 99-3-5.precitテスト_NB　→　交互作用が見れないのでNG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0pPaUx_7pjW"
      },
      "outputs": [],
      "source": [
        "modelNBTest <- train(\n",
        "  C_yF ~ C_poutcome ,\n",
        "  data = samp_i,\n",
        "  method = \"rf\",\n",
        "  tuneLength = 2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDM6ny697pjX"
      },
      "outputs": [],
      "source": [
        "modelNBTest_out_result <- predict(modelNBTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5vk86LzG7pjX",
        "outputId": "ec286a5e-92fd-46d6-8517-deb0cd5811f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>25</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>26</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>35</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>38</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45152</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45154</th><td>0.9799580</td><td>0.020041982</td></tr>\n",
              "\t<tr><th scope=row>45155</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45156</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45157</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45159</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45164</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>0.9799580</td><td>0.020041982</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45177</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45178</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45179</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45185</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45195</th><td>0.9867352</td><td>0.013264785</td></tr>\n",
              "\t<tr><th scope=row>45197</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45199</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>0.9799580</td><td>0.020041982</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45206</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>0.9954754</td><td>0.004524587</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>0.8192250</td><td>0.180775009</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>0.9799580</td><td>0.020041982</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n  & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 0.9954754 & 0.004524587\\\\\n\t2 & 0.9954754 & 0.004524587\\\\\n\t4 & 0.9954754 & 0.004524587\\\\\n\t6 & 0.9954754 & 0.004524587\\\\\n\t8 & 0.9954754 & 0.004524587\\\\\n\t10 & 0.9954754 & 0.004524587\\\\\n\t11 & 0.9954754 & 0.004524587\\\\\n\t14 & 0.9954754 & 0.004524587\\\\\n\t16 & 0.9954754 & 0.004524587\\\\\n\t18 & 0.9954754 & 0.004524587\\\\\n\t19 & 0.9954754 & 0.004524587\\\\\n\t22 & 0.9954754 & 0.004524587\\\\\n\t23 & 0.9954754 & 0.004524587\\\\\n\t24 & 0.9954754 & 0.004524587\\\\\n\t25 & 0.9954754 & 0.004524587\\\\\n\t26 & 0.9954754 & 0.004524587\\\\\n\t29 & 0.9954754 & 0.004524587\\\\\n\t31 & 0.9954754 & 0.004524587\\\\\n\t32 & 0.9954754 & 0.004524587\\\\\n\t33 & 0.9954754 & 0.004524587\\\\\n\t34 & 0.9954754 & 0.004524587\\\\\n\t35 & 0.9954754 & 0.004524587\\\\\n\t36 & 0.9954754 & 0.004524587\\\\\n\t37 & 0.9954754 & 0.004524587\\\\\n\t38 & 0.9954754 & 0.004524587\\\\\n\t41 & 0.9954754 & 0.004524587\\\\\n\t46 & 0.9954754 & 0.004524587\\\\\n\t47 & 0.9954754 & 0.004524587\\\\\n\t50 & 0.9954754 & 0.004524587\\\\\n\t52 & 0.9954754 & 0.004524587\\\\\n\t⋮ & ⋮ & ⋮\\\\\n\t45152 & 0.9867352 & 0.013264785\\\\\n\t45154 & 0.9799580 & 0.020041982\\\\\n\t45155 & 0.9867352 & 0.013264785\\\\\n\t45156 & 0.8192250 & 0.180775009\\\\\n\t45157 & 0.9954754 & 0.004524587\\\\\n\t45159 & 0.9867352 & 0.013264785\\\\\n\t45162 & 0.9954754 & 0.004524587\\\\\n\t45163 & 0.8192250 & 0.180775009\\\\\n\t45164 & 0.9867352 & 0.013264785\\\\\n\t45166 & 0.9799580 & 0.020041982\\\\\n\t45169 & 0.8192250 & 0.180775009\\\\\n\t45172 & 0.9867352 & 0.013264785\\\\\n\t45175 & 0.8192250 & 0.180775009\\\\\n\t45177 & 0.9954754 & 0.004524587\\\\\n\t45178 & 0.8192250 & 0.180775009\\\\\n\t45179 & 0.8192250 & 0.180775009\\\\\n\t45185 & 0.8192250 & 0.180775009\\\\\n\t45188 & 0.9954754 & 0.004524587\\\\\n\t45195 & 0.9867352 & 0.013264785\\\\\n\t45197 & 0.9954754 & 0.004524587\\\\\n\t45198 & 0.9954754 & 0.004524587\\\\\n\t45199 & 0.9954754 & 0.004524587\\\\\n\t45200 & 0.9799580 & 0.020041982\\\\\n\t45201 & 0.9954754 & 0.004524587\\\\\n\t45203 & 0.9954754 & 0.004524587\\\\\n\t45204 & 0.9954754 & 0.004524587\\\\\n\t45206 & 0.9954754 & 0.004524587\\\\\n\t45207 & 0.9954754 & 0.004524587\\\\\n\t45209 & 0.8192250 & 0.180775009\\\\\n\t45211 & 0.9799580 & 0.020041982\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; |\n|---|---|---|\n| 1 | 0.9954754 | 0.004524587 |\n| 2 | 0.9954754 | 0.004524587 |\n| 4 | 0.9954754 | 0.004524587 |\n| 6 | 0.9954754 | 0.004524587 |\n| 8 | 0.9954754 | 0.004524587 |\n| 10 | 0.9954754 | 0.004524587 |\n| 11 | 0.9954754 | 0.004524587 |\n| 14 | 0.9954754 | 0.004524587 |\n| 16 | 0.9954754 | 0.004524587 |\n| 18 | 0.9954754 | 0.004524587 |\n| 19 | 0.9954754 | 0.004524587 |\n| 22 | 0.9954754 | 0.004524587 |\n| 23 | 0.9954754 | 0.004524587 |\n| 24 | 0.9954754 | 0.004524587 |\n| 25 | 0.9954754 | 0.004524587 |\n| 26 | 0.9954754 | 0.004524587 |\n| 29 | 0.9954754 | 0.004524587 |\n| 31 | 0.9954754 | 0.004524587 |\n| 32 | 0.9954754 | 0.004524587 |\n| 33 | 0.9954754 | 0.004524587 |\n| 34 | 0.9954754 | 0.004524587 |\n| 35 | 0.9954754 | 0.004524587 |\n| 36 | 0.9954754 | 0.004524587 |\n| 37 | 0.9954754 | 0.004524587 |\n| 38 | 0.9954754 | 0.004524587 |\n| 41 | 0.9954754 | 0.004524587 |\n| 46 | 0.9954754 | 0.004524587 |\n| 47 | 0.9954754 | 0.004524587 |\n| 50 | 0.9954754 | 0.004524587 |\n| 52 | 0.9954754 | 0.004524587 |\n| ⋮ | ⋮ | ⋮ |\n| 45152 | 0.9867352 | 0.013264785 |\n| 45154 | 0.9799580 | 0.020041982 |\n| 45155 | 0.9867352 | 0.013264785 |\n| 45156 | 0.8192250 | 0.180775009 |\n| 45157 | 0.9954754 | 0.004524587 |\n| 45159 | 0.9867352 | 0.013264785 |\n| 45162 | 0.9954754 | 0.004524587 |\n| 45163 | 0.8192250 | 0.180775009 |\n| 45164 | 0.9867352 | 0.013264785 |\n| 45166 | 0.9799580 | 0.020041982 |\n| 45169 | 0.8192250 | 0.180775009 |\n| 45172 | 0.9867352 | 0.013264785 |\n| 45175 | 0.8192250 | 0.180775009 |\n| 45177 | 0.9954754 | 0.004524587 |\n| 45178 | 0.8192250 | 0.180775009 |\n| 45179 | 0.8192250 | 0.180775009 |\n| 45185 | 0.8192250 | 0.180775009 |\n| 45188 | 0.9954754 | 0.004524587 |\n| 45195 | 0.9867352 | 0.013264785 |\n| 45197 | 0.9954754 | 0.004524587 |\n| 45198 | 0.9954754 | 0.004524587 |\n| 45199 | 0.9954754 | 0.004524587 |\n| 45200 | 0.9799580 | 0.020041982 |\n| 45201 | 0.9954754 | 0.004524587 |\n| 45203 | 0.9954754 | 0.004524587 |\n| 45204 | 0.9954754 | 0.004524587 |\n| 45206 | 0.9954754 | 0.004524587 |\n| 45207 | 0.9954754 | 0.004524587 |\n| 45209 | 0.8192250 | 0.180775009 |\n| 45211 | 0.9799580 | 0.020041982 |\n\n",
            "text/plain": [
              "      0         1          \n",
              "1     0.9954754 0.004524587\n",
              "2     0.9954754 0.004524587\n",
              "4     0.9954754 0.004524587\n",
              "6     0.9954754 0.004524587\n",
              "8     0.9954754 0.004524587\n",
              "10    0.9954754 0.004524587\n",
              "11    0.9954754 0.004524587\n",
              "14    0.9954754 0.004524587\n",
              "16    0.9954754 0.004524587\n",
              "18    0.9954754 0.004524587\n",
              "19    0.9954754 0.004524587\n",
              "22    0.9954754 0.004524587\n",
              "23    0.9954754 0.004524587\n",
              "24    0.9954754 0.004524587\n",
              "25    0.9954754 0.004524587\n",
              "26    0.9954754 0.004524587\n",
              "29    0.9954754 0.004524587\n",
              "31    0.9954754 0.004524587\n",
              "32    0.9954754 0.004524587\n",
              "33    0.9954754 0.004524587\n",
              "34    0.9954754 0.004524587\n",
              "35    0.9954754 0.004524587\n",
              "36    0.9954754 0.004524587\n",
              "37    0.9954754 0.004524587\n",
              "38    0.9954754 0.004524587\n",
              "41    0.9954754 0.004524587\n",
              "46    0.9954754 0.004524587\n",
              "47    0.9954754 0.004524587\n",
              "50    0.9954754 0.004524587\n",
              "52    0.9954754 0.004524587\n",
              "⋮     ⋮         ⋮          \n",
              "45152 0.9867352 0.013264785\n",
              "45154 0.9799580 0.020041982\n",
              "45155 0.9867352 0.013264785\n",
              "45156 0.8192250 0.180775009\n",
              "45157 0.9954754 0.004524587\n",
              "45159 0.9867352 0.013264785\n",
              "45162 0.9954754 0.004524587\n",
              "45163 0.8192250 0.180775009\n",
              "45164 0.9867352 0.013264785\n",
              "45166 0.9799580 0.020041982\n",
              "45169 0.8192250 0.180775009\n",
              "45172 0.9867352 0.013264785\n",
              "45175 0.8192250 0.180775009\n",
              "45177 0.9954754 0.004524587\n",
              "45178 0.8192250 0.180775009\n",
              "45179 0.8192250 0.180775009\n",
              "45185 0.8192250 0.180775009\n",
              "45188 0.9954754 0.004524587\n",
              "45195 0.9867352 0.013264785\n",
              "45197 0.9954754 0.004524587\n",
              "45198 0.9954754 0.004524587\n",
              "45199 0.9954754 0.004524587\n",
              "45200 0.9799580 0.020041982\n",
              "45201 0.9954754 0.004524587\n",
              "45203 0.9954754 0.004524587\n",
              "45204 0.9954754 0.004524587\n",
              "45206 0.9954754 0.004524587\n",
              "45207 0.9954754 0.004524587\n",
              "45209 0.8192250 0.180775009\n",
              "45211 0.9799580 0.020041982"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelNBTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyaTuTo97pjX"
      },
      "outputs": [],
      "source": [
        "modelNBTest_out_result_data <- data.frame(samp_o,predict(modelNBTest,samp_o,type=\"prob\"))\n",
        "write.table(modelNBTest_out_result_data, file = \"/content/modelNBTest_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "\n",
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelNBTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"yes\"\n",
        "sortPred <- modelNBTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3k5Yhh5PGDc"
      },
      "source": [
        "## 99-3-5.precitテスト_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7OK_G-ePGDm"
      },
      "outputs": [],
      "source": [
        "modelRFTest <- train(\n",
        "  C_yF ~ C_poutcome  + C_month:B_pdays,\n",
        "  data = samp_i,\n",
        "  method = \"rf\",\n",
        "  tuneLength = 2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDEf9fnsPGDn"
      },
      "outputs": [],
      "source": [
        "modelRFTest_out_result <- predict(modelRFTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wS5ibaNdPGDn",
        "outputId": "a0081140-486c-4808-efc0-8079e7b2df48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>25</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>26</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>35</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>38</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45152</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45154</th><td>0.816</td><td>0.184</td></tr>\n",
              "\t<tr><th scope=row>45155</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45156</th><td>0.374</td><td>0.626</td></tr>\n",
              "\t<tr><th scope=row>45157</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45159</th><td>0.940</td><td>0.060</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>0.374</td><td>0.626</td></tr>\n",
              "\t<tr><th scope=row>45164</th><td>0.744</td><td>0.256</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>0.816</td><td>0.184</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>0.444</td><td>0.556</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>0.402</td><td>0.598</td></tr>\n",
              "\t<tr><th scope=row>45177</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45178</th><td>0.502</td><td>0.498</td></tr>\n",
              "\t<tr><th scope=row>45179</th><td>0.402</td><td>0.598</td></tr>\n",
              "\t<tr><th scope=row>45185</th><td>0.458</td><td>0.542</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45195</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45197</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45199</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45206</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>0.502</td><td>0.498</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>1.000</td><td>0.000</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n  & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 1 & 0\\\\\n\t2 & 1 & 0\\\\\n\t4 & 1 & 0\\\\\n\t6 & 1 & 0\\\\\n\t8 & 1 & 0\\\\\n\t10 & 1 & 0\\\\\n\t11 & 1 & 0\\\\\n\t14 & 1 & 0\\\\\n\t16 & 1 & 0\\\\\n\t18 & 1 & 0\\\\\n\t19 & 1 & 0\\\\\n\t22 & 1 & 0\\\\\n\t23 & 1 & 0\\\\\n\t24 & 1 & 0\\\\\n\t25 & 1 & 0\\\\\n\t26 & 1 & 0\\\\\n\t29 & 1 & 0\\\\\n\t31 & 1 & 0\\\\\n\t32 & 1 & 0\\\\\n\t33 & 1 & 0\\\\\n\t34 & 1 & 0\\\\\n\t35 & 1 & 0\\\\\n\t36 & 1 & 0\\\\\n\t37 & 1 & 0\\\\\n\t38 & 1 & 0\\\\\n\t41 & 1 & 0\\\\\n\t46 & 1 & 0\\\\\n\t47 & 1 & 0\\\\\n\t50 & 1 & 0\\\\\n\t52 & 1 & 0\\\\\n\t⋮ & ⋮ & ⋮\\\\\n\t45152 & 1.000 & 0.000\\\\\n\t45154 & 0.816 & 0.184\\\\\n\t45155 & 1.000 & 0.000\\\\\n\t45156 & 0.374 & 0.626\\\\\n\t45157 & 1.000 & 0.000\\\\\n\t45159 & 0.940 & 0.060\\\\\n\t45162 & 1.000 & 0.000\\\\\n\t45163 & 0.374 & 0.626\\\\\n\t45164 & 0.744 & 0.256\\\\\n\t45166 & 0.816 & 0.184\\\\\n\t45169 & 0.444 & 0.556\\\\\n\t45172 & 1.000 & 0.000\\\\\n\t45175 & 0.402 & 0.598\\\\\n\t45177 & 1.000 & 0.000\\\\\n\t45178 & 0.502 & 0.498\\\\\n\t45179 & 0.402 & 0.598\\\\\n\t45185 & 0.458 & 0.542\\\\\n\t45188 & 1.000 & 0.000\\\\\n\t45195 & 1.000 & 0.000\\\\\n\t45197 & 1.000 & 0.000\\\\\n\t45198 & 1.000 & 0.000\\\\\n\t45199 & 1.000 & 0.000\\\\\n\t45200 & 1.000 & 0.000\\\\\n\t45201 & 1.000 & 0.000\\\\\n\t45203 & 1.000 & 0.000\\\\\n\t45204 & 1.000 & 0.000\\\\\n\t45206 & 1.000 & 0.000\\\\\n\t45207 & 1.000 & 0.000\\\\\n\t45209 & 0.502 & 0.498\\\\\n\t45211 & 1.000 & 0.000\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; |\n|---|---|---|\n| 1 | 1 | 0 |\n| 2 | 1 | 0 |\n| 4 | 1 | 0 |\n| 6 | 1 | 0 |\n| 8 | 1 | 0 |\n| 10 | 1 | 0 |\n| 11 | 1 | 0 |\n| 14 | 1 | 0 |\n| 16 | 1 | 0 |\n| 18 | 1 | 0 |\n| 19 | 1 | 0 |\n| 22 | 1 | 0 |\n| 23 | 1 | 0 |\n| 24 | 1 | 0 |\n| 25 | 1 | 0 |\n| 26 | 1 | 0 |\n| 29 | 1 | 0 |\n| 31 | 1 | 0 |\n| 32 | 1 | 0 |\n| 33 | 1 | 0 |\n| 34 | 1 | 0 |\n| 35 | 1 | 0 |\n| 36 | 1 | 0 |\n| 37 | 1 | 0 |\n| 38 | 1 | 0 |\n| 41 | 1 | 0 |\n| 46 | 1 | 0 |\n| 47 | 1 | 0 |\n| 50 | 1 | 0 |\n| 52 | 1 | 0 |\n| ⋮ | ⋮ | ⋮ |\n| 45152 | 1.000 | 0.000 |\n| 45154 | 0.816 | 0.184 |\n| 45155 | 1.000 | 0.000 |\n| 45156 | 0.374 | 0.626 |\n| 45157 | 1.000 | 0.000 |\n| 45159 | 0.940 | 0.060 |\n| 45162 | 1.000 | 0.000 |\n| 45163 | 0.374 | 0.626 |\n| 45164 | 0.744 | 0.256 |\n| 45166 | 0.816 | 0.184 |\n| 45169 | 0.444 | 0.556 |\n| 45172 | 1.000 | 0.000 |\n| 45175 | 0.402 | 0.598 |\n| 45177 | 1.000 | 0.000 |\n| 45178 | 0.502 | 0.498 |\n| 45179 | 0.402 | 0.598 |\n| 45185 | 0.458 | 0.542 |\n| 45188 | 1.000 | 0.000 |\n| 45195 | 1.000 | 0.000 |\n| 45197 | 1.000 | 0.000 |\n| 45198 | 1.000 | 0.000 |\n| 45199 | 1.000 | 0.000 |\n| 45200 | 1.000 | 0.000 |\n| 45201 | 1.000 | 0.000 |\n| 45203 | 1.000 | 0.000 |\n| 45204 | 1.000 | 0.000 |\n| 45206 | 1.000 | 0.000 |\n| 45207 | 1.000 | 0.000 |\n| 45209 | 0.502 | 0.498 |\n| 45211 | 1.000 | 0.000 |\n\n",
            "text/plain": [
              "      0     1    \n",
              "1     1     0    \n",
              "2     1     0    \n",
              "4     1     0    \n",
              "6     1     0    \n",
              "8     1     0    \n",
              "10    1     0    \n",
              "11    1     0    \n",
              "14    1     0    \n",
              "16    1     0    \n",
              "18    1     0    \n",
              "19    1     0    \n",
              "22    1     0    \n",
              "23    1     0    \n",
              "24    1     0    \n",
              "25    1     0    \n",
              "26    1     0    \n",
              "29    1     0    \n",
              "31    1     0    \n",
              "32    1     0    \n",
              "33    1     0    \n",
              "34    1     0    \n",
              "35    1     0    \n",
              "36    1     0    \n",
              "37    1     0    \n",
              "38    1     0    \n",
              "41    1     0    \n",
              "46    1     0    \n",
              "47    1     0    \n",
              "50    1     0    \n",
              "52    1     0    \n",
              "⋮     ⋮     ⋮    \n",
              "45152 1.000 0.000\n",
              "45154 0.816 0.184\n",
              "45155 1.000 0.000\n",
              "45156 0.374 0.626\n",
              "45157 1.000 0.000\n",
              "45159 0.940 0.060\n",
              "45162 1.000 0.000\n",
              "45163 0.374 0.626\n",
              "45164 0.744 0.256\n",
              "45166 0.816 0.184\n",
              "45169 0.444 0.556\n",
              "45172 1.000 0.000\n",
              "45175 0.402 0.598\n",
              "45177 1.000 0.000\n",
              "45178 0.502 0.498\n",
              "45179 0.402 0.598\n",
              "45185 0.458 0.542\n",
              "45188 1.000 0.000\n",
              "45195 1.000 0.000\n",
              "45197 1.000 0.000\n",
              "45198 1.000 0.000\n",
              "45199 1.000 0.000\n",
              "45200 1.000 0.000\n",
              "45201 1.000 0.000\n",
              "45203 1.000 0.000\n",
              "45204 1.000 0.000\n",
              "45206 1.000 0.000\n",
              "45207 1.000 0.000\n",
              "45209 0.502 0.498\n",
              "45211 1.000 0.000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelRFTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xrxRyySk1fS",
        "outputId": "4bdae7a9-de94-4ace-8cee-c800e3785007"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 43</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>age</th><th scope=col>job</th><th scope=col>marital</th><th scope=col>education</th><th scope=col>default</th><th scope=col>balance</th><th scope=col>housing</th><th scope=col>loan</th><th scope=col>contact</th><th scope=col>day</th><th scope=col>⋯</th><th scope=col>campaign_11</th><th scope=col>pdays_120</th><th scope=col>previous_11</th><th scope=col>B_age</th><th scope=col>B_balance</th><th scope=col>B_campaign</th><th scope=col>B_pdays</th><th scope=col>B_previous</th><th scope=col>X0</th><th scope=col>X1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>58</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td> 2143</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.4197550723, 3.150000e-01, 7.879593e-02</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>44</td><td>technician   </td><td>single  </td><td>secondary</td><td>no </td><td>   29</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.0177811347, 1.073092e-04, 2.158705e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>47</td><td>blue-collar  </td><td>married </td><td>unknown  </td><td>no </td><td> 1506</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.198453191, 0.44270327, 0.32918961</td><td>0.4412754278, 1.903269e-01, 2.736335e-02</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>35</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  231</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.430231616, 0.29255750, 0.06631303</td><td>0.1265590834, 6.156785e-03, 9.983743e-05</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>42</td><td>entrepreneur </td><td>divorced</td><td>tertiary </td><td>yes</td><td>    2</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.314868805, 0.41982507, 0.18658892</td><td>0.0017974816, 1.078921e-06, 2.158705e-10</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>43</td><td>technician   </td><td>single  </td><td>secondary</td><td>no </td><td>  593</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.292557499, 0.43023162, 0.21089785</td><td>0.2767089696, 3.729638e-02, 1.675671e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>41</td><td>admin.       </td><td>divorced</td><td>secondary</td><td>no </td><td>  270</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.336208293, 0.40698899, 0.16422363</td><td>0.1454260685, 8.332022e-03, 1.591246e-04</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>58</td><td>technician   </td><td>married </td><td>unknown  </td><td>no </td><td>   71</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.0419566518, 6.128787e-04, 2.984193e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>51</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>  229</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.108236152, 0.39686589, 0.48505831</td><td>0.1255733153, 6.053629e-03, 9.727762e-05</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>57</td><td>blue-collar  </td><td>married </td><td>primary  </td><td>no </td><td>   52</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.0311233218, 3.333743e-04, 1.190302e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>60</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>   60</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.000000000, 0.00000000, 1.00000000</td><td>0.0357054428, 4.408972e-04, 1.814759e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>56</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  779</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.024619372, 0.23388403, 0.74063276</td><td>0.3333312248, 6.159639e-02, 3.794139e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>32</td><td>blue-collar  </td><td>single  </td><td>primary  </td><td>no </td><td>   23</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.444444444, 0.22222222, 0.03703704</td><td>0.0142592674, 6.876078e-05, 1.105257e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>25</td><td>services     </td><td>married </td><td>secondary</td><td>no </td><td>   50</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.347222222, 0.06944444, 0.00462963</td><td>0.0299730726, 3.088135e-04, 1.060572e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>25</th><td>40</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>    0</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.356333009, 0.39196631, 0.14372098</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>26</th><td>44</td><td>admin.       </td><td>married </td><td>secondary</td><td>no </td><td> -372</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>46</td><td>management   </td><td>single  </td><td>secondary</td><td>no </td><td> -246</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>2</td><td>-1</td><td>0</td><td>0.222222222, 0.44444444, 0.29629630</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.243, 0.027, 0.001</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>57</td><td>technician   </td><td>married </td><td>secondary</td><td>no </td><td>  839</td><td>no </td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.3488393019, 7.042178e-02, 4.738788e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>49</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  378</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.151886945, 0.42804503, 0.40210290</td><td>0.1942002494, 1.592425e-02, 4.352583e-04</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>60</td><td>admin.       </td><td>married </td><td>secondary</td><td>no </td><td>   39</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.000000000, 0.00000000, 1.00000000</td><td>0.0236128896, 1.903881e-04, 5.116929e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>59</td><td>blue-collar  </td><td>married </td><td>secondary</td><td>no </td><td>    0</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.001660188, 0.06806770, 0.93025861</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>35</th><td>51</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>10635</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.108236152, 0.39686589, 0.48505831</td><td>0.0000000000, 0.000000e+00, 1.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>57</td><td>technician   </td><td>divorced</td><td>secondary</td><td>no </td><td>   63</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.0374159623, 4.850358e-04, 2.095894e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>25</td><td>blue-collar  </td><td>married </td><td>secondary</td><td>no </td><td>   -7</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.347222222, 0.06944444, 0.00462963</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>38</th><td>53</td><td>technician   </td><td>married </td><td>secondary</td><td>no </td><td>   -3</td><td>no </td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.069444444, 0.34722222, 0.57870370</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>44</td><td>services     </td><td>divorced</td><td>secondary</td><td>no </td><td> 2586</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.3615943628, 3.875081e-01, 1.384263e-01</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>36</td><td>admin.       </td><td>single  </td><td>primary  </td><td>no </td><td> -171</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.419825073, 0.31486880, 0.07871720</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>58</td><td>self-employed</td><td>married </td><td>tertiary </td><td>no </td><td> -364</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>29</td><td>management   </td><td>single  </td><td>tertiary </td><td>no </td><td>    0</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.428045028, 0.15188695, 0.01796512</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>48</td><td>management   </td><td>divorced</td><td>tertiary </td><td>no </td><td> -244</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.174927114, 0.43731778, 0.36443149</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45152</th><td>47</td><td>management  </td><td>single  </td><td>tertiary </td><td>no</td><td> 311</td><td>yes</td><td>yes</td><td>cellular </td><td> 9</td><td>⋯</td><td>3</td><td>120</td><td> 2</td><td>0.198453191, 0.44270327, 0.329189612</td><td>0.16453782, 0.0109481342, 2.428249e-04</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.3651390, 0.08114200, 0.0060105184</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45154</th><td>64</td><td>retired     </td><td>married </td><td>tertiary </td><td>no</td><td>2059</td><td>no </td><td>yes</td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> 95</td><td> 1</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.42737387, 0.2993506161, 6.989258e-02</td><td>0.000, 0.000, 0.000</td><td>0.1016053, 0.39016438, 0.499410407</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.816</td><td>0.184</td></tr>\n",
              "\t<tr><th scope=row>45155</th><td>63</td><td>retired     </td><td>married </td><td>primary  </td><td>no</td><td>3738</td><td>no </td><td>no </td><td>telephone</td><td> 9</td><td>⋯</td><td>1</td><td>120</td><td> 4</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.14283179, 0.4231759485, 4.179226e-01</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4417731, 0.25244177, 0.0480841473</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45156</th><td>44</td><td>entrepreneur</td><td>married </td><td>tertiary </td><td>no</td><td> 121</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> 91</td><td> 1</td><td>0.269517331, 0.43796566, 0.237231400</td><td>0.06965819, 0.0017418116, 1.451807e-05</td><td>0.000, 0.000, 0.000</td><td>0.1310234, 0.41566054, 0.439549076</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.374</td><td>0.626</td></tr>\n",
              "\t<tr><th scope=row>45157</th><td>37</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td>3556</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.17789713, 0.4382133607, 3.598165e-01</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45159</th><td>34</td><td>student     </td><td>single  </td><td>unknown  </td><td>no</td><td>2321</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 99</td><td> 5</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.39972226, 0.3464557994, 1.000959e-01</td><td>0.243, 0.027, 0.001</td><td>0.0746799, 0.35561858, 0.564473930</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>0.940</td><td>0.060</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>31</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td> 720</td><td>yes</td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>3</td><td> -1</td><td> 0</td><td>0.442703272, 0.19845319, 0.029653925</td><td>0.31679148, 0.0533660415, 2.996645e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>29</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 464</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 91</td><td> 3</td><td>0.428045028, 0.15188695, 0.017965123</td><td>0.22948259, 0.0235250006, 8.038746e-04</td><td>0.243, 0.027, 0.001</td><td>0.1310234, 0.41566054, 0.439549076</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.374</td><td>0.626</td></tr>\n",
              "\t<tr><th scope=row>45164</th><td>71</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>2064</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 92</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.42695573, 0.3002941379, 7.040275e-02</td><td>0.243, 0.027, 0.001</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.744</td><td>0.256</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>33</td><td>technician  </td><td>married </td><td>tertiary </td><td>no</td><td>2976</td><td>yes</td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 95</td><td>11</td><td>0.442784257, 0.24599125, 0.045553936</td><td>0.29251662, 0.4302480083, 2.109434e-01</td><td>0.243, 0.027, 0.001</td><td>0.1016053, 0.39016438, 0.499410407</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>0.816</td><td>0.184</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>62</td><td>retired     </td><td>married </td><td>tertiary </td><td>no</td><td>2557</td><td>yes</td><td>no </td><td>cellular </td><td>10</td><td>⋯</td><td>1</td><td> 57</td><td> 8</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.36618299, 0.3834204198, 1.338231e-01</td><td>0.000, 0.000, 0.000</td><td>0.3898291, 0.35889027, 0.110135637</td><td>0.1622840, 0.43275733, 0.3846731781</td><td>0.444</td><td>0.556</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>33</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 690</td><td>no </td><td>no </td><td>cellular </td><td>10</td><td>⋯</td><td>3</td><td>120</td><td>11</td><td>0.442784257, 0.24599125, 0.045553936</td><td>0.30788128, 0.0493610121, 2.637932e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>62</td><td>blue-collar </td><td>married </td><td>secondary</td><td>no</td><td> 272</td><td>no </td><td>no </td><td>cellular </td><td>11</td><td>⋯</td><td>1</td><td> 92</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.14637546, 0.0084518825, 1.626737e-04</td><td>0.000, 0.000, 0.000</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.402</td><td>0.598</td></tr>\n",
              "\t<tr><th scope=row>45177</th><td>54</td><td>admin.      </td><td>married </td><td>secondary</td><td>no</td><td>  66</td><td>yes</td><td>no </td><td>cellular </td><td>11</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.052478134, 0.31486880, 0.629737609</td><td>0.03912225, 0.0005312506, 2.404661e-06</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45178</th><td>36</td><td>admin.      </td><td>divorced</td><td>secondary</td><td>no</td><td>1224</td><td>yes</td><td>no </td><td>cellular </td><td>12</td><td>⋯</td><td>1</td><td>120</td><td> 1</td><td>0.419825073, 0.31486880, 0.078717201</td><td>0.41893896, 0.1359110770, 1.469730e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.502</td><td>0.498</td></tr>\n",
              "\t<tr><th scope=row>45179</th><td>34</td><td>blue-collar </td><td>married </td><td>secondary</td><td>no</td><td> 320</td><td>yes</td><td>no </td><td>cellular </td><td>12</td><td>⋯</td><td>1</td><td> 92</td><td> 3</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.16863489, 0.0115666238, 2.644506e-04</td><td>0.000, 0.000, 0.000</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.402</td><td>0.598</td></tr>\n",
              "\t<tr><th scope=row>45185</th><td>63</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>1495</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> 22</td><td> 5</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.44081699, 0.1881489939, 2.676851e-02</td><td>0.000, 0.000, 0.000</td><td>0.3740633, 0.08779037, 0.006867954</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>0.458</td><td>0.542</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>32</td><td>services    </td><td>single  </td><td>secondary</td><td>no</td><td>1168</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.444444444, 0.22222222, 0.037037037</td><td>0.41173350, 0.1256045043, 1.277241e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45195</th><td>59</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td> 138</td><td>yes</td><td>yes</td><td>cellular </td><td>16</td><td>⋯</td><td>2</td><td>120</td><td> 5</td><td>0.001660188, 0.06806770, 0.930258611</td><td>0.07881255, 0.0022531767, 2.147207e-05</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45197</th><td>25</td><td>student     </td><td>single  </td><td>secondary</td><td>no</td><td> 358</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.347222222, 0.06944444, 0.004629630</td><td>0.18554763, 0.0143497629, 3.699242e-04</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>36</td><td>management  </td><td>single  </td><td>secondary</td><td>no</td><td>1511</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.419825073, 0.31486880, 0.078717201</td><td>0.44147328, 0.1913177404, 2.763661e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45199</th><td>37</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td>1428</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>2</td><td> -1</td><td> 0</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.43732653, 0.1749550968, 2.333061e-02</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>34</td><td>blue-collar </td><td>single  </td><td>secondary</td><td>no</td><td>1475</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>3</td><td>120</td><td>11</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.43990135, 0.1841969893, 2.570920e-02</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>38</td><td>technician  </td><td>married </td><td>secondary</td><td>no</td><td> 557</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>4</td><td> -1</td><td> 0</td><td>0.391966310, 0.35633301, 0.107979700</td><td>0.26420286, 0.0331814532, 1.389095e-03</td><td>0.441, 0.189, 0.027</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>34</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 557</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.26420286, 0.0331814532, 1.389095e-03</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>23</td><td>student     </td><td>single  </td><td>tertiary </td><td>no</td><td> 113</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.277170392, 0.03745546, 0.001687183</td><td>0.06530407, 0.0015233606, 1.184524e-05</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45206</th><td>25</td><td>technician  </td><td>single  </td><td>secondary</td><td>no</td><td> 505</td><td>no </td><td>yes</td><td>cellular </td><td>17</td><td>⋯</td><td>2</td><td> -1</td><td> 0</td><td>0.347222222, 0.06944444, 0.004629630</td><td>0.24522266, 0.0276045976, 1.035812e-03</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>51</td><td>technician  </td><td>married </td><td>tertiary </td><td>no</td><td> 825</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>3</td><td> -1</td><td> 0</td><td>0.108236152, 0.39686589, 0.485058309</td><td>0.34533747, 0.0683230532, 4.505776e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>72</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>5715</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>5</td><td>120</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.00000000, 0.0000000000, 1.000000e+00</td><td>0.432, 0.288, 0.064</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.502</td><td>0.498</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>37</td><td>entrepreneur</td><td>married </td><td>secondary</td><td>no</td><td>2971</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>2</td><td>120</td><td>11</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.29346992, 0.4298632801, 2.098823e-01</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>1.000</td><td>0.000</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 43\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & age & job & marital & education & default & balance & housing & loan & contact & day & ⋯ & campaign\\_11 & pdays\\_120 & previous\\_11 & B\\_age & B\\_balance & B\\_campaign & B\\_pdays & B\\_previous & X0 & X1\\\\\n  & <int> & <fct> & <fct> & <fct> & <fct> & <int> & <fct> & <fct> & <fct> & <int> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 58 & management    & married  & tertiary  & no  &  2143 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.4197550723, 3.150000e-01, 7.879593e-02 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t2 & 44 & technician    & single   & secondary & no  &    29 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.0177811347, 1.073092e-04, 2.158705e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t4 & 47 & blue-collar   & married  & unknown   & no  &  1506 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.198453191, 0.44270327, 0.32918961 & 0.4412754278, 1.903269e-01, 2.736335e-02 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t6 & 35 & management    & married  & tertiary  & no  &   231 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.430231616, 0.29255750, 0.06631303 & 0.1265590834, 6.156785e-03, 9.983743e-05 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t8 & 42 & entrepreneur  & divorced & tertiary  & yes &     2 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.314868805, 0.41982507, 0.18658892 & 0.0017974816, 1.078921e-06, 2.158705e-10 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t10 & 43 & technician    & single   & secondary & no  &   593 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.292557499, 0.43023162, 0.21089785 & 0.2767089696, 3.729638e-02, 1.675671e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t11 & 41 & admin.        & divorced & secondary & no  &   270 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.336208293, 0.40698899, 0.16422363 & 0.1454260685, 8.332022e-03, 1.591246e-04 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t14 & 58 & technician    & married  & unknown   & no  &    71 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.0419566518, 6.128787e-04, 2.984193e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t16 & 51 & retired       & married  & primary   & no  &   229 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.108236152, 0.39686589, 0.48505831 & 0.1255733153, 6.053629e-03, 9.727762e-05 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t18 & 57 & blue-collar   & married  & primary   & no  &    52 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.0311233218, 3.333743e-04, 1.190302e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t19 & 60 & retired       & married  & primary   & no  &    60 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.000000000, 0.00000000, 1.00000000 & 0.0357054428, 4.408972e-04, 1.814759e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t22 & 56 & management    & married  & tertiary  & no  &   779 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.024619372, 0.23388403, 0.74063276 & 0.3333312248, 6.159639e-02, 3.794139e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t23 & 32 & blue-collar   & single   & primary   & no  &    23 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.444444444, 0.22222222, 0.03703704 & 0.0142592674, 6.876078e-05, 1.105257e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t24 & 25 & services      & married  & secondary & no  &    50 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.347222222, 0.06944444, 0.00462963 & 0.0299730726, 3.088135e-04, 1.060572e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t25 & 40 & retired       & married  & primary   & no  &     0 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.356333009, 0.39196631, 0.14372098 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t26 & 44 & admin.        & married  & secondary & no  &  -372 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t29 & 46 & management    & single   & secondary & no  &  -246 & yes & no  & unknown & 5 & ⋯ & 2 & -1 & 0 & 0.222222222, 0.44444444, 0.29629630 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.243, 0.027, 0.001 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t31 & 57 & technician    & married  & secondary & no  &   839 & no  & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.3488393019, 7.042178e-02, 4.738788e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t32 & 49 & management    & married  & tertiary  & no  &   378 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.151886945, 0.42804503, 0.40210290 & 0.1942002494, 1.592425e-02, 4.352583e-04 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t33 & 60 & admin.        & married  & secondary & no  &    39 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.000000000, 0.00000000, 1.00000000 & 0.0236128896, 1.903881e-04, 5.116929e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t34 & 59 & blue-collar   & married  & secondary & no  &     0 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.001660188, 0.06806770, 0.93025861 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t35 & 51 & management    & married  & tertiary  & no  & 10635 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.108236152, 0.39686589, 0.48505831 & 0.0000000000, 0.000000e+00, 1.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t36 & 57 & technician    & divorced & secondary & no  &    63 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.0374159623, 4.850358e-04, 2.095894e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t37 & 25 & blue-collar   & married  & secondary & no  &    -7 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.347222222, 0.06944444, 0.00462963 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t38 & 53 & technician    & married  & secondary & no  &    -3 & no  & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.069444444, 0.34722222, 0.57870370 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t41 & 44 & services      & divorced & secondary & no  &  2586 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.3615943628, 3.875081e-01, 1.384263e-01 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t46 & 36 & admin.        & single   & primary   & no  &  -171 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.419825073, 0.31486880, 0.07871720 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t47 & 58 & self-employed & married  & tertiary  & no  &  -364 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t50 & 29 & management    & single   & tertiary  & no  &     0 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.428045028, 0.15188695, 0.01796512 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t52 & 48 & management    & divorced & tertiary  & no  &  -244 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.174927114, 0.43731778, 0.36443149 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 1 & 0\\\\\n\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n\t45152 & 47 & management   & single   & tertiary  & no &  311 & yes & yes & cellular  &  9 & ⋯ & 3 & 120 &  2 & 0.198453191, 0.44270327, 0.329189612 & 0.16453782, 0.0109481342, 2.428249e-04 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.3651390, 0.08114200, 0.0060105184 & 1.000 & 0.000\\\\\n\t45154 & 64 & retired      & married  & tertiary  & no & 2059 & no  & yes & cellular  &  9 & ⋯ & 1 &  95 &  1 & 0.000000000, 0.00000000, 1.000000000 & 0.42737387, 0.2993506161, 6.989258e-02 & 0.000, 0.000, 0.000 & 0.1016053, 0.39016438, 0.499410407 & 0.2253944, 0.02253944, 0.0007513148 & 0.816 & 0.184\\\\\n\t45155 & 63 & retired      & married  & primary   & no & 3738 & no  & no  & telephone &  9 & ⋯ & 1 & 120 &  4 & 0.000000000, 0.00000000, 1.000000000 & 0.14283179, 0.4231759485, 4.179226e-01 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 1.000000000 & 0.4417731, 0.25244177, 0.0480841473 & 1.000 & 0.000\\\\\n\t45156 & 44 & entrepreneur & married  & tertiary  & no &  121 & no  & no  & cellular  &  9 & ⋯ & 1 &  91 &  1 & 0.269517331, 0.43796566, 0.237231400 & 0.06965819, 0.0017418116, 1.451807e-05 & 0.000, 0.000, 0.000 & 0.1310234, 0.41566054, 0.439549076 & 0.2253944, 0.02253944, 0.0007513148 & 0.374 & 0.626\\\\\n\t45157 & 37 & management   & married  & tertiary  & no & 3556 & no  & no  & cellular  &  9 & ⋯ & 1 &  -1 &  0 & 0.406988986, 0.33620829, 0.092579095 & 0.17789713, 0.4382133607, 3.598165e-01 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45159 & 34 & student      & single   & unknown   & no & 2321 & no  & no  & cellular  &  9 & ⋯ & 2 &  99 &  5 & 0.437965662, 0.26951733, 0.055285606 & 0.39972226, 0.3464557994, 1.000959e-01 & 0.243, 0.027, 0.001 & 0.0746799, 0.35561858, 0.564473930 & 0.4057100, 0.33809166, 0.0939143501 & 0.940 & 0.060\\\\\n\t45162 & 31 & management   & married  & tertiary  & no &  720 & yes & no  & cellular  &  9 & ⋯ & 3 &  -1 &  0 & 0.442703272, 0.19845319, 0.029653925 & 0.31679148, 0.0533660415, 2.996645e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45163 & 29 & admin.       & single   & secondary & no &  464 & no  & no  & cellular  &  9 & ⋯ & 2 &  91 &  3 & 0.428045028, 0.15188695, 0.017965123 & 0.22948259, 0.0235250006, 8.038746e-04 & 0.243, 0.027, 0.001 & 0.1310234, 0.41566054, 0.439549076 & 0.4327573, 0.16228400, 0.0202854996 & 0.374 & 0.626\\\\\n\t45164 & 71 & retired      & married  & secondary & no & 2064 & no  & no  & cellular  &  9 & ⋯ & 2 &  92 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.42695573, 0.3002941379, 7.040275e-02 & 0.243, 0.027, 0.001 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.744 & 0.256\\\\\n\t45166 & 33 & technician   & married  & tertiary  & no & 2976 & yes & no  & cellular  &  9 & ⋯ & 2 &  95 & 11 & 0.442784257, 0.24599125, 0.045553936 & 0.29251662, 0.4302480083, 2.109434e-01 & 0.243, 0.027, 0.001 & 0.1016053, 0.39016438, 0.499410407 & 0.0000000, 0.00000000, 1.0000000000 & 0.816 & 0.184\\\\\n\t45169 & 62 & retired      & married  & tertiary  & no & 2557 & yes & no  & cellular  & 10 & ⋯ & 1 &  57 &  8 & 0.000000000, 0.00000000, 1.000000000 & 0.36618299, 0.3834204198, 1.338231e-01 & 0.000, 0.000, 0.000 & 0.3898291, 0.35889027, 0.110135637 & 0.1622840, 0.43275733, 0.3846731781 & 0.444 & 0.556\\\\\n\t45172 & 33 & admin.       & single   & secondary & no &  690 & no  & no  & cellular  & 10 & ⋯ & 3 & 120 & 11 & 0.442784257, 0.24599125, 0.045553936 & 0.30788128, 0.0493610121, 2.637932e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 1.000 & 0.000\\\\\n\t45175 & 62 & blue-collar  & married  & secondary & no &  272 & no  & no  & cellular  & 11 & ⋯ & 1 &  92 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.14637546, 0.0084518825, 1.626737e-04 & 0.000, 0.000, 0.000 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.402 & 0.598\\\\\n\t45177 & 54 & admin.       & married  & secondary & no &   66 & yes & no  & cellular  & 11 & ⋯ & 1 &  -1 &  0 & 0.052478134, 0.31486880, 0.629737609 & 0.03912225, 0.0005312506, 2.404661e-06 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45178 & 36 & admin.       & divorced & secondary & no & 1224 & yes & no  & cellular  & 12 & ⋯ & 1 & 120 &  1 & 0.419825073, 0.31486880, 0.078717201 & 0.41893896, 0.1359110770, 1.469730e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 1.000000000 & 0.2253944, 0.02253944, 0.0007513148 & 0.502 & 0.498\\\\\n\t45179 & 34 & blue-collar  & married  & secondary & no &  320 & yes & no  & cellular  & 12 & ⋯ & 1 &  92 &  3 & 0.437965662, 0.26951733, 0.055285606 & 0.16863489, 0.0115666238, 2.644506e-04 & 0.000, 0.000, 0.000 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.402 & 0.598\\\\\n\t45185 & 63 & retired      & married  & secondary & no & 1495 & no  & no  & cellular  & 16 & ⋯ & 1 &  22 &  5 & 0.000000000, 0.00000000, 1.000000000 & 0.44081699, 0.1881489939, 2.676851e-02 & 0.000, 0.000, 0.000 & 0.3740633, 0.08779037, 0.006867954 & 0.4057100, 0.33809166, 0.0939143501 & 0.458 & 0.542\\\\\n\t45188 & 32 & services     & single   & secondary & no & 1168 & yes & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.444444444, 0.22222222, 0.037037037 & 0.41173350, 0.1256045043, 1.277241e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45195 & 59 & management   & married  & tertiary  & no &  138 & yes & yes & cellular  & 16 & ⋯ & 2 & 120 &  5 & 0.001660188, 0.06806770, 0.930258611 & 0.07881255, 0.0022531767, 2.147207e-05 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 1.000000000 & 0.4057100, 0.33809166, 0.0939143501 & 1.000 & 0.000\\\\\n\t45197 & 25 & student      & single   & secondary & no &  358 & no  & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.347222222, 0.06944444, 0.004629630 & 0.18554763, 0.0143497629, 3.699242e-04 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45198 & 36 & management   & single   & secondary & no & 1511 & yes & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.419825073, 0.31486880, 0.078717201 & 0.44147328, 0.1913177404, 2.763661e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45199 & 37 & management   & married  & tertiary  & no & 1428 & no  & no  & cellular  & 16 & ⋯ & 2 &  -1 &  0 & 0.406988986, 0.33620829, 0.092579095 & 0.43732653, 0.1749550968, 2.333061e-02 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45200 & 34 & blue-collar  & single   & secondary & no & 1475 & yes & no  & cellular  & 16 & ⋯ & 3 & 120 & 11 & 0.437965662, 0.26951733, 0.055285606 & 0.43990135, 0.1841969893, 2.570920e-02 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 1.000 & 0.000\\\\\n\t45201 & 38 & technician   & married  & secondary & no &  557 & yes & no  & cellular  & 16 & ⋯ & 4 &  -1 &  0 & 0.391966310, 0.35633301, 0.107979700 & 0.26420286, 0.0331814532, 1.389095e-03 & 0.441, 0.189, 0.027 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45203 & 34 & admin.       & single   & secondary & no &  557 & no  & no  & cellular  & 17 & ⋯ & 1 &  -1 &  0 & 0.437965662, 0.26951733, 0.055285606 & 0.26420286, 0.0331814532, 1.389095e-03 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45204 & 23 & student      & single   & tertiary  & no &  113 & no  & no  & cellular  & 17 & ⋯ & 1 &  -1 &  0 & 0.277170392, 0.03745546, 0.001687183 & 0.06530407, 0.0015233606, 1.184524e-05 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45206 & 25 & technician   & single   & secondary & no &  505 & no  & yes & cellular  & 17 & ⋯ & 2 &  -1 &  0 & 0.347222222, 0.06944444, 0.004629630 & 0.24522266, 0.0276045976, 1.035812e-03 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45207 & 51 & technician   & married  & tertiary  & no &  825 & no  & no  & cellular  & 17 & ⋯ & 3 &  -1 &  0 & 0.108236152, 0.39686589, 0.485058309 & 0.34533747, 0.0683230532, 4.505776e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 1.000 & 0.000\\\\\n\t45209 & 72 & retired      & married  & secondary & no & 5715 & no  & no  & cellular  & 17 & ⋯ & 5 & 120 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.00000000, 0.0000000000, 1.000000e+00 & 0.432, 0.288, 0.064 & 0.0000000, 0.00000000, 1.000000000 & 0.4327573, 0.16228400, 0.0202854996 & 0.502 & 0.498\\\\\n\t45211 & 37 & entrepreneur & married  & secondary & no & 2971 & no  & no  & cellular  & 17 & ⋯ & 2 & 120 & 11 & 0.406988986, 0.33620829, 0.092579095 & 0.29346992, 0.4298632801, 2.098823e-01 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 1.000 & 0.000\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 43\n\n| <!--/--> | age &lt;int&gt; | job &lt;fct&gt; | marital &lt;fct&gt; | education &lt;fct&gt; | default &lt;fct&gt; | balance &lt;int&gt; | housing &lt;fct&gt; | loan &lt;fct&gt; | contact &lt;fct&gt; | day &lt;int&gt; | ⋯ ⋯ | campaign_11 &lt;dbl&gt; | pdays_120 &lt;dbl&gt; | previous_11 &lt;dbl&gt; | B_age &lt;dbl[,3]&gt; | B_balance &lt;dbl[,3]&gt; | B_campaign &lt;dbl[,3]&gt; | B_pdays &lt;dbl[,3]&gt; | B_previous &lt;dbl[,3]&gt; | X0 &lt;dbl&gt; | X1 &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 58 | management    | married  | tertiary  | no  |  2143 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.4197550723, 3.150000e-01, 7.879593e-02 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 2 | 44 | technician    | single   | secondary | no  |    29 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.0177811347, 1.073092e-04, 2.158705e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 4 | 47 | blue-collar   | married  | unknown   | no  |  1506 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.198453191, 0.44270327, 0.32918961 | 0.4412754278, 1.903269e-01, 2.736335e-02 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 6 | 35 | management    | married  | tertiary  | no  |   231 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.430231616, 0.29255750, 0.06631303 | 0.1265590834, 6.156785e-03, 9.983743e-05 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 8 | 42 | entrepreneur  | divorced | tertiary  | yes |     2 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.314868805, 0.41982507, 0.18658892 | 0.0017974816, 1.078921e-06, 2.158705e-10 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 10 | 43 | technician    | single   | secondary | no  |   593 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.292557499, 0.43023162, 0.21089785 | 0.2767089696, 3.729638e-02, 1.675671e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 11 | 41 | admin.        | divorced | secondary | no  |   270 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.336208293, 0.40698899, 0.16422363 | 0.1454260685, 8.332022e-03, 1.591246e-04 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 14 | 58 | technician    | married  | unknown   | no  |    71 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.0419566518, 6.128787e-04, 2.984193e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 16 | 51 | retired       | married  | primary   | no  |   229 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.108236152, 0.39686589, 0.48505831 | 0.1255733153, 6.053629e-03, 9.727762e-05 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 18 | 57 | blue-collar   | married  | primary   | no  |    52 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.0311233218, 3.333743e-04, 1.190302e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 19 | 60 | retired       | married  | primary   | no  |    60 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.000000000, 0.00000000, 1.00000000 | 0.0357054428, 4.408972e-04, 1.814759e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 22 | 56 | management    | married  | tertiary  | no  |   779 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.024619372, 0.23388403, 0.74063276 | 0.3333312248, 6.159639e-02, 3.794139e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 23 | 32 | blue-collar   | single   | primary   | no  |    23 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.444444444, 0.22222222, 0.03703704 | 0.0142592674, 6.876078e-05, 1.105257e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 24 | 25 | services      | married  | secondary | no  |    50 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.347222222, 0.06944444, 0.00462963 | 0.0299730726, 3.088135e-04, 1.060572e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 25 | 40 | retired       | married  | primary   | no  |     0 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.356333009, 0.39196631, 0.14372098 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 26 | 44 | admin.        | married  | secondary | no  |  -372 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 29 | 46 | management    | single   | secondary | no  |  -246 | yes | no  | unknown | 5 | ⋯ | 2 | -1 | 0 | 0.222222222, 0.44444444, 0.29629630 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.243, 0.027, 0.001 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 31 | 57 | technician    | married  | secondary | no  |   839 | no  | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.3488393019, 7.042178e-02, 4.738788e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 32 | 49 | management    | married  | tertiary  | no  |   378 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.151886945, 0.42804503, 0.40210290 | 0.1942002494, 1.592425e-02, 4.352583e-04 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 33 | 60 | admin.        | married  | secondary | no  |    39 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.000000000, 0.00000000, 1.00000000 | 0.0236128896, 1.903881e-04, 5.116929e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 34 | 59 | blue-collar   | married  | secondary | no  |     0 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.001660188, 0.06806770, 0.93025861 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 35 | 51 | management    | married  | tertiary  | no  | 10635 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.108236152, 0.39686589, 0.48505831 | 0.0000000000, 0.000000e+00, 1.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 36 | 57 | technician    | divorced | secondary | no  |    63 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.0374159623, 4.850358e-04, 2.095894e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 37 | 25 | blue-collar   | married  | secondary | no  |    -7 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.347222222, 0.06944444, 0.00462963 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 38 | 53 | technician    | married  | secondary | no  |    -3 | no  | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.069444444, 0.34722222, 0.57870370 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 41 | 44 | services      | divorced | secondary | no  |  2586 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.3615943628, 3.875081e-01, 1.384263e-01 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 46 | 36 | admin.        | single   | primary   | no  |  -171 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.419825073, 0.31486880, 0.07871720 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 47 | 58 | self-employed | married  | tertiary  | no  |  -364 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 50 | 29 | management    | single   | tertiary  | no  |     0 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.428045028, 0.15188695, 0.01796512 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| 52 | 48 | management    | divorced | tertiary  | no  |  -244 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.174927114, 0.43731778, 0.36443149 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 1 | 0 |\n| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n| 45152 | 47 | management   | single   | tertiary  | no |  311 | yes | yes | cellular  |  9 | ⋯ | 3 | 120 |  2 | 0.198453191, 0.44270327, 0.329189612 | 0.16453782, 0.0109481342, 2.428249e-04 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.3651390, 0.08114200, 0.0060105184 | 1.000 | 0.000 |\n| 45154 | 64 | retired      | married  | tertiary  | no | 2059 | no  | yes | cellular  |  9 | ⋯ | 1 |  95 |  1 | 0.000000000, 0.00000000, 1.000000000 | 0.42737387, 0.2993506161, 6.989258e-02 | 0.000, 0.000, 0.000 | 0.1016053, 0.39016438, 0.499410407 | 0.2253944, 0.02253944, 0.0007513148 | 0.816 | 0.184 |\n| 45155 | 63 | retired      | married  | primary   | no | 3738 | no  | no  | telephone |  9 | ⋯ | 1 | 120 |  4 | 0.000000000, 0.00000000, 1.000000000 | 0.14283179, 0.4231759485, 4.179226e-01 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 1.000000000 | 0.4417731, 0.25244177, 0.0480841473 | 1.000 | 0.000 |\n| 45156 | 44 | entrepreneur | married  | tertiary  | no |  121 | no  | no  | cellular  |  9 | ⋯ | 1 |  91 |  1 | 0.269517331, 0.43796566, 0.237231400 | 0.06965819, 0.0017418116, 1.451807e-05 | 0.000, 0.000, 0.000 | 0.1310234, 0.41566054, 0.439549076 | 0.2253944, 0.02253944, 0.0007513148 | 0.374 | 0.626 |\n| 45157 | 37 | management   | married  | tertiary  | no | 3556 | no  | no  | cellular  |  9 | ⋯ | 1 |  -1 |  0 | 0.406988986, 0.33620829, 0.092579095 | 0.17789713, 0.4382133607, 3.598165e-01 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45159 | 34 | student      | single   | unknown   | no | 2321 | no  | no  | cellular  |  9 | ⋯ | 2 |  99 |  5 | 0.437965662, 0.26951733, 0.055285606 | 0.39972226, 0.3464557994, 1.000959e-01 | 0.243, 0.027, 0.001 | 0.0746799, 0.35561858, 0.564473930 | 0.4057100, 0.33809166, 0.0939143501 | 0.940 | 0.060 |\n| 45162 | 31 | management   | married  | tertiary  | no |  720 | yes | no  | cellular  |  9 | ⋯ | 3 |  -1 |  0 | 0.442703272, 0.19845319, 0.029653925 | 0.31679148, 0.0533660415, 2.996645e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45163 | 29 | admin.       | single   | secondary | no |  464 | no  | no  | cellular  |  9 | ⋯ | 2 |  91 |  3 | 0.428045028, 0.15188695, 0.017965123 | 0.22948259, 0.0235250006, 8.038746e-04 | 0.243, 0.027, 0.001 | 0.1310234, 0.41566054, 0.439549076 | 0.4327573, 0.16228400, 0.0202854996 | 0.374 | 0.626 |\n| 45164 | 71 | retired      | married  | secondary | no | 2064 | no  | no  | cellular  |  9 | ⋯ | 2 |  92 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.42695573, 0.3002941379, 7.040275e-02 | 0.243, 0.027, 0.001 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.744 | 0.256 |\n| 45166 | 33 | technician   | married  | tertiary  | no | 2976 | yes | no  | cellular  |  9 | ⋯ | 2 |  95 | 11 | 0.442784257, 0.24599125, 0.045553936 | 0.29251662, 0.4302480083, 2.109434e-01 | 0.243, 0.027, 0.001 | 0.1016053, 0.39016438, 0.499410407 | 0.0000000, 0.00000000, 1.0000000000 | 0.816 | 0.184 |\n| 45169 | 62 | retired      | married  | tertiary  | no | 2557 | yes | no  | cellular  | 10 | ⋯ | 1 |  57 |  8 | 0.000000000, 0.00000000, 1.000000000 | 0.36618299, 0.3834204198, 1.338231e-01 | 0.000, 0.000, 0.000 | 0.3898291, 0.35889027, 0.110135637 | 0.1622840, 0.43275733, 0.3846731781 | 0.444 | 0.556 |\n| 45172 | 33 | admin.       | single   | secondary | no |  690 | no  | no  | cellular  | 10 | ⋯ | 3 | 120 | 11 | 0.442784257, 0.24599125, 0.045553936 | 0.30788128, 0.0493610121, 2.637932e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 1.000 | 0.000 |\n| 45175 | 62 | blue-collar  | married  | secondary | no |  272 | no  | no  | cellular  | 11 | ⋯ | 1 |  92 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.14637546, 0.0084518825, 1.626737e-04 | 0.000, 0.000, 0.000 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.402 | 0.598 |\n| 45177 | 54 | admin.       | married  | secondary | no |   66 | yes | no  | cellular  | 11 | ⋯ | 1 |  -1 |  0 | 0.052478134, 0.31486880, 0.629737609 | 0.03912225, 0.0005312506, 2.404661e-06 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45178 | 36 | admin.       | divorced | secondary | no | 1224 | yes | no  | cellular  | 12 | ⋯ | 1 | 120 |  1 | 0.419825073, 0.31486880, 0.078717201 | 0.41893896, 0.1359110770, 1.469730e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 1.000000000 | 0.2253944, 0.02253944, 0.0007513148 | 0.502 | 0.498 |\n| 45179 | 34 | blue-collar  | married  | secondary | no |  320 | yes | no  | cellular  | 12 | ⋯ | 1 |  92 |  3 | 0.437965662, 0.26951733, 0.055285606 | 0.16863489, 0.0115666238, 2.644506e-04 | 0.000, 0.000, 0.000 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.402 | 0.598 |\n| 45185 | 63 | retired      | married  | secondary | no | 1495 | no  | no  | cellular  | 16 | ⋯ | 1 |  22 |  5 | 0.000000000, 0.00000000, 1.000000000 | 0.44081699, 0.1881489939, 2.676851e-02 | 0.000, 0.000, 0.000 | 0.3740633, 0.08779037, 0.006867954 | 0.4057100, 0.33809166, 0.0939143501 | 0.458 | 0.542 |\n| 45188 | 32 | services     | single   | secondary | no | 1168 | yes | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.444444444, 0.22222222, 0.037037037 | 0.41173350, 0.1256045043, 1.277241e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45195 | 59 | management   | married  | tertiary  | no |  138 | yes | yes | cellular  | 16 | ⋯ | 2 | 120 |  5 | 0.001660188, 0.06806770, 0.930258611 | 0.07881255, 0.0022531767, 2.147207e-05 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 1.000000000 | 0.4057100, 0.33809166, 0.0939143501 | 1.000 | 0.000 |\n| 45197 | 25 | student      | single   | secondary | no |  358 | no  | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.347222222, 0.06944444, 0.004629630 | 0.18554763, 0.0143497629, 3.699242e-04 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45198 | 36 | management   | single   | secondary | no | 1511 | yes | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.419825073, 0.31486880, 0.078717201 | 0.44147328, 0.1913177404, 2.763661e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45199 | 37 | management   | married  | tertiary  | no | 1428 | no  | no  | cellular  | 16 | ⋯ | 2 |  -1 |  0 | 0.406988986, 0.33620829, 0.092579095 | 0.43732653, 0.1749550968, 2.333061e-02 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45200 | 34 | blue-collar  | single   | secondary | no | 1475 | yes | no  | cellular  | 16 | ⋯ | 3 | 120 | 11 | 0.437965662, 0.26951733, 0.055285606 | 0.43990135, 0.1841969893, 2.570920e-02 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 1.000 | 0.000 |\n| 45201 | 38 | technician   | married  | secondary | no |  557 | yes | no  | cellular  | 16 | ⋯ | 4 |  -1 |  0 | 0.391966310, 0.35633301, 0.107979700 | 0.26420286, 0.0331814532, 1.389095e-03 | 0.441, 0.189, 0.027 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45203 | 34 | admin.       | single   | secondary | no |  557 | no  | no  | cellular  | 17 | ⋯ | 1 |  -1 |  0 | 0.437965662, 0.26951733, 0.055285606 | 0.26420286, 0.0331814532, 1.389095e-03 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45204 | 23 | student      | single   | tertiary  | no |  113 | no  | no  | cellular  | 17 | ⋯ | 1 |  -1 |  0 | 0.277170392, 0.03745546, 0.001687183 | 0.06530407, 0.0015233606, 1.184524e-05 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45206 | 25 | technician   | single   | secondary | no |  505 | no  | yes | cellular  | 17 | ⋯ | 2 |  -1 |  0 | 0.347222222, 0.06944444, 0.004629630 | 0.24522266, 0.0276045976, 1.035812e-03 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45207 | 51 | technician   | married  | tertiary  | no |  825 | no  | no  | cellular  | 17 | ⋯ | 3 |  -1 |  0 | 0.108236152, 0.39686589, 0.485058309 | 0.34533747, 0.0683230532, 4.505776e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 1.000 | 0.000 |\n| 45209 | 72 | retired      | married  | secondary | no | 5715 | no  | no  | cellular  | 17 | ⋯ | 5 | 120 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.00000000, 0.0000000000, 1.000000e+00 | 0.432, 0.288, 0.064 | 0.0000000, 0.00000000, 1.000000000 | 0.4327573, 0.16228400, 0.0202854996 | 0.502 | 0.498 |\n| 45211 | 37 | entrepreneur | married  | secondary | no | 2971 | no  | no  | cellular  | 17 | ⋯ | 2 | 120 | 11 | 0.406988986, 0.33620829, 0.092579095 | 0.29346992, 0.4298632801, 2.098823e-01 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 1.000 | 0.000 |\n\n",
            "text/plain": [
              "      age job           marital  education default balance housing loan\n",
              "1     58  management    married  tertiary  no       2143   yes     no  \n",
              "2     44  technician    single   secondary no         29   yes     no  \n",
              "4     47  blue-collar   married  unknown   no       1506   yes     no  \n",
              "6     35  management    married  tertiary  no        231   yes     no  \n",
              "8     42  entrepreneur  divorced tertiary  yes         2   yes     no  \n",
              "10    43  technician    single   secondary no        593   yes     no  \n",
              "11    41  admin.        divorced secondary no        270   yes     no  \n",
              "14    58  technician    married  unknown   no         71   yes     no  \n",
              "16    51  retired       married  primary   no        229   yes     no  \n",
              "18    57  blue-collar   married  primary   no         52   yes     no  \n",
              "19    60  retired       married  primary   no         60   yes     no  \n",
              "22    56  management    married  tertiary  no        779   yes     no  \n",
              "23    32  blue-collar   single   primary   no         23   yes     yes \n",
              "24    25  services      married  secondary no         50   yes     no  \n",
              "25    40  retired       married  primary   no          0   yes     yes \n",
              "26    44  admin.        married  secondary no       -372   yes     no  \n",
              "29    46  management    single   secondary no       -246   yes     no  \n",
              "31    57  technician    married  secondary no        839   no      yes \n",
              "32    49  management    married  tertiary  no        378   yes     no  \n",
              "33    60  admin.        married  secondary no         39   yes     yes \n",
              "34    59  blue-collar   married  secondary no          0   yes     no  \n",
              "35    51  management    married  tertiary  no      10635   yes     no  \n",
              "36    57  technician    divorced secondary no         63   yes     no  \n",
              "37    25  blue-collar   married  secondary no         -7   yes     no  \n",
              "38    53  technician    married  secondary no         -3   no      no  \n",
              "41    44  services      divorced secondary no       2586   yes     no  \n",
              "46    36  admin.        single   primary   no       -171   yes     no  \n",
              "47    58  self-employed married  tertiary  no       -364   yes     no  \n",
              "50    29  management    single   tertiary  no          0   yes     no  \n",
              "52    48  management    divorced tertiary  no       -244   yes     no  \n",
              "⋮     ⋮   ⋮             ⋮        ⋮         ⋮       ⋮       ⋮       ⋮   \n",
              "45152 47  management    single   tertiary  no       311    yes     yes \n",
              "45154 64  retired       married  tertiary  no      2059    no      yes \n",
              "45155 63  retired       married  primary   no      3738    no      no  \n",
              "45156 44  entrepreneur  married  tertiary  no       121    no      no  \n",
              "45157 37  management    married  tertiary  no      3556    no      no  \n",
              "45159 34  student       single   unknown   no      2321    no      no  \n",
              "45162 31  management    married  tertiary  no       720    yes     no  \n",
              "45163 29  admin.        single   secondary no       464    no      no  \n",
              "45164 71  retired       married  secondary no      2064    no      no  \n",
              "45166 33  technician    married  tertiary  no      2976    yes     no  \n",
              "45169 62  retired       married  tertiary  no      2557    yes     no  \n",
              "45172 33  admin.        single   secondary no       690    no      no  \n",
              "45175 62  blue-collar   married  secondary no       272    no      no  \n",
              "45177 54  admin.        married  secondary no        66    yes     no  \n",
              "45178 36  admin.        divorced secondary no      1224    yes     no  \n",
              "45179 34  blue-collar   married  secondary no       320    yes     no  \n",
              "45185 63  retired       married  secondary no      1495    no      no  \n",
              "45188 32  services      single   secondary no      1168    yes     no  \n",
              "45195 59  management    married  tertiary  no       138    yes     yes \n",
              "45197 25  student       single   secondary no       358    no      no  \n",
              "45198 36  management    single   secondary no      1511    yes     no  \n",
              "45199 37  management    married  tertiary  no      1428    no      no  \n",
              "45200 34  blue-collar   single   secondary no      1475    yes     no  \n",
              "45201 38  technician    married  secondary no       557    yes     no  \n",
              "45203 34  admin.        single   secondary no       557    no      no  \n",
              "45204 23  student       single   tertiary  no       113    no      no  \n",
              "45206 25  technician    single   secondary no       505    no      yes \n",
              "45207 51  technician    married  tertiary  no       825    no      no  \n",
              "45209 72  retired       married  secondary no      5715    no      no  \n",
              "45211 37  entrepreneur  married  secondary no      2971    no      no  \n",
              "      contact   day ⋯ campaign_11 pdays_120 previous_11\n",
              "1     unknown   5   ⋯ 1           -1        0          \n",
              "2     unknown   5   ⋯ 1           -1        0          \n",
              "4     unknown   5   ⋯ 1           -1        0          \n",
              "6     unknown   5   ⋯ 1           -1        0          \n",
              "8     unknown   5   ⋯ 1           -1        0          \n",
              "10    unknown   5   ⋯ 1           -1        0          \n",
              "11    unknown   5   ⋯ 1           -1        0          \n",
              "14    unknown   5   ⋯ 1           -1        0          \n",
              "16    unknown   5   ⋯ 1           -1        0          \n",
              "18    unknown   5   ⋯ 1           -1        0          \n",
              "19    unknown   5   ⋯ 1           -1        0          \n",
              "22    unknown   5   ⋯ 1           -1        0          \n",
              "23    unknown   5   ⋯ 1           -1        0          \n",
              "24    unknown   5   ⋯ 1           -1        0          \n",
              "25    unknown   5   ⋯ 1           -1        0          \n",
              "26    unknown   5   ⋯ 1           -1        0          \n",
              "29    unknown   5   ⋯ 2           -1        0          \n",
              "31    unknown   5   ⋯ 1           -1        0          \n",
              "32    unknown   5   ⋯ 1           -1        0          \n",
              "33    unknown   5   ⋯ 1           -1        0          \n",
              "34    unknown   5   ⋯ 1           -1        0          \n",
              "35    unknown   5   ⋯ 1           -1        0          \n",
              "36    unknown   5   ⋯ 1           -1        0          \n",
              "37    unknown   5   ⋯ 1           -1        0          \n",
              "38    unknown   5   ⋯ 1           -1        0          \n",
              "41    unknown   5   ⋯ 1           -1        0          \n",
              "46    unknown   5   ⋯ 1           -1        0          \n",
              "47    unknown   5   ⋯ 1           -1        0          \n",
              "50    unknown   5   ⋯ 1           -1        0          \n",
              "52    unknown   5   ⋯ 1           -1        0          \n",
              "⋮     ⋮         ⋮   ⋱ ⋮           ⋮         ⋮          \n",
              "45152 cellular   9  ⋯ 3           120        2         \n",
              "45154 cellular   9  ⋯ 1            95        1         \n",
              "45155 telephone  9  ⋯ 1           120        4         \n",
              "45156 cellular   9  ⋯ 1            91        1         \n",
              "45157 cellular   9  ⋯ 1            -1        0         \n",
              "45159 cellular   9  ⋯ 2            99        5         \n",
              "45162 cellular   9  ⋯ 3            -1        0         \n",
              "45163 cellular   9  ⋯ 2            91        3         \n",
              "45164 cellular   9  ⋯ 2            92        3         \n",
              "45166 cellular   9  ⋯ 2            95       11         \n",
              "45169 cellular  10  ⋯ 1            57        8         \n",
              "45172 cellular  10  ⋯ 3           120       11         \n",
              "45175 cellular  11  ⋯ 1            92        3         \n",
              "45177 cellular  11  ⋯ 1            -1        0         \n",
              "45178 cellular  12  ⋯ 1           120        1         \n",
              "45179 cellular  12  ⋯ 1            92        3         \n",
              "45185 cellular  16  ⋯ 1            22        5         \n",
              "45188 cellular  16  ⋯ 1            -1        0         \n",
              "45195 cellular  16  ⋯ 2           120        5         \n",
              "45197 cellular  16  ⋯ 1            -1        0         \n",
              "45198 cellular  16  ⋯ 1            -1        0         \n",
              "45199 cellular  16  ⋯ 2            -1        0         \n",
              "45200 cellular  16  ⋯ 3           120       11         \n",
              "45201 cellular  16  ⋯ 4            -1        0         \n",
              "45203 cellular  17  ⋯ 1            -1        0         \n",
              "45204 cellular  17  ⋯ 1            -1        0         \n",
              "45206 cellular  17  ⋯ 2            -1        0         \n",
              "45207 cellular  17  ⋯ 3            -1        0         \n",
              "45209 cellular  17  ⋯ 5           120        3         \n",
              "45211 cellular  17  ⋯ 2           120       11         \n",
              "      B_age                               \n",
              "1     0.006478782, 0.12957564, 0.86383760 \n",
              "2     0.269517331, 0.43796566, 0.23723140 \n",
              "4     0.198453191, 0.44270327, 0.32918961 \n",
              "6     0.430231616, 0.29255750, 0.06631303 \n",
              "8     0.314868805, 0.41982507, 0.18658892 \n",
              "10    0.292557499, 0.43023162, 0.21089785 \n",
              "11    0.336208293, 0.40698899, 0.16422363 \n",
              "14    0.006478782, 0.12957564, 0.86383760 \n",
              "16    0.108236152, 0.39686589, 0.48505831 \n",
              "18    0.014212828, 0.18476676, 0.80065598 \n",
              "19    0.000000000, 0.00000000, 1.00000000 \n",
              "22    0.024619372, 0.23388403, 0.74063276 \n",
              "23    0.444444444, 0.22222222, 0.03703704 \n",
              "24    0.347222222, 0.06944444, 0.00462963 \n",
              "25    0.356333009, 0.39196631, 0.14372098 \n",
              "26    0.269517331, 0.43796566, 0.23723140 \n",
              "29    0.222222222, 0.44444444, 0.29629630 \n",
              "31    0.014212828, 0.18476676, 0.80065598 \n",
              "32    0.151886945, 0.42804503, 0.40210290 \n",
              "33    0.000000000, 0.00000000, 1.00000000 \n",
              "34    0.001660188, 0.06806770, 0.93025861 \n",
              "35    0.108236152, 0.39686589, 0.48505831 \n",
              "36    0.014212828, 0.18476676, 0.80065598 \n",
              "37    0.347222222, 0.06944444, 0.00462963 \n",
              "38    0.069444444, 0.34722222, 0.57870370 \n",
              "41    0.269517331, 0.43796566, 0.23723140 \n",
              "46    0.419825073, 0.31486880, 0.07871720 \n",
              "47    0.006478782, 0.12957564, 0.86383760 \n",
              "50    0.428045028, 0.15188695, 0.01796512 \n",
              "52    0.174927114, 0.43731778, 0.36443149 \n",
              "⋮     ⋮                                   \n",
              "45152 0.198453191, 0.44270327, 0.329189612\n",
              "45154 0.000000000, 0.00000000, 1.000000000\n",
              "45155 0.000000000, 0.00000000, 1.000000000\n",
              "45156 0.269517331, 0.43796566, 0.237231400\n",
              "45157 0.406988986, 0.33620829, 0.092579095\n",
              "45159 0.437965662, 0.26951733, 0.055285606\n",
              "45162 0.442703272, 0.19845319, 0.029653925\n",
              "45163 0.428045028, 0.15188695, 0.017965123\n",
              "45164 0.000000000, 0.00000000, 1.000000000\n",
              "45166 0.442784257, 0.24599125, 0.045553936\n",
              "45169 0.000000000, 0.00000000, 1.000000000\n",
              "45172 0.442784257, 0.24599125, 0.045553936\n",
              "45175 0.000000000, 0.00000000, 1.000000000\n",
              "45177 0.052478134, 0.31486880, 0.629737609\n",
              "45178 0.419825073, 0.31486880, 0.078717201\n",
              "45179 0.437965662, 0.26951733, 0.055285606\n",
              "45185 0.000000000, 0.00000000, 1.000000000\n",
              "45188 0.444444444, 0.22222222, 0.037037037\n",
              "45195 0.001660188, 0.06806770, 0.930258611\n",
              "45197 0.347222222, 0.06944444, 0.004629630\n",
              "45198 0.419825073, 0.31486880, 0.078717201\n",
              "45199 0.406988986, 0.33620829, 0.092579095\n",
              "45200 0.437965662, 0.26951733, 0.055285606\n",
              "45201 0.391966310, 0.35633301, 0.107979700\n",
              "45203 0.437965662, 0.26951733, 0.055285606\n",
              "45204 0.277170392, 0.03745546, 0.001687183\n",
              "45206 0.347222222, 0.06944444, 0.004629630\n",
              "45207 0.108236152, 0.39686589, 0.485058309\n",
              "45209 0.000000000, 0.00000000, 1.000000000\n",
              "45211 0.406988986, 0.33620829, 0.092579095\n",
              "      B_balance                                B_campaign         \n",
              "1     0.4197550723, 3.150000e-01, 7.879593e-02 0.000, 0.000, 0.000\n",
              "2     0.0177811347, 1.073092e-04, 2.158705e-07 0.000, 0.000, 0.000\n",
              "4     0.4412754278, 1.903269e-01, 2.736335e-02 0.000, 0.000, 0.000\n",
              "6     0.1265590834, 6.156785e-03, 9.983743e-05 0.000, 0.000, 0.000\n",
              "8     0.0017974816, 1.078921e-06, 2.158705e-10 0.000, 0.000, 0.000\n",
              "10    0.2767089696, 3.729638e-02, 1.675671e-03 0.000, 0.000, 0.000\n",
              "11    0.1454260685, 8.332022e-03, 1.591246e-04 0.000, 0.000, 0.000\n",
              "14    0.0419566518, 6.128787e-04, 2.984193e-06 0.000, 0.000, 0.000\n",
              "16    0.1255733153, 6.053629e-03, 9.727762e-05 0.000, 0.000, 0.000\n",
              "18    0.0311233218, 3.333743e-04, 1.190302e-06 0.000, 0.000, 0.000\n",
              "19    0.0357054428, 4.408972e-04, 1.814759e-06 0.000, 0.000, 0.000\n",
              "22    0.3333312248, 6.159639e-02, 3.794139e-03 0.000, 0.000, 0.000\n",
              "23    0.0142592674, 6.876078e-05, 1.105257e-07 0.000, 0.000, 0.000\n",
              "24    0.0299730726, 3.088135e-04, 1.060572e-06 0.000, 0.000, 0.000\n",
              "25    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "26    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "29    0.0000000000, 0.000000e+00, 0.000000e+00 0.243, 0.027, 0.001\n",
              "31    0.3488393019, 7.042178e-02, 4.738788e-03 0.000, 0.000, 0.000\n",
              "32    0.1942002494, 1.592425e-02, 4.352583e-04 0.000, 0.000, 0.000\n",
              "33    0.0236128896, 1.903881e-04, 5.116929e-07 0.000, 0.000, 0.000\n",
              "34    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "35    0.0000000000, 0.000000e+00, 1.000000e+00 0.000, 0.000, 0.000\n",
              "36    0.0374159623, 4.850358e-04, 2.095894e-06 0.000, 0.000, 0.000\n",
              "37    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "38    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "41    0.3615943628, 3.875081e-01, 1.384263e-01 0.000, 0.000, 0.000\n",
              "46    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "47    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "50    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "52    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "⋮     ⋮                                        ⋮                  \n",
              "45152 0.16453782, 0.0109481342, 2.428249e-04   0.384, 0.096, 0.008\n",
              "45154 0.42737387, 0.2993506161, 6.989258e-02   0.000, 0.000, 0.000\n",
              "45155 0.14283179, 0.4231759485, 4.179226e-01   0.000, 0.000, 0.000\n",
              "45156 0.06965819, 0.0017418116, 1.451807e-05   0.000, 0.000, 0.000\n",
              "45157 0.17789713, 0.4382133607, 3.598165e-01   0.000, 0.000, 0.000\n",
              "45159 0.39972226, 0.3464557994, 1.000959e-01   0.243, 0.027, 0.001\n",
              "45162 0.31679148, 0.0533660415, 2.996645e-03   0.384, 0.096, 0.008\n",
              "45163 0.22948259, 0.0235250006, 8.038746e-04   0.243, 0.027, 0.001\n",
              "45164 0.42695573, 0.3002941379, 7.040275e-02   0.243, 0.027, 0.001\n",
              "45166 0.29251662, 0.4302480083, 2.109434e-01   0.243, 0.027, 0.001\n",
              "45169 0.36618299, 0.3834204198, 1.338231e-01   0.000, 0.000, 0.000\n",
              "45172 0.30788128, 0.0493610121, 2.637932e-03   0.384, 0.096, 0.008\n",
              "45175 0.14637546, 0.0084518825, 1.626737e-04   0.000, 0.000, 0.000\n",
              "45177 0.03912225, 0.0005312506, 2.404661e-06   0.000, 0.000, 0.000\n",
              "45178 0.41893896, 0.1359110770, 1.469730e-02   0.000, 0.000, 0.000\n",
              "45179 0.16863489, 0.0115666238, 2.644506e-04   0.000, 0.000, 0.000\n",
              "45185 0.44081699, 0.1881489939, 2.676851e-02   0.000, 0.000, 0.000\n",
              "45188 0.41173350, 0.1256045043, 1.277241e-02   0.000, 0.000, 0.000\n",
              "45195 0.07881255, 0.0022531767, 2.147207e-05   0.243, 0.027, 0.001\n",
              "45197 0.18554763, 0.0143497629, 3.699242e-04   0.000, 0.000, 0.000\n",
              "45198 0.44147328, 0.1913177404, 2.763661e-02   0.000, 0.000, 0.000\n",
              "45199 0.43732653, 0.1749550968, 2.333061e-02   0.243, 0.027, 0.001\n",
              "45200 0.43990135, 0.1841969893, 2.570920e-02   0.384, 0.096, 0.008\n",
              "45201 0.26420286, 0.0331814532, 1.389095e-03   0.441, 0.189, 0.027\n",
              "45203 0.26420286, 0.0331814532, 1.389095e-03   0.000, 0.000, 0.000\n",
              "45204 0.06530407, 0.0015233606, 1.184524e-05   0.000, 0.000, 0.000\n",
              "45206 0.24522266, 0.0276045976, 1.035812e-03   0.243, 0.027, 0.001\n",
              "45207 0.34533747, 0.0683230532, 4.505776e-03   0.384, 0.096, 0.008\n",
              "45209 0.00000000, 0.0000000000, 1.000000e+00   0.432, 0.288, 0.064\n",
              "45211 0.29346992, 0.4298632801, 2.098823e-01   0.243, 0.027, 0.001\n",
              "      B_pdays                            B_previous                         \n",
              "1     0, 0, 0                            0, 0, 0                            \n",
              "2     0, 0, 0                            0, 0, 0                            \n",
              "4     0, 0, 0                            0, 0, 0                            \n",
              "6     0, 0, 0                            0, 0, 0                            \n",
              "8     0, 0, 0                            0, 0, 0                            \n",
              "10    0, 0, 0                            0, 0, 0                            \n",
              "11    0, 0, 0                            0, 0, 0                            \n",
              "14    0, 0, 0                            0, 0, 0                            \n",
              "16    0, 0, 0                            0, 0, 0                            \n",
              "18    0, 0, 0                            0, 0, 0                            \n",
              "19    0, 0, 0                            0, 0, 0                            \n",
              "22    0, 0, 0                            0, 0, 0                            \n",
              "23    0, 0, 0                            0, 0, 0                            \n",
              "24    0, 0, 0                            0, 0, 0                            \n",
              "25    0, 0, 0                            0, 0, 0                            \n",
              "26    0, 0, 0                            0, 0, 0                            \n",
              "29    0, 0, 0                            0, 0, 0                            \n",
              "31    0, 0, 0                            0, 0, 0                            \n",
              "32    0, 0, 0                            0, 0, 0                            \n",
              "33    0, 0, 0                            0, 0, 0                            \n",
              "34    0, 0, 0                            0, 0, 0                            \n",
              "35    0, 0, 0                            0, 0, 0                            \n",
              "36    0, 0, 0                            0, 0, 0                            \n",
              "37    0, 0, 0                            0, 0, 0                            \n",
              "38    0, 0, 0                            0, 0, 0                            \n",
              "41    0, 0, 0                            0, 0, 0                            \n",
              "46    0, 0, 0                            0, 0, 0                            \n",
              "47    0, 0, 0                            0, 0, 0                            \n",
              "50    0, 0, 0                            0, 0, 0                            \n",
              "52    0, 0, 0                            0, 0, 0                            \n",
              "⋮     ⋮                                  ⋮                                  \n",
              "45152 0.0000000, 0.00000000, 1.000000000 0.3651390, 0.08114200, 0.0060105184\n",
              "45154 0.1016053, 0.39016438, 0.499410407 0.2253944, 0.02253944, 0.0007513148\n",
              "45155 0.0000000, 0.00000000, 1.000000000 0.4417731, 0.25244177, 0.0480841473\n",
              "45156 0.1310234, 0.41566054, 0.439549076 0.2253944, 0.02253944, 0.0007513148\n",
              "45157 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45159 0.0746799, 0.35561858, 0.564473930 0.4057100, 0.33809166, 0.0939143501\n",
              "45162 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45163 0.1310234, 0.41566054, 0.439549076 0.4327573, 0.16228400, 0.0202854996\n",
              "45164 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45166 0.1016053, 0.39016438, 0.499410407 0.0000000, 0.00000000, 1.0000000000\n",
              "45169 0.3898291, 0.35889027, 0.110135637 0.1622840, 0.43275733, 0.3846731781\n",
              "45172 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "45175 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45177 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45178 0.0000000, 0.00000000, 1.000000000 0.2253944, 0.02253944, 0.0007513148\n",
              "45179 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45185 0.3740633, 0.08779037, 0.006867954 0.4057100, 0.33809166, 0.0939143501\n",
              "45188 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45195 0.0000000, 0.00000000, 1.000000000 0.4057100, 0.33809166, 0.0939143501\n",
              "45197 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45198 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45199 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45200 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "45201 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45203 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45204 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45206 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45207 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45209 0.0000000, 0.00000000, 1.000000000 0.4327573, 0.16228400, 0.0202854996\n",
              "45211 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "      X0    X1   \n",
              "1     1     0    \n",
              "2     1     0    \n",
              "4     1     0    \n",
              "6     1     0    \n",
              "8     1     0    \n",
              "10    1     0    \n",
              "11    1     0    \n",
              "14    1     0    \n",
              "16    1     0    \n",
              "18    1     0    \n",
              "19    1     0    \n",
              "22    1     0    \n",
              "23    1     0    \n",
              "24    1     0    \n",
              "25    1     0    \n",
              "26    1     0    \n",
              "29    1     0    \n",
              "31    1     0    \n",
              "32    1     0    \n",
              "33    1     0    \n",
              "34    1     0    \n",
              "35    1     0    \n",
              "36    1     0    \n",
              "37    1     0    \n",
              "38    1     0    \n",
              "41    1     0    \n",
              "46    1     0    \n",
              "47    1     0    \n",
              "50    1     0    \n",
              "52    1     0    \n",
              "⋮     ⋮     ⋮    \n",
              "45152 1.000 0.000\n",
              "45154 0.816 0.184\n",
              "45155 1.000 0.000\n",
              "45156 0.374 0.626\n",
              "45157 1.000 0.000\n",
              "45159 0.940 0.060\n",
              "45162 1.000 0.000\n",
              "45163 0.374 0.626\n",
              "45164 0.744 0.256\n",
              "45166 0.816 0.184\n",
              "45169 0.444 0.556\n",
              "45172 1.000 0.000\n",
              "45175 0.402 0.598\n",
              "45177 1.000 0.000\n",
              "45178 0.502 0.498\n",
              "45179 0.402 0.598\n",
              "45185 0.458 0.542\n",
              "45188 1.000 0.000\n",
              "45195 1.000 0.000\n",
              "45197 1.000 0.000\n",
              "45198 1.000 0.000\n",
              "45199 1.000 0.000\n",
              "45200 1.000 0.000\n",
              "45201 1.000 0.000\n",
              "45203 1.000 0.000\n",
              "45204 1.000 0.000\n",
              "45206 1.000 0.000\n",
              "45207 1.000 0.000\n",
              "45209 0.502 0.498\n",
              "45211 1.000 0.000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelRFTest_out_result_data <- data.frame(samp_o,predict(modelRFTest,samp_o,type=\"prob\"))\n",
        "modelRFTest_out_result_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93zegrM2lFPQ"
      },
      "outputs": [],
      "source": [
        "write.table(modelRFTest_out_result_data, file = \"/content/modelRFTest_out_result_data.csv\",row.names=F,sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelRFTest, scale = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "yTDWDy4KVQ_w",
        "outputId": "9cc0856f-3d00-4e6b-af1d-75049f073d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rf variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 39)\n",
              "\n",
              "                    Overall\n",
              "C_poutcomesuccess   100.000\n",
              "C_poutcomeunknown    20.018\n",
              "C_monthaug:B_pdays3  12.769\n",
              "C_monthmar:B_pdays3  12.025\n",
              "C_monthsep:B_pdays3  11.195\n",
              "C_monthoct:B_pdays3  10.477\n",
              "C_monthjul:B_pdays3   9.278\n",
              "C_monthjun:B_pdays3   8.503\n",
              "C_monthnov:B_pdays1   4.350\n",
              "C_monthmay:B_pdays3   4.149\n",
              "C_monthsep:B_pdays2   3.823\n",
              "C_monthaug:B_pdays1   3.779\n",
              "C_monthsep:B_pdays1   3.604\n",
              "C_monthaug:B_pdays2   3.388\n",
              "C_monthfeb:B_pdays2   3.295\n",
              "C_monthmay:B_pdays1   2.985\n",
              "C_monthnov:B_pdays2   2.848\n",
              "C_monthmay:B_pdays2   2.833\n",
              "C_monthjun:B_pdays2   2.689\n",
              "C_monthapr:B_pdays2   2.624"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zN1MzXTcPGDo",
        "outputId": "857b7e44-9c0a-4bf5-bb11-d8f2ee6905f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "26.0029062296708"
            ],
            "text/latex": "26.0029062296708",
            "text/markdown": "26.0029062296708",
            "text/plain": [
              "[1] 26.00291"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelRFTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelRFTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVo0yCd4A3fP"
      },
      "source": [
        "## 99-3-5.precitテスト_DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHuDoKwGA3fQ",
        "outputId": "cb9003e6-8e34-4809-dcd0-658525460d2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "“model fit failed for Resample11: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample12: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample13: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample14: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample15: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample16: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample17: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample18: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample19: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample20: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample21: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample22: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample23: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample24: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=0, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=0, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=2, layer2=1, layer3=1, hidden_dropout=0.0, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=0, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=0, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=1, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "training layer 2 autoencoder ...\n",
            "\n",
            "training layer 3 autoencoder ...\n",
            "\n",
            "Warning message:\n",
            "“model fit failed for Resample25: layer1=2, layer2=1, layer3=1, hidden_dropout=0.7, visible_dropout=0.7 Error in runif(size, min = 0, max = 1) : invalid arguments\n",
            "”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n",
            "Warning message in train.default(x, y, weights = w, ...):\n",
            "“missing values found in aggregated results”\n",
            "begin to train sae ......\n",
            "\n",
            "training layer 1 autoencoder ...\n",
            "\n",
            "sae has been trained.\n",
            "\n",
            "begin to train deep nn ......\n",
            "\n",
            "deep nn has been trained.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modelDNNTest <- train(\n",
        "  C_yF ~ C_poutcome  + C_month:B_pdays,\n",
        "  data = samp_i,\n",
        "  method = \"dnn\",\n",
        "  tuneLength = 2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SkG0-wNA3fQ"
      },
      "outputs": [],
      "source": [
        "modelDNNTest_out_result <- predict(modelDNNTest,samp_o,type=\"prob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OTtRUHDlA3fQ",
        "outputId": "f4e10829-7928-48e0-b327-08344e5dbe6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>25</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>26</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>35</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>38</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45152</th><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45154</th><td>0.6413766</td><td>0.3586234</td></tr>\n",
              "\t<tr><th scope=row>45155</th><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45156</th><td>0.6274899</td><td>0.3725101</td></tr>\n",
              "\t<tr><th scope=row>45157</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45159</th><td>0.6532363</td><td>0.3467637</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>0.6274899</td><td>0.3725101</td></tr>\n",
              "\t<tr><th scope=row>45164</th><td>0.6533850</td><td>0.3466150</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>0.6413766</td><td>0.3586234</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>0.6279270</td><td>0.3720730</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>0.6274767</td><td>0.3725233</td></tr>\n",
              "\t<tr><th scope=row>45177</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45178</th><td>0.6270424</td><td>0.3729576</td></tr>\n",
              "\t<tr><th scope=row>45179</th><td>0.6274767</td><td>0.3725233</td></tr>\n",
              "\t<tr><th scope=row>45185</th><td>0.6285563</td><td>0.3714437</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45195</th><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45197</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45199</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>0.6408124</td><td>0.3591876</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45206</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>0.6270424</td><td>0.3729576</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>0.6408124</td><td>0.3591876</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 2\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n  & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 0.6912076 & 0.3087924\\\\\n\t2 & 0.6912076 & 0.3087924\\\\\n\t4 & 0.6912076 & 0.3087924\\\\\n\t6 & 0.6912076 & 0.3087924\\\\\n\t8 & 0.6912076 & 0.3087924\\\\\n\t10 & 0.6912076 & 0.3087924\\\\\n\t11 & 0.6912076 & 0.3087924\\\\\n\t14 & 0.6912076 & 0.3087924\\\\\n\t16 & 0.6912076 & 0.3087924\\\\\n\t18 & 0.6912076 & 0.3087924\\\\\n\t19 & 0.6912076 & 0.3087924\\\\\n\t22 & 0.6912076 & 0.3087924\\\\\n\t23 & 0.6912076 & 0.3087924\\\\\n\t24 & 0.6912076 & 0.3087924\\\\\n\t25 & 0.6912076 & 0.3087924\\\\\n\t26 & 0.6912076 & 0.3087924\\\\\n\t29 & 0.6912076 & 0.3087924\\\\\n\t31 & 0.6912076 & 0.3087924\\\\\n\t32 & 0.6912076 & 0.3087924\\\\\n\t33 & 0.6912076 & 0.3087924\\\\\n\t34 & 0.6912076 & 0.3087924\\\\\n\t35 & 0.6912076 & 0.3087924\\\\\n\t36 & 0.6912076 & 0.3087924\\\\\n\t37 & 0.6912076 & 0.3087924\\\\\n\t38 & 0.6912076 & 0.3087924\\\\\n\t41 & 0.6912076 & 0.3087924\\\\\n\t46 & 0.6912076 & 0.3087924\\\\\n\t47 & 0.6912076 & 0.3087924\\\\\n\t50 & 0.6912076 & 0.3087924\\\\\n\t52 & 0.6912076 & 0.3087924\\\\\n\t⋮ & ⋮ & ⋮\\\\\n\t45152 & 0.6527043 & 0.3472957\\\\\n\t45154 & 0.6413766 & 0.3586234\\\\\n\t45155 & 0.6527043 & 0.3472957\\\\\n\t45156 & 0.6274899 & 0.3725101\\\\\n\t45157 & 0.6912076 & 0.3087924\\\\\n\t45159 & 0.6532363 & 0.3467637\\\\\n\t45162 & 0.6912076 & 0.3087924\\\\\n\t45163 & 0.6274899 & 0.3725101\\\\\n\t45164 & 0.6533850 & 0.3466150\\\\\n\t45166 & 0.6413766 & 0.3586234\\\\\n\t45169 & 0.6279270 & 0.3720730\\\\\n\t45172 & 0.6527043 & 0.3472957\\\\\n\t45175 & 0.6274767 & 0.3725233\\\\\n\t45177 & 0.6912076 & 0.3087924\\\\\n\t45178 & 0.6270424 & 0.3729576\\\\\n\t45179 & 0.6274767 & 0.3725233\\\\\n\t45185 & 0.6285563 & 0.3714437\\\\\n\t45188 & 0.6912076 & 0.3087924\\\\\n\t45195 & 0.6527043 & 0.3472957\\\\\n\t45197 & 0.6912076 & 0.3087924\\\\\n\t45198 & 0.6912076 & 0.3087924\\\\\n\t45199 & 0.6912076 & 0.3087924\\\\\n\t45200 & 0.6408124 & 0.3591876\\\\\n\t45201 & 0.6912076 & 0.3087924\\\\\n\t45203 & 0.6912076 & 0.3087924\\\\\n\t45204 & 0.6912076 & 0.3087924\\\\\n\t45206 & 0.6912076 & 0.3087924\\\\\n\t45207 & 0.6912076 & 0.3087924\\\\\n\t45209 & 0.6270424 & 0.3729576\\\\\n\t45211 & 0.6408124 & 0.3591876\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 2\n\n| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; |\n|---|---|---|\n| 1 | 0.6912076 | 0.3087924 |\n| 2 | 0.6912076 | 0.3087924 |\n| 4 | 0.6912076 | 0.3087924 |\n| 6 | 0.6912076 | 0.3087924 |\n| 8 | 0.6912076 | 0.3087924 |\n| 10 | 0.6912076 | 0.3087924 |\n| 11 | 0.6912076 | 0.3087924 |\n| 14 | 0.6912076 | 0.3087924 |\n| 16 | 0.6912076 | 0.3087924 |\n| 18 | 0.6912076 | 0.3087924 |\n| 19 | 0.6912076 | 0.3087924 |\n| 22 | 0.6912076 | 0.3087924 |\n| 23 | 0.6912076 | 0.3087924 |\n| 24 | 0.6912076 | 0.3087924 |\n| 25 | 0.6912076 | 0.3087924 |\n| 26 | 0.6912076 | 0.3087924 |\n| 29 | 0.6912076 | 0.3087924 |\n| 31 | 0.6912076 | 0.3087924 |\n| 32 | 0.6912076 | 0.3087924 |\n| 33 | 0.6912076 | 0.3087924 |\n| 34 | 0.6912076 | 0.3087924 |\n| 35 | 0.6912076 | 0.3087924 |\n| 36 | 0.6912076 | 0.3087924 |\n| 37 | 0.6912076 | 0.3087924 |\n| 38 | 0.6912076 | 0.3087924 |\n| 41 | 0.6912076 | 0.3087924 |\n| 46 | 0.6912076 | 0.3087924 |\n| 47 | 0.6912076 | 0.3087924 |\n| 50 | 0.6912076 | 0.3087924 |\n| 52 | 0.6912076 | 0.3087924 |\n| ⋮ | ⋮ | ⋮ |\n| 45152 | 0.6527043 | 0.3472957 |\n| 45154 | 0.6413766 | 0.3586234 |\n| 45155 | 0.6527043 | 0.3472957 |\n| 45156 | 0.6274899 | 0.3725101 |\n| 45157 | 0.6912076 | 0.3087924 |\n| 45159 | 0.6532363 | 0.3467637 |\n| 45162 | 0.6912076 | 0.3087924 |\n| 45163 | 0.6274899 | 0.3725101 |\n| 45164 | 0.6533850 | 0.3466150 |\n| 45166 | 0.6413766 | 0.3586234 |\n| 45169 | 0.6279270 | 0.3720730 |\n| 45172 | 0.6527043 | 0.3472957 |\n| 45175 | 0.6274767 | 0.3725233 |\n| 45177 | 0.6912076 | 0.3087924 |\n| 45178 | 0.6270424 | 0.3729576 |\n| 45179 | 0.6274767 | 0.3725233 |\n| 45185 | 0.6285563 | 0.3714437 |\n| 45188 | 0.6912076 | 0.3087924 |\n| 45195 | 0.6527043 | 0.3472957 |\n| 45197 | 0.6912076 | 0.3087924 |\n| 45198 | 0.6912076 | 0.3087924 |\n| 45199 | 0.6912076 | 0.3087924 |\n| 45200 | 0.6408124 | 0.3591876 |\n| 45201 | 0.6912076 | 0.3087924 |\n| 45203 | 0.6912076 | 0.3087924 |\n| 45204 | 0.6912076 | 0.3087924 |\n| 45206 | 0.6912076 | 0.3087924 |\n| 45207 | 0.6912076 | 0.3087924 |\n| 45209 | 0.6270424 | 0.3729576 |\n| 45211 | 0.6408124 | 0.3591876 |\n\n",
            "text/plain": [
              "      0         1        \n",
              "1     0.6912076 0.3087924\n",
              "2     0.6912076 0.3087924\n",
              "4     0.6912076 0.3087924\n",
              "6     0.6912076 0.3087924\n",
              "8     0.6912076 0.3087924\n",
              "10    0.6912076 0.3087924\n",
              "11    0.6912076 0.3087924\n",
              "14    0.6912076 0.3087924\n",
              "16    0.6912076 0.3087924\n",
              "18    0.6912076 0.3087924\n",
              "19    0.6912076 0.3087924\n",
              "22    0.6912076 0.3087924\n",
              "23    0.6912076 0.3087924\n",
              "24    0.6912076 0.3087924\n",
              "25    0.6912076 0.3087924\n",
              "26    0.6912076 0.3087924\n",
              "29    0.6912076 0.3087924\n",
              "31    0.6912076 0.3087924\n",
              "32    0.6912076 0.3087924\n",
              "33    0.6912076 0.3087924\n",
              "34    0.6912076 0.3087924\n",
              "35    0.6912076 0.3087924\n",
              "36    0.6912076 0.3087924\n",
              "37    0.6912076 0.3087924\n",
              "38    0.6912076 0.3087924\n",
              "41    0.6912076 0.3087924\n",
              "46    0.6912076 0.3087924\n",
              "47    0.6912076 0.3087924\n",
              "50    0.6912076 0.3087924\n",
              "52    0.6912076 0.3087924\n",
              "⋮     ⋮         ⋮        \n",
              "45152 0.6527043 0.3472957\n",
              "45154 0.6413766 0.3586234\n",
              "45155 0.6527043 0.3472957\n",
              "45156 0.6274899 0.3725101\n",
              "45157 0.6912076 0.3087924\n",
              "45159 0.6532363 0.3467637\n",
              "45162 0.6912076 0.3087924\n",
              "45163 0.6274899 0.3725101\n",
              "45164 0.6533850 0.3466150\n",
              "45166 0.6413766 0.3586234\n",
              "45169 0.6279270 0.3720730\n",
              "45172 0.6527043 0.3472957\n",
              "45175 0.6274767 0.3725233\n",
              "45177 0.6912076 0.3087924\n",
              "45178 0.6270424 0.3729576\n",
              "45179 0.6274767 0.3725233\n",
              "45185 0.6285563 0.3714437\n",
              "45188 0.6912076 0.3087924\n",
              "45195 0.6527043 0.3472957\n",
              "45197 0.6912076 0.3087924\n",
              "45198 0.6912076 0.3087924\n",
              "45199 0.6912076 0.3087924\n",
              "45200 0.6408124 0.3591876\n",
              "45201 0.6912076 0.3087924\n",
              "45203 0.6912076 0.3087924\n",
              "45204 0.6912076 0.3087924\n",
              "45206 0.6912076 0.3087924\n",
              "45207 0.6912076 0.3087924\n",
              "45209 0.6270424 0.3729576\n",
              "45211 0.6408124 0.3591876"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelDNNTest_out_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m-RyP6gNA3fR",
        "outputId": "0c172103-53f5-4379-9228-f527c4d14fe4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 22605 × 43</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>age</th><th scope=col>job</th><th scope=col>marital</th><th scope=col>education</th><th scope=col>default</th><th scope=col>balance</th><th scope=col>housing</th><th scope=col>loan</th><th scope=col>contact</th><th scope=col>day</th><th scope=col>⋯</th><th scope=col>campaign_11</th><th scope=col>pdays_120</th><th scope=col>previous_11</th><th scope=col>B_age</th><th scope=col>B_balance</th><th scope=col>B_campaign</th><th scope=col>B_pdays</th><th scope=col>B_previous</th><th scope=col>X0</th><th scope=col>X1</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl[,3]&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>58</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td> 2143</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.4197550723, 3.150000e-01, 7.879593e-02</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>44</td><td>technician   </td><td>single  </td><td>secondary</td><td>no </td><td>   29</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.0177811347, 1.073092e-04, 2.158705e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>47</td><td>blue-collar  </td><td>married </td><td>unknown  </td><td>no </td><td> 1506</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.198453191, 0.44270327, 0.32918961</td><td>0.4412754278, 1.903269e-01, 2.736335e-02</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>35</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  231</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.430231616, 0.29255750, 0.06631303</td><td>0.1265590834, 6.156785e-03, 9.983743e-05</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>42</td><td>entrepreneur </td><td>divorced</td><td>tertiary </td><td>yes</td><td>    2</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.314868805, 0.41982507, 0.18658892</td><td>0.0017974816, 1.078921e-06, 2.158705e-10</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>43</td><td>technician   </td><td>single  </td><td>secondary</td><td>no </td><td>  593</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.292557499, 0.43023162, 0.21089785</td><td>0.2767089696, 3.729638e-02, 1.675671e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>41</td><td>admin.       </td><td>divorced</td><td>secondary</td><td>no </td><td>  270</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.336208293, 0.40698899, 0.16422363</td><td>0.1454260685, 8.332022e-03, 1.591246e-04</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>58</td><td>technician   </td><td>married </td><td>unknown  </td><td>no </td><td>   71</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.0419566518, 6.128787e-04, 2.984193e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>51</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>  229</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.108236152, 0.39686589, 0.48505831</td><td>0.1255733153, 6.053629e-03, 9.727762e-05</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>57</td><td>blue-collar  </td><td>married </td><td>primary  </td><td>no </td><td>   52</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.0311233218, 3.333743e-04, 1.190302e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>60</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>   60</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.000000000, 0.00000000, 1.00000000</td><td>0.0357054428, 4.408972e-04, 1.814759e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>56</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  779</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.024619372, 0.23388403, 0.74063276</td><td>0.3333312248, 6.159639e-02, 3.794139e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>32</td><td>blue-collar  </td><td>single  </td><td>primary  </td><td>no </td><td>   23</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.444444444, 0.22222222, 0.03703704</td><td>0.0142592674, 6.876078e-05, 1.105257e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>25</td><td>services     </td><td>married </td><td>secondary</td><td>no </td><td>   50</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.347222222, 0.06944444, 0.00462963</td><td>0.0299730726, 3.088135e-04, 1.060572e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>25</th><td>40</td><td>retired      </td><td>married </td><td>primary  </td><td>no </td><td>    0</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.356333009, 0.39196631, 0.14372098</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>26</th><td>44</td><td>admin.       </td><td>married </td><td>secondary</td><td>no </td><td> -372</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>46</td><td>management   </td><td>single  </td><td>secondary</td><td>no </td><td> -246</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>2</td><td>-1</td><td>0</td><td>0.222222222, 0.44444444, 0.29629630</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.243, 0.027, 0.001</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>31</th><td>57</td><td>technician   </td><td>married </td><td>secondary</td><td>no </td><td>  839</td><td>no </td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.3488393019, 7.042178e-02, 4.738788e-03</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>32</th><td>49</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>  378</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.151886945, 0.42804503, 0.40210290</td><td>0.1942002494, 1.592425e-02, 4.352583e-04</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>60</td><td>admin.       </td><td>married </td><td>secondary</td><td>no </td><td>   39</td><td>yes</td><td>yes</td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.000000000, 0.00000000, 1.00000000</td><td>0.0236128896, 1.903881e-04, 5.116929e-07</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>34</th><td>59</td><td>blue-collar  </td><td>married </td><td>secondary</td><td>no </td><td>    0</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.001660188, 0.06806770, 0.93025861</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>35</th><td>51</td><td>management   </td><td>married </td><td>tertiary </td><td>no </td><td>10635</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.108236152, 0.39686589, 0.48505831</td><td>0.0000000000, 0.000000e+00, 1.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>57</td><td>technician   </td><td>divorced</td><td>secondary</td><td>no </td><td>   63</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.014212828, 0.18476676, 0.80065598</td><td>0.0374159623, 4.850358e-04, 2.095894e-06</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>25</td><td>blue-collar  </td><td>married </td><td>secondary</td><td>no </td><td>   -7</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.347222222, 0.06944444, 0.00462963</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>38</th><td>53</td><td>technician   </td><td>married </td><td>secondary</td><td>no </td><td>   -3</td><td>no </td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.069444444, 0.34722222, 0.57870370</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>41</th><td>44</td><td>services     </td><td>divorced</td><td>secondary</td><td>no </td><td> 2586</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.269517331, 0.43796566, 0.23723140</td><td>0.3615943628, 3.875081e-01, 1.384263e-01</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>36</td><td>admin.       </td><td>single  </td><td>primary  </td><td>no </td><td> -171</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.419825073, 0.31486880, 0.07871720</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>58</td><td>self-employed</td><td>married </td><td>tertiary </td><td>no </td><td> -364</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.006478782, 0.12957564, 0.86383760</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>29</td><td>management   </td><td>single  </td><td>tertiary </td><td>no </td><td>    0</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.428045028, 0.15188695, 0.01796512</td><td>0.0005996401, 1.199280e-07, 7.995202e-12</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>48</td><td>management   </td><td>divorced</td><td>tertiary </td><td>no </td><td> -244</td><td>yes</td><td>no </td><td>unknown</td><td>5</td><td>⋯</td><td>1</td><td>-1</td><td>0</td><td>0.174927114, 0.43731778, 0.36443149</td><td>0.0000000000, 0.000000e+00, 0.000000e+00</td><td>0.000, 0.000, 0.000</td><td>0, 0, 0</td><td>0, 0, 0</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>45152</th><td>47</td><td>management  </td><td>single  </td><td>tertiary </td><td>no</td><td> 311</td><td>yes</td><td>yes</td><td>cellular </td><td> 9</td><td>⋯</td><td>3</td><td>120</td><td> 2</td><td>0.198453191, 0.44270327, 0.329189612</td><td>0.16453782, 0.0109481342, 2.428249e-04</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.3651390, 0.08114200, 0.0060105184</td><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45154</th><td>64</td><td>retired     </td><td>married </td><td>tertiary </td><td>no</td><td>2059</td><td>no </td><td>yes</td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> 95</td><td> 1</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.42737387, 0.2993506161, 6.989258e-02</td><td>0.000, 0.000, 0.000</td><td>0.1016053, 0.39016438, 0.499410407</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.6413766</td><td>0.3586234</td></tr>\n",
              "\t<tr><th scope=row>45155</th><td>63</td><td>retired     </td><td>married </td><td>primary  </td><td>no</td><td>3738</td><td>no </td><td>no </td><td>telephone</td><td> 9</td><td>⋯</td><td>1</td><td>120</td><td> 4</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.14283179, 0.4231759485, 4.179226e-01</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4417731, 0.25244177, 0.0480841473</td><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45156</th><td>44</td><td>entrepreneur</td><td>married </td><td>tertiary </td><td>no</td><td> 121</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> 91</td><td> 1</td><td>0.269517331, 0.43796566, 0.237231400</td><td>0.06965819, 0.0017418116, 1.451807e-05</td><td>0.000, 0.000, 0.000</td><td>0.1310234, 0.41566054, 0.439549076</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.6274899</td><td>0.3725101</td></tr>\n",
              "\t<tr><th scope=row>45157</th><td>37</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td>3556</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.17789713, 0.4382133607, 3.598165e-01</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45159</th><td>34</td><td>student     </td><td>single  </td><td>unknown  </td><td>no</td><td>2321</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 99</td><td> 5</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.39972226, 0.3464557994, 1.000959e-01</td><td>0.243, 0.027, 0.001</td><td>0.0746799, 0.35561858, 0.564473930</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>0.6532363</td><td>0.3467637</td></tr>\n",
              "\t<tr><th scope=row>45162</th><td>31</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td> 720</td><td>yes</td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>3</td><td> -1</td><td> 0</td><td>0.442703272, 0.19845319, 0.029653925</td><td>0.31679148, 0.0533660415, 2.996645e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45163</th><td>29</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 464</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 91</td><td> 3</td><td>0.428045028, 0.15188695, 0.017965123</td><td>0.22948259, 0.0235250006, 8.038746e-04</td><td>0.243, 0.027, 0.001</td><td>0.1310234, 0.41566054, 0.439549076</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.6274899</td><td>0.3725101</td></tr>\n",
              "\t<tr><th scope=row>45164</th><td>71</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>2064</td><td>no </td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 92</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.42695573, 0.3002941379, 7.040275e-02</td><td>0.243, 0.027, 0.001</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.6533850</td><td>0.3466150</td></tr>\n",
              "\t<tr><th scope=row>45166</th><td>33</td><td>technician  </td><td>married </td><td>tertiary </td><td>no</td><td>2976</td><td>yes</td><td>no </td><td>cellular </td><td> 9</td><td>⋯</td><td>2</td><td> 95</td><td>11</td><td>0.442784257, 0.24599125, 0.045553936</td><td>0.29251662, 0.4302480083, 2.109434e-01</td><td>0.243, 0.027, 0.001</td><td>0.1016053, 0.39016438, 0.499410407</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>0.6413766</td><td>0.3586234</td></tr>\n",
              "\t<tr><th scope=row>45169</th><td>62</td><td>retired     </td><td>married </td><td>tertiary </td><td>no</td><td>2557</td><td>yes</td><td>no </td><td>cellular </td><td>10</td><td>⋯</td><td>1</td><td> 57</td><td> 8</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.36618299, 0.3834204198, 1.338231e-01</td><td>0.000, 0.000, 0.000</td><td>0.3898291, 0.35889027, 0.110135637</td><td>0.1622840, 0.43275733, 0.3846731781</td><td>0.6279270</td><td>0.3720730</td></tr>\n",
              "\t<tr><th scope=row>45172</th><td>33</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 690</td><td>no </td><td>no </td><td>cellular </td><td>10</td><td>⋯</td><td>3</td><td>120</td><td>11</td><td>0.442784257, 0.24599125, 0.045553936</td><td>0.30788128, 0.0493610121, 2.637932e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45175</th><td>62</td><td>blue-collar </td><td>married </td><td>secondary</td><td>no</td><td> 272</td><td>no </td><td>no </td><td>cellular </td><td>11</td><td>⋯</td><td>1</td><td> 92</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.14637546, 0.0084518825, 1.626737e-04</td><td>0.000, 0.000, 0.000</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.6274767</td><td>0.3725233</td></tr>\n",
              "\t<tr><th scope=row>45177</th><td>54</td><td>admin.      </td><td>married </td><td>secondary</td><td>no</td><td>  66</td><td>yes</td><td>no </td><td>cellular </td><td>11</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.052478134, 0.31486880, 0.629737609</td><td>0.03912225, 0.0005312506, 2.404661e-06</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45178</th><td>36</td><td>admin.      </td><td>divorced</td><td>secondary</td><td>no</td><td>1224</td><td>yes</td><td>no </td><td>cellular </td><td>12</td><td>⋯</td><td>1</td><td>120</td><td> 1</td><td>0.419825073, 0.31486880, 0.078717201</td><td>0.41893896, 0.1359110770, 1.469730e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.2253944, 0.02253944, 0.0007513148</td><td>0.6270424</td><td>0.3729576</td></tr>\n",
              "\t<tr><th scope=row>45179</th><td>34</td><td>blue-collar </td><td>married </td><td>secondary</td><td>no</td><td> 320</td><td>yes</td><td>no </td><td>cellular </td><td>12</td><td>⋯</td><td>1</td><td> 92</td><td> 3</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.16863489, 0.0115666238, 2.644506e-04</td><td>0.000, 0.000, 0.000</td><td>0.1234708, 0.41009934, 0.454038557</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.6274767</td><td>0.3725233</td></tr>\n",
              "\t<tr><th scope=row>45185</th><td>63</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>1495</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> 22</td><td> 5</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.44081699, 0.1881489939, 2.676851e-02</td><td>0.000, 0.000, 0.000</td><td>0.3740633, 0.08779037, 0.006867954</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>0.6285563</td><td>0.3714437</td></tr>\n",
              "\t<tr><th scope=row>45188</th><td>32</td><td>services    </td><td>single  </td><td>secondary</td><td>no</td><td>1168</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.444444444, 0.22222222, 0.037037037</td><td>0.41173350, 0.1256045043, 1.277241e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45195</th><td>59</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td> 138</td><td>yes</td><td>yes</td><td>cellular </td><td>16</td><td>⋯</td><td>2</td><td>120</td><td> 5</td><td>0.001660188, 0.06806770, 0.930258611</td><td>0.07881255, 0.0022531767, 2.147207e-05</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4057100, 0.33809166, 0.0939143501</td><td>0.6527043</td><td>0.3472957</td></tr>\n",
              "\t<tr><th scope=row>45197</th><td>25</td><td>student     </td><td>single  </td><td>secondary</td><td>no</td><td> 358</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.347222222, 0.06944444, 0.004629630</td><td>0.18554763, 0.0143497629, 3.699242e-04</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45198</th><td>36</td><td>management  </td><td>single  </td><td>secondary</td><td>no</td><td>1511</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.419825073, 0.31486880, 0.078717201</td><td>0.44147328, 0.1913177404, 2.763661e-02</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45199</th><td>37</td><td>management  </td><td>married </td><td>tertiary </td><td>no</td><td>1428</td><td>no </td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>2</td><td> -1</td><td> 0</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.43732653, 0.1749550968, 2.333061e-02</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45200</th><td>34</td><td>blue-collar </td><td>single  </td><td>secondary</td><td>no</td><td>1475</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>3</td><td>120</td><td>11</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.43990135, 0.1841969893, 2.570920e-02</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>0.6408124</td><td>0.3591876</td></tr>\n",
              "\t<tr><th scope=row>45201</th><td>38</td><td>technician  </td><td>married </td><td>secondary</td><td>no</td><td> 557</td><td>yes</td><td>no </td><td>cellular </td><td>16</td><td>⋯</td><td>4</td><td> -1</td><td> 0</td><td>0.391966310, 0.35633301, 0.107979700</td><td>0.26420286, 0.0331814532, 1.389095e-03</td><td>0.441, 0.189, 0.027</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45203</th><td>34</td><td>admin.      </td><td>single  </td><td>secondary</td><td>no</td><td> 557</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.437965662, 0.26951733, 0.055285606</td><td>0.26420286, 0.0331814532, 1.389095e-03</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45204</th><td>23</td><td>student     </td><td>single  </td><td>tertiary </td><td>no</td><td> 113</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>1</td><td> -1</td><td> 0</td><td>0.277170392, 0.03745546, 0.001687183</td><td>0.06530407, 0.0015233606, 1.184524e-05</td><td>0.000, 0.000, 0.000</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45206</th><td>25</td><td>technician  </td><td>single  </td><td>secondary</td><td>no</td><td> 505</td><td>no </td><td>yes</td><td>cellular </td><td>17</td><td>⋯</td><td>2</td><td> -1</td><td> 0</td><td>0.347222222, 0.06944444, 0.004629630</td><td>0.24522266, 0.0276045976, 1.035812e-03</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45207</th><td>51</td><td>technician  </td><td>married </td><td>tertiary </td><td>no</td><td> 825</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>3</td><td> -1</td><td> 0</td><td>0.108236152, 0.39686589, 0.485058309</td><td>0.34533747, 0.0683230532, 4.505776e-03</td><td>0.384, 0.096, 0.008</td><td>0.0000000, 0.00000000, 0.000000000</td><td>0.0000000, 0.00000000, 0.0000000000</td><td>0.6912076</td><td>0.3087924</td></tr>\n",
              "\t<tr><th scope=row>45209</th><td>72</td><td>retired     </td><td>married </td><td>secondary</td><td>no</td><td>5715</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>5</td><td>120</td><td> 3</td><td>0.000000000, 0.00000000, 1.000000000</td><td>0.00000000, 0.0000000000, 1.000000e+00</td><td>0.432, 0.288, 0.064</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.4327573, 0.16228400, 0.0202854996</td><td>0.6270424</td><td>0.3729576</td></tr>\n",
              "\t<tr><th scope=row>45211</th><td>37</td><td>entrepreneur</td><td>married </td><td>secondary</td><td>no</td><td>2971</td><td>no </td><td>no </td><td>cellular </td><td>17</td><td>⋯</td><td>2</td><td>120</td><td>11</td><td>0.406988986, 0.33620829, 0.092579095</td><td>0.29346992, 0.4298632801, 2.098823e-01</td><td>0.243, 0.027, 0.001</td><td>0.0000000, 0.00000000, 1.000000000</td><td>0.0000000, 0.00000000, 1.0000000000</td><td>0.6408124</td><td>0.3591876</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A data.frame: 22605 × 43\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & age & job & marital & education & default & balance & housing & loan & contact & day & ⋯ & campaign\\_11 & pdays\\_120 & previous\\_11 & B\\_age & B\\_balance & B\\_campaign & B\\_pdays & B\\_previous & X0 & X1\\\\\n  & <int> & <fct> & <fct> & <fct> & <fct> & <int> & <fct> & <fct> & <fct> & <int> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl{[},3{]}> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 58 & management    & married  & tertiary  & no  &  2143 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.4197550723, 3.150000e-01, 7.879593e-02 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t2 & 44 & technician    & single   & secondary & no  &    29 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.0177811347, 1.073092e-04, 2.158705e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t4 & 47 & blue-collar   & married  & unknown   & no  &  1506 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.198453191, 0.44270327, 0.32918961 & 0.4412754278, 1.903269e-01, 2.736335e-02 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t6 & 35 & management    & married  & tertiary  & no  &   231 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.430231616, 0.29255750, 0.06631303 & 0.1265590834, 6.156785e-03, 9.983743e-05 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t8 & 42 & entrepreneur  & divorced & tertiary  & yes &     2 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.314868805, 0.41982507, 0.18658892 & 0.0017974816, 1.078921e-06, 2.158705e-10 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t10 & 43 & technician    & single   & secondary & no  &   593 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.292557499, 0.43023162, 0.21089785 & 0.2767089696, 3.729638e-02, 1.675671e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t11 & 41 & admin.        & divorced & secondary & no  &   270 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.336208293, 0.40698899, 0.16422363 & 0.1454260685, 8.332022e-03, 1.591246e-04 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t14 & 58 & technician    & married  & unknown   & no  &    71 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.0419566518, 6.128787e-04, 2.984193e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t16 & 51 & retired       & married  & primary   & no  &   229 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.108236152, 0.39686589, 0.48505831 & 0.1255733153, 6.053629e-03, 9.727762e-05 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t18 & 57 & blue-collar   & married  & primary   & no  &    52 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.0311233218, 3.333743e-04, 1.190302e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t19 & 60 & retired       & married  & primary   & no  &    60 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.000000000, 0.00000000, 1.00000000 & 0.0357054428, 4.408972e-04, 1.814759e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t22 & 56 & management    & married  & tertiary  & no  &   779 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.024619372, 0.23388403, 0.74063276 & 0.3333312248, 6.159639e-02, 3.794139e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t23 & 32 & blue-collar   & single   & primary   & no  &    23 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.444444444, 0.22222222, 0.03703704 & 0.0142592674, 6.876078e-05, 1.105257e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t24 & 25 & services      & married  & secondary & no  &    50 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.347222222, 0.06944444, 0.00462963 & 0.0299730726, 3.088135e-04, 1.060572e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t25 & 40 & retired       & married  & primary   & no  &     0 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.356333009, 0.39196631, 0.14372098 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t26 & 44 & admin.        & married  & secondary & no  &  -372 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t29 & 46 & management    & single   & secondary & no  &  -246 & yes & no  & unknown & 5 & ⋯ & 2 & -1 & 0 & 0.222222222, 0.44444444, 0.29629630 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.243, 0.027, 0.001 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t31 & 57 & technician    & married  & secondary & no  &   839 & no  & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.3488393019, 7.042178e-02, 4.738788e-03 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t32 & 49 & management    & married  & tertiary  & no  &   378 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.151886945, 0.42804503, 0.40210290 & 0.1942002494, 1.592425e-02, 4.352583e-04 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t33 & 60 & admin.        & married  & secondary & no  &    39 & yes & yes & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.000000000, 0.00000000, 1.00000000 & 0.0236128896, 1.903881e-04, 5.116929e-07 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t34 & 59 & blue-collar   & married  & secondary & no  &     0 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.001660188, 0.06806770, 0.93025861 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t35 & 51 & management    & married  & tertiary  & no  & 10635 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.108236152, 0.39686589, 0.48505831 & 0.0000000000, 0.000000e+00, 1.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t36 & 57 & technician    & divorced & secondary & no  &    63 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.014212828, 0.18476676, 0.80065598 & 0.0374159623, 4.850358e-04, 2.095894e-06 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t37 & 25 & blue-collar   & married  & secondary & no  &    -7 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.347222222, 0.06944444, 0.00462963 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t38 & 53 & technician    & married  & secondary & no  &    -3 & no  & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.069444444, 0.34722222, 0.57870370 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t41 & 44 & services      & divorced & secondary & no  &  2586 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.269517331, 0.43796566, 0.23723140 & 0.3615943628, 3.875081e-01, 1.384263e-01 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t46 & 36 & admin.        & single   & primary   & no  &  -171 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.419825073, 0.31486880, 0.07871720 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t47 & 58 & self-employed & married  & tertiary  & no  &  -364 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.006478782, 0.12957564, 0.86383760 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t50 & 29 & management    & single   & tertiary  & no  &     0 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.428045028, 0.15188695, 0.01796512 & 0.0005996401, 1.199280e-07, 7.995202e-12 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t52 & 48 & management    & divorced & tertiary  & no  &  -244 & yes & no  & unknown & 5 & ⋯ & 1 & -1 & 0 & 0.174927114, 0.43731778, 0.36443149 & 0.0000000000, 0.000000e+00, 0.000000e+00 & 0.000, 0.000, 0.000 & 0, 0, 0 & 0, 0, 0 & 0.6912076 & 0.3087924\\\\\n\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n\t45152 & 47 & management   & single   & tertiary  & no &  311 & yes & yes & cellular  &  9 & ⋯ & 3 & 120 &  2 & 0.198453191, 0.44270327, 0.329189612 & 0.16453782, 0.0109481342, 2.428249e-04 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.3651390, 0.08114200, 0.0060105184 & 0.6527043 & 0.3472957\\\\\n\t45154 & 64 & retired      & married  & tertiary  & no & 2059 & no  & yes & cellular  &  9 & ⋯ & 1 &  95 &  1 & 0.000000000, 0.00000000, 1.000000000 & 0.42737387, 0.2993506161, 6.989258e-02 & 0.000, 0.000, 0.000 & 0.1016053, 0.39016438, 0.499410407 & 0.2253944, 0.02253944, 0.0007513148 & 0.6413766 & 0.3586234\\\\\n\t45155 & 63 & retired      & married  & primary   & no & 3738 & no  & no  & telephone &  9 & ⋯ & 1 & 120 &  4 & 0.000000000, 0.00000000, 1.000000000 & 0.14283179, 0.4231759485, 4.179226e-01 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 1.000000000 & 0.4417731, 0.25244177, 0.0480841473 & 0.6527043 & 0.3472957\\\\\n\t45156 & 44 & entrepreneur & married  & tertiary  & no &  121 & no  & no  & cellular  &  9 & ⋯ & 1 &  91 &  1 & 0.269517331, 0.43796566, 0.237231400 & 0.06965819, 0.0017418116, 1.451807e-05 & 0.000, 0.000, 0.000 & 0.1310234, 0.41566054, 0.439549076 & 0.2253944, 0.02253944, 0.0007513148 & 0.6274899 & 0.3725101\\\\\n\t45157 & 37 & management   & married  & tertiary  & no & 3556 & no  & no  & cellular  &  9 & ⋯ & 1 &  -1 &  0 & 0.406988986, 0.33620829, 0.092579095 & 0.17789713, 0.4382133607, 3.598165e-01 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45159 & 34 & student      & single   & unknown   & no & 2321 & no  & no  & cellular  &  9 & ⋯ & 2 &  99 &  5 & 0.437965662, 0.26951733, 0.055285606 & 0.39972226, 0.3464557994, 1.000959e-01 & 0.243, 0.027, 0.001 & 0.0746799, 0.35561858, 0.564473930 & 0.4057100, 0.33809166, 0.0939143501 & 0.6532363 & 0.3467637\\\\\n\t45162 & 31 & management   & married  & tertiary  & no &  720 & yes & no  & cellular  &  9 & ⋯ & 3 &  -1 &  0 & 0.442703272, 0.19845319, 0.029653925 & 0.31679148, 0.0533660415, 2.996645e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45163 & 29 & admin.       & single   & secondary & no &  464 & no  & no  & cellular  &  9 & ⋯ & 2 &  91 &  3 & 0.428045028, 0.15188695, 0.017965123 & 0.22948259, 0.0235250006, 8.038746e-04 & 0.243, 0.027, 0.001 & 0.1310234, 0.41566054, 0.439549076 & 0.4327573, 0.16228400, 0.0202854996 & 0.6274899 & 0.3725101\\\\\n\t45164 & 71 & retired      & married  & secondary & no & 2064 & no  & no  & cellular  &  9 & ⋯ & 2 &  92 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.42695573, 0.3002941379, 7.040275e-02 & 0.243, 0.027, 0.001 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.6533850 & 0.3466150\\\\\n\t45166 & 33 & technician   & married  & tertiary  & no & 2976 & yes & no  & cellular  &  9 & ⋯ & 2 &  95 & 11 & 0.442784257, 0.24599125, 0.045553936 & 0.29251662, 0.4302480083, 2.109434e-01 & 0.243, 0.027, 0.001 & 0.1016053, 0.39016438, 0.499410407 & 0.0000000, 0.00000000, 1.0000000000 & 0.6413766 & 0.3586234\\\\\n\t45169 & 62 & retired      & married  & tertiary  & no & 2557 & yes & no  & cellular  & 10 & ⋯ & 1 &  57 &  8 & 0.000000000, 0.00000000, 1.000000000 & 0.36618299, 0.3834204198, 1.338231e-01 & 0.000, 0.000, 0.000 & 0.3898291, 0.35889027, 0.110135637 & 0.1622840, 0.43275733, 0.3846731781 & 0.6279270 & 0.3720730\\\\\n\t45172 & 33 & admin.       & single   & secondary & no &  690 & no  & no  & cellular  & 10 & ⋯ & 3 & 120 & 11 & 0.442784257, 0.24599125, 0.045553936 & 0.30788128, 0.0493610121, 2.637932e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 0.6527043 & 0.3472957\\\\\n\t45175 & 62 & blue-collar  & married  & secondary & no &  272 & no  & no  & cellular  & 11 & ⋯ & 1 &  92 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.14637546, 0.0084518825, 1.626737e-04 & 0.000, 0.000, 0.000 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.6274767 & 0.3725233\\\\\n\t45177 & 54 & admin.       & married  & secondary & no &   66 & yes & no  & cellular  & 11 & ⋯ & 1 &  -1 &  0 & 0.052478134, 0.31486880, 0.629737609 & 0.03912225, 0.0005312506, 2.404661e-06 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45178 & 36 & admin.       & divorced & secondary & no & 1224 & yes & no  & cellular  & 12 & ⋯ & 1 & 120 &  1 & 0.419825073, 0.31486880, 0.078717201 & 0.41893896, 0.1359110770, 1.469730e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 1.000000000 & 0.2253944, 0.02253944, 0.0007513148 & 0.6270424 & 0.3729576\\\\\n\t45179 & 34 & blue-collar  & married  & secondary & no &  320 & yes & no  & cellular  & 12 & ⋯ & 1 &  92 &  3 & 0.437965662, 0.26951733, 0.055285606 & 0.16863489, 0.0115666238, 2.644506e-04 & 0.000, 0.000, 0.000 & 0.1234708, 0.41009934, 0.454038557 & 0.4327573, 0.16228400, 0.0202854996 & 0.6274767 & 0.3725233\\\\\n\t45185 & 63 & retired      & married  & secondary & no & 1495 & no  & no  & cellular  & 16 & ⋯ & 1 &  22 &  5 & 0.000000000, 0.00000000, 1.000000000 & 0.44081699, 0.1881489939, 2.676851e-02 & 0.000, 0.000, 0.000 & 0.3740633, 0.08779037, 0.006867954 & 0.4057100, 0.33809166, 0.0939143501 & 0.6285563 & 0.3714437\\\\\n\t45188 & 32 & services     & single   & secondary & no & 1168 & yes & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.444444444, 0.22222222, 0.037037037 & 0.41173350, 0.1256045043, 1.277241e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45195 & 59 & management   & married  & tertiary  & no &  138 & yes & yes & cellular  & 16 & ⋯ & 2 & 120 &  5 & 0.001660188, 0.06806770, 0.930258611 & 0.07881255, 0.0022531767, 2.147207e-05 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 1.000000000 & 0.4057100, 0.33809166, 0.0939143501 & 0.6527043 & 0.3472957\\\\\n\t45197 & 25 & student      & single   & secondary & no &  358 & no  & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.347222222, 0.06944444, 0.004629630 & 0.18554763, 0.0143497629, 3.699242e-04 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45198 & 36 & management   & single   & secondary & no & 1511 & yes & no  & cellular  & 16 & ⋯ & 1 &  -1 &  0 & 0.419825073, 0.31486880, 0.078717201 & 0.44147328, 0.1913177404, 2.763661e-02 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45199 & 37 & management   & married  & tertiary  & no & 1428 & no  & no  & cellular  & 16 & ⋯ & 2 &  -1 &  0 & 0.406988986, 0.33620829, 0.092579095 & 0.43732653, 0.1749550968, 2.333061e-02 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45200 & 34 & blue-collar  & single   & secondary & no & 1475 & yes & no  & cellular  & 16 & ⋯ & 3 & 120 & 11 & 0.437965662, 0.26951733, 0.055285606 & 0.43990135, 0.1841969893, 2.570920e-02 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 0.6408124 & 0.3591876\\\\\n\t45201 & 38 & technician   & married  & secondary & no &  557 & yes & no  & cellular  & 16 & ⋯ & 4 &  -1 &  0 & 0.391966310, 0.35633301, 0.107979700 & 0.26420286, 0.0331814532, 1.389095e-03 & 0.441, 0.189, 0.027 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45203 & 34 & admin.       & single   & secondary & no &  557 & no  & no  & cellular  & 17 & ⋯ & 1 &  -1 &  0 & 0.437965662, 0.26951733, 0.055285606 & 0.26420286, 0.0331814532, 1.389095e-03 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45204 & 23 & student      & single   & tertiary  & no &  113 & no  & no  & cellular  & 17 & ⋯ & 1 &  -1 &  0 & 0.277170392, 0.03745546, 0.001687183 & 0.06530407, 0.0015233606, 1.184524e-05 & 0.000, 0.000, 0.000 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45206 & 25 & technician   & single   & secondary & no &  505 & no  & yes & cellular  & 17 & ⋯ & 2 &  -1 &  0 & 0.347222222, 0.06944444, 0.004629630 & 0.24522266, 0.0276045976, 1.035812e-03 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45207 & 51 & technician   & married  & tertiary  & no &  825 & no  & no  & cellular  & 17 & ⋯ & 3 &  -1 &  0 & 0.108236152, 0.39686589, 0.485058309 & 0.34533747, 0.0683230532, 4.505776e-03 & 0.384, 0.096, 0.008 & 0.0000000, 0.00000000, 0.000000000 & 0.0000000, 0.00000000, 0.0000000000 & 0.6912076 & 0.3087924\\\\\n\t45209 & 72 & retired      & married  & secondary & no & 5715 & no  & no  & cellular  & 17 & ⋯ & 5 & 120 &  3 & 0.000000000, 0.00000000, 1.000000000 & 0.00000000, 0.0000000000, 1.000000e+00 & 0.432, 0.288, 0.064 & 0.0000000, 0.00000000, 1.000000000 & 0.4327573, 0.16228400, 0.0202854996 & 0.6270424 & 0.3729576\\\\\n\t45211 & 37 & entrepreneur & married  & secondary & no & 2971 & no  & no  & cellular  & 17 & ⋯ & 2 & 120 & 11 & 0.406988986, 0.33620829, 0.092579095 & 0.29346992, 0.4298632801, 2.098823e-01 & 0.243, 0.027, 0.001 & 0.0000000, 0.00000000, 1.000000000 & 0.0000000, 0.00000000, 1.0000000000 & 0.6408124 & 0.3591876\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 22605 × 43\n\n| <!--/--> | age &lt;int&gt; | job &lt;fct&gt; | marital &lt;fct&gt; | education &lt;fct&gt; | default &lt;fct&gt; | balance &lt;int&gt; | housing &lt;fct&gt; | loan &lt;fct&gt; | contact &lt;fct&gt; | day &lt;int&gt; | ⋯ ⋯ | campaign_11 &lt;dbl&gt; | pdays_120 &lt;dbl&gt; | previous_11 &lt;dbl&gt; | B_age &lt;dbl[,3]&gt; | B_balance &lt;dbl[,3]&gt; | B_campaign &lt;dbl[,3]&gt; | B_pdays &lt;dbl[,3]&gt; | B_previous &lt;dbl[,3]&gt; | X0 &lt;dbl&gt; | X1 &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 58 | management    | married  | tertiary  | no  |  2143 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.4197550723, 3.150000e-01, 7.879593e-02 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 2 | 44 | technician    | single   | secondary | no  |    29 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.0177811347, 1.073092e-04, 2.158705e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 4 | 47 | blue-collar   | married  | unknown   | no  |  1506 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.198453191, 0.44270327, 0.32918961 | 0.4412754278, 1.903269e-01, 2.736335e-02 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 6 | 35 | management    | married  | tertiary  | no  |   231 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.430231616, 0.29255750, 0.06631303 | 0.1265590834, 6.156785e-03, 9.983743e-05 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 8 | 42 | entrepreneur  | divorced | tertiary  | yes |     2 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.314868805, 0.41982507, 0.18658892 | 0.0017974816, 1.078921e-06, 2.158705e-10 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 10 | 43 | technician    | single   | secondary | no  |   593 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.292557499, 0.43023162, 0.21089785 | 0.2767089696, 3.729638e-02, 1.675671e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 11 | 41 | admin.        | divorced | secondary | no  |   270 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.336208293, 0.40698899, 0.16422363 | 0.1454260685, 8.332022e-03, 1.591246e-04 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 14 | 58 | technician    | married  | unknown   | no  |    71 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.0419566518, 6.128787e-04, 2.984193e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 16 | 51 | retired       | married  | primary   | no  |   229 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.108236152, 0.39686589, 0.48505831 | 0.1255733153, 6.053629e-03, 9.727762e-05 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 18 | 57 | blue-collar   | married  | primary   | no  |    52 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.0311233218, 3.333743e-04, 1.190302e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 19 | 60 | retired       | married  | primary   | no  |    60 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.000000000, 0.00000000, 1.00000000 | 0.0357054428, 4.408972e-04, 1.814759e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 22 | 56 | management    | married  | tertiary  | no  |   779 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.024619372, 0.23388403, 0.74063276 | 0.3333312248, 6.159639e-02, 3.794139e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 23 | 32 | blue-collar   | single   | primary   | no  |    23 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.444444444, 0.22222222, 0.03703704 | 0.0142592674, 6.876078e-05, 1.105257e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 24 | 25 | services      | married  | secondary | no  |    50 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.347222222, 0.06944444, 0.00462963 | 0.0299730726, 3.088135e-04, 1.060572e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 25 | 40 | retired       | married  | primary   | no  |     0 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.356333009, 0.39196631, 0.14372098 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 26 | 44 | admin.        | married  | secondary | no  |  -372 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 29 | 46 | management    | single   | secondary | no  |  -246 | yes | no  | unknown | 5 | ⋯ | 2 | -1 | 0 | 0.222222222, 0.44444444, 0.29629630 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.243, 0.027, 0.001 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 31 | 57 | technician    | married  | secondary | no  |   839 | no  | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.3488393019, 7.042178e-02, 4.738788e-03 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 32 | 49 | management    | married  | tertiary  | no  |   378 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.151886945, 0.42804503, 0.40210290 | 0.1942002494, 1.592425e-02, 4.352583e-04 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 33 | 60 | admin.        | married  | secondary | no  |    39 | yes | yes | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.000000000, 0.00000000, 1.00000000 | 0.0236128896, 1.903881e-04, 5.116929e-07 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 34 | 59 | blue-collar   | married  | secondary | no  |     0 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.001660188, 0.06806770, 0.93025861 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 35 | 51 | management    | married  | tertiary  | no  | 10635 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.108236152, 0.39686589, 0.48505831 | 0.0000000000, 0.000000e+00, 1.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 36 | 57 | technician    | divorced | secondary | no  |    63 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.014212828, 0.18476676, 0.80065598 | 0.0374159623, 4.850358e-04, 2.095894e-06 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 37 | 25 | blue-collar   | married  | secondary | no  |    -7 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.347222222, 0.06944444, 0.00462963 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 38 | 53 | technician    | married  | secondary | no  |    -3 | no  | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.069444444, 0.34722222, 0.57870370 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 41 | 44 | services      | divorced | secondary | no  |  2586 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.269517331, 0.43796566, 0.23723140 | 0.3615943628, 3.875081e-01, 1.384263e-01 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 46 | 36 | admin.        | single   | primary   | no  |  -171 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.419825073, 0.31486880, 0.07871720 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 47 | 58 | self-employed | married  | tertiary  | no  |  -364 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.006478782, 0.12957564, 0.86383760 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 50 | 29 | management    | single   | tertiary  | no  |     0 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.428045028, 0.15188695, 0.01796512 | 0.0005996401, 1.199280e-07, 7.995202e-12 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| 52 | 48 | management    | divorced | tertiary  | no  |  -244 | yes | no  | unknown | 5 | ⋯ | 1 | -1 | 0 | 0.174927114, 0.43731778, 0.36443149 | 0.0000000000, 0.000000e+00, 0.000000e+00 | 0.000, 0.000, 0.000 | 0, 0, 0 | 0, 0, 0 | 0.6912076 | 0.3087924 |\n| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n| 45152 | 47 | management   | single   | tertiary  | no |  311 | yes | yes | cellular  |  9 | ⋯ | 3 | 120 |  2 | 0.198453191, 0.44270327, 0.329189612 | 0.16453782, 0.0109481342, 2.428249e-04 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.3651390, 0.08114200, 0.0060105184 | 0.6527043 | 0.3472957 |\n| 45154 | 64 | retired      | married  | tertiary  | no | 2059 | no  | yes | cellular  |  9 | ⋯ | 1 |  95 |  1 | 0.000000000, 0.00000000, 1.000000000 | 0.42737387, 0.2993506161, 6.989258e-02 | 0.000, 0.000, 0.000 | 0.1016053, 0.39016438, 0.499410407 | 0.2253944, 0.02253944, 0.0007513148 | 0.6413766 | 0.3586234 |\n| 45155 | 63 | retired      | married  | primary   | no | 3738 | no  | no  | telephone |  9 | ⋯ | 1 | 120 |  4 | 0.000000000, 0.00000000, 1.000000000 | 0.14283179, 0.4231759485, 4.179226e-01 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 1.000000000 | 0.4417731, 0.25244177, 0.0480841473 | 0.6527043 | 0.3472957 |\n| 45156 | 44 | entrepreneur | married  | tertiary  | no |  121 | no  | no  | cellular  |  9 | ⋯ | 1 |  91 |  1 | 0.269517331, 0.43796566, 0.237231400 | 0.06965819, 0.0017418116, 1.451807e-05 | 0.000, 0.000, 0.000 | 0.1310234, 0.41566054, 0.439549076 | 0.2253944, 0.02253944, 0.0007513148 | 0.6274899 | 0.3725101 |\n| 45157 | 37 | management   | married  | tertiary  | no | 3556 | no  | no  | cellular  |  9 | ⋯ | 1 |  -1 |  0 | 0.406988986, 0.33620829, 0.092579095 | 0.17789713, 0.4382133607, 3.598165e-01 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45159 | 34 | student      | single   | unknown   | no | 2321 | no  | no  | cellular  |  9 | ⋯ | 2 |  99 |  5 | 0.437965662, 0.26951733, 0.055285606 | 0.39972226, 0.3464557994, 1.000959e-01 | 0.243, 0.027, 0.001 | 0.0746799, 0.35561858, 0.564473930 | 0.4057100, 0.33809166, 0.0939143501 | 0.6532363 | 0.3467637 |\n| 45162 | 31 | management   | married  | tertiary  | no |  720 | yes | no  | cellular  |  9 | ⋯ | 3 |  -1 |  0 | 0.442703272, 0.19845319, 0.029653925 | 0.31679148, 0.0533660415, 2.996645e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45163 | 29 | admin.       | single   | secondary | no |  464 | no  | no  | cellular  |  9 | ⋯ | 2 |  91 |  3 | 0.428045028, 0.15188695, 0.017965123 | 0.22948259, 0.0235250006, 8.038746e-04 | 0.243, 0.027, 0.001 | 0.1310234, 0.41566054, 0.439549076 | 0.4327573, 0.16228400, 0.0202854996 | 0.6274899 | 0.3725101 |\n| 45164 | 71 | retired      | married  | secondary | no | 2064 | no  | no  | cellular  |  9 | ⋯ | 2 |  92 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.42695573, 0.3002941379, 7.040275e-02 | 0.243, 0.027, 0.001 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.6533850 | 0.3466150 |\n| 45166 | 33 | technician   | married  | tertiary  | no | 2976 | yes | no  | cellular  |  9 | ⋯ | 2 |  95 | 11 | 0.442784257, 0.24599125, 0.045553936 | 0.29251662, 0.4302480083, 2.109434e-01 | 0.243, 0.027, 0.001 | 0.1016053, 0.39016438, 0.499410407 | 0.0000000, 0.00000000, 1.0000000000 | 0.6413766 | 0.3586234 |\n| 45169 | 62 | retired      | married  | tertiary  | no | 2557 | yes | no  | cellular  | 10 | ⋯ | 1 |  57 |  8 | 0.000000000, 0.00000000, 1.000000000 | 0.36618299, 0.3834204198, 1.338231e-01 | 0.000, 0.000, 0.000 | 0.3898291, 0.35889027, 0.110135637 | 0.1622840, 0.43275733, 0.3846731781 | 0.6279270 | 0.3720730 |\n| 45172 | 33 | admin.       | single   | secondary | no |  690 | no  | no  | cellular  | 10 | ⋯ | 3 | 120 | 11 | 0.442784257, 0.24599125, 0.045553936 | 0.30788128, 0.0493610121, 2.637932e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 0.6527043 | 0.3472957 |\n| 45175 | 62 | blue-collar  | married  | secondary | no |  272 | no  | no  | cellular  | 11 | ⋯ | 1 |  92 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.14637546, 0.0084518825, 1.626737e-04 | 0.000, 0.000, 0.000 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.6274767 | 0.3725233 |\n| 45177 | 54 | admin.       | married  | secondary | no |   66 | yes | no  | cellular  | 11 | ⋯ | 1 |  -1 |  0 | 0.052478134, 0.31486880, 0.629737609 | 0.03912225, 0.0005312506, 2.404661e-06 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45178 | 36 | admin.       | divorced | secondary | no | 1224 | yes | no  | cellular  | 12 | ⋯ | 1 | 120 |  1 | 0.419825073, 0.31486880, 0.078717201 | 0.41893896, 0.1359110770, 1.469730e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 1.000000000 | 0.2253944, 0.02253944, 0.0007513148 | 0.6270424 | 0.3729576 |\n| 45179 | 34 | blue-collar  | married  | secondary | no |  320 | yes | no  | cellular  | 12 | ⋯ | 1 |  92 |  3 | 0.437965662, 0.26951733, 0.055285606 | 0.16863489, 0.0115666238, 2.644506e-04 | 0.000, 0.000, 0.000 | 0.1234708, 0.41009934, 0.454038557 | 0.4327573, 0.16228400, 0.0202854996 | 0.6274767 | 0.3725233 |\n| 45185 | 63 | retired      | married  | secondary | no | 1495 | no  | no  | cellular  | 16 | ⋯ | 1 |  22 |  5 | 0.000000000, 0.00000000, 1.000000000 | 0.44081699, 0.1881489939, 2.676851e-02 | 0.000, 0.000, 0.000 | 0.3740633, 0.08779037, 0.006867954 | 0.4057100, 0.33809166, 0.0939143501 | 0.6285563 | 0.3714437 |\n| 45188 | 32 | services     | single   | secondary | no | 1168 | yes | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.444444444, 0.22222222, 0.037037037 | 0.41173350, 0.1256045043, 1.277241e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45195 | 59 | management   | married  | tertiary  | no |  138 | yes | yes | cellular  | 16 | ⋯ | 2 | 120 |  5 | 0.001660188, 0.06806770, 0.930258611 | 0.07881255, 0.0022531767, 2.147207e-05 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 1.000000000 | 0.4057100, 0.33809166, 0.0939143501 | 0.6527043 | 0.3472957 |\n| 45197 | 25 | student      | single   | secondary | no |  358 | no  | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.347222222, 0.06944444, 0.004629630 | 0.18554763, 0.0143497629, 3.699242e-04 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45198 | 36 | management   | single   | secondary | no | 1511 | yes | no  | cellular  | 16 | ⋯ | 1 |  -1 |  0 | 0.419825073, 0.31486880, 0.078717201 | 0.44147328, 0.1913177404, 2.763661e-02 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45199 | 37 | management   | married  | tertiary  | no | 1428 | no  | no  | cellular  | 16 | ⋯ | 2 |  -1 |  0 | 0.406988986, 0.33620829, 0.092579095 | 0.43732653, 0.1749550968, 2.333061e-02 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45200 | 34 | blue-collar  | single   | secondary | no | 1475 | yes | no  | cellular  | 16 | ⋯ | 3 | 120 | 11 | 0.437965662, 0.26951733, 0.055285606 | 0.43990135, 0.1841969893, 2.570920e-02 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 0.6408124 | 0.3591876 |\n| 45201 | 38 | technician   | married  | secondary | no |  557 | yes | no  | cellular  | 16 | ⋯ | 4 |  -1 |  0 | 0.391966310, 0.35633301, 0.107979700 | 0.26420286, 0.0331814532, 1.389095e-03 | 0.441, 0.189, 0.027 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45203 | 34 | admin.       | single   | secondary | no |  557 | no  | no  | cellular  | 17 | ⋯ | 1 |  -1 |  0 | 0.437965662, 0.26951733, 0.055285606 | 0.26420286, 0.0331814532, 1.389095e-03 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45204 | 23 | student      | single   | tertiary  | no |  113 | no  | no  | cellular  | 17 | ⋯ | 1 |  -1 |  0 | 0.277170392, 0.03745546, 0.001687183 | 0.06530407, 0.0015233606, 1.184524e-05 | 0.000, 0.000, 0.000 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45206 | 25 | technician   | single   | secondary | no |  505 | no  | yes | cellular  | 17 | ⋯ | 2 |  -1 |  0 | 0.347222222, 0.06944444, 0.004629630 | 0.24522266, 0.0276045976, 1.035812e-03 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45207 | 51 | technician   | married  | tertiary  | no |  825 | no  | no  | cellular  | 17 | ⋯ | 3 |  -1 |  0 | 0.108236152, 0.39686589, 0.485058309 | 0.34533747, 0.0683230532, 4.505776e-03 | 0.384, 0.096, 0.008 | 0.0000000, 0.00000000, 0.000000000 | 0.0000000, 0.00000000, 0.0000000000 | 0.6912076 | 0.3087924 |\n| 45209 | 72 | retired      | married  | secondary | no | 5715 | no  | no  | cellular  | 17 | ⋯ | 5 | 120 |  3 | 0.000000000, 0.00000000, 1.000000000 | 0.00000000, 0.0000000000, 1.000000e+00 | 0.432, 0.288, 0.064 | 0.0000000, 0.00000000, 1.000000000 | 0.4327573, 0.16228400, 0.0202854996 | 0.6270424 | 0.3729576 |\n| 45211 | 37 | entrepreneur | married  | secondary | no | 2971 | no  | no  | cellular  | 17 | ⋯ | 2 | 120 | 11 | 0.406988986, 0.33620829, 0.092579095 | 0.29346992, 0.4298632801, 2.098823e-01 | 0.243, 0.027, 0.001 | 0.0000000, 0.00000000, 1.000000000 | 0.0000000, 0.00000000, 1.0000000000 | 0.6408124 | 0.3591876 |\n\n",
            "text/plain": [
              "      age job           marital  education default balance housing loan\n",
              "1     58  management    married  tertiary  no       2143   yes     no  \n",
              "2     44  technician    single   secondary no         29   yes     no  \n",
              "4     47  blue-collar   married  unknown   no       1506   yes     no  \n",
              "6     35  management    married  tertiary  no        231   yes     no  \n",
              "8     42  entrepreneur  divorced tertiary  yes         2   yes     no  \n",
              "10    43  technician    single   secondary no        593   yes     no  \n",
              "11    41  admin.        divorced secondary no        270   yes     no  \n",
              "14    58  technician    married  unknown   no         71   yes     no  \n",
              "16    51  retired       married  primary   no        229   yes     no  \n",
              "18    57  blue-collar   married  primary   no         52   yes     no  \n",
              "19    60  retired       married  primary   no         60   yes     no  \n",
              "22    56  management    married  tertiary  no        779   yes     no  \n",
              "23    32  blue-collar   single   primary   no         23   yes     yes \n",
              "24    25  services      married  secondary no         50   yes     no  \n",
              "25    40  retired       married  primary   no          0   yes     yes \n",
              "26    44  admin.        married  secondary no       -372   yes     no  \n",
              "29    46  management    single   secondary no       -246   yes     no  \n",
              "31    57  technician    married  secondary no        839   no      yes \n",
              "32    49  management    married  tertiary  no        378   yes     no  \n",
              "33    60  admin.        married  secondary no         39   yes     yes \n",
              "34    59  blue-collar   married  secondary no          0   yes     no  \n",
              "35    51  management    married  tertiary  no      10635   yes     no  \n",
              "36    57  technician    divorced secondary no         63   yes     no  \n",
              "37    25  blue-collar   married  secondary no         -7   yes     no  \n",
              "38    53  technician    married  secondary no         -3   no      no  \n",
              "41    44  services      divorced secondary no       2586   yes     no  \n",
              "46    36  admin.        single   primary   no       -171   yes     no  \n",
              "47    58  self-employed married  tertiary  no       -364   yes     no  \n",
              "50    29  management    single   tertiary  no          0   yes     no  \n",
              "52    48  management    divorced tertiary  no       -244   yes     no  \n",
              "⋮     ⋮   ⋮             ⋮        ⋮         ⋮       ⋮       ⋮       ⋮   \n",
              "45152 47  management    single   tertiary  no       311    yes     yes \n",
              "45154 64  retired       married  tertiary  no      2059    no      yes \n",
              "45155 63  retired       married  primary   no      3738    no      no  \n",
              "45156 44  entrepreneur  married  tertiary  no       121    no      no  \n",
              "45157 37  management    married  tertiary  no      3556    no      no  \n",
              "45159 34  student       single   unknown   no      2321    no      no  \n",
              "45162 31  management    married  tertiary  no       720    yes     no  \n",
              "45163 29  admin.        single   secondary no       464    no      no  \n",
              "45164 71  retired       married  secondary no      2064    no      no  \n",
              "45166 33  technician    married  tertiary  no      2976    yes     no  \n",
              "45169 62  retired       married  tertiary  no      2557    yes     no  \n",
              "45172 33  admin.        single   secondary no       690    no      no  \n",
              "45175 62  blue-collar   married  secondary no       272    no      no  \n",
              "45177 54  admin.        married  secondary no        66    yes     no  \n",
              "45178 36  admin.        divorced secondary no      1224    yes     no  \n",
              "45179 34  blue-collar   married  secondary no       320    yes     no  \n",
              "45185 63  retired       married  secondary no      1495    no      no  \n",
              "45188 32  services      single   secondary no      1168    yes     no  \n",
              "45195 59  management    married  tertiary  no       138    yes     yes \n",
              "45197 25  student       single   secondary no       358    no      no  \n",
              "45198 36  management    single   secondary no      1511    yes     no  \n",
              "45199 37  management    married  tertiary  no      1428    no      no  \n",
              "45200 34  blue-collar   single   secondary no      1475    yes     no  \n",
              "45201 38  technician    married  secondary no       557    yes     no  \n",
              "45203 34  admin.        single   secondary no       557    no      no  \n",
              "45204 23  student       single   tertiary  no       113    no      no  \n",
              "45206 25  technician    single   secondary no       505    no      yes \n",
              "45207 51  technician    married  tertiary  no       825    no      no  \n",
              "45209 72  retired       married  secondary no      5715    no      no  \n",
              "45211 37  entrepreneur  married  secondary no      2971    no      no  \n",
              "      contact   day ⋯ campaign_11 pdays_120 previous_11\n",
              "1     unknown   5   ⋯ 1           -1        0          \n",
              "2     unknown   5   ⋯ 1           -1        0          \n",
              "4     unknown   5   ⋯ 1           -1        0          \n",
              "6     unknown   5   ⋯ 1           -1        0          \n",
              "8     unknown   5   ⋯ 1           -1        0          \n",
              "10    unknown   5   ⋯ 1           -1        0          \n",
              "11    unknown   5   ⋯ 1           -1        0          \n",
              "14    unknown   5   ⋯ 1           -1        0          \n",
              "16    unknown   5   ⋯ 1           -1        0          \n",
              "18    unknown   5   ⋯ 1           -1        0          \n",
              "19    unknown   5   ⋯ 1           -1        0          \n",
              "22    unknown   5   ⋯ 1           -1        0          \n",
              "23    unknown   5   ⋯ 1           -1        0          \n",
              "24    unknown   5   ⋯ 1           -1        0          \n",
              "25    unknown   5   ⋯ 1           -1        0          \n",
              "26    unknown   5   ⋯ 1           -1        0          \n",
              "29    unknown   5   ⋯ 2           -1        0          \n",
              "31    unknown   5   ⋯ 1           -1        0          \n",
              "32    unknown   5   ⋯ 1           -1        0          \n",
              "33    unknown   5   ⋯ 1           -1        0          \n",
              "34    unknown   5   ⋯ 1           -1        0          \n",
              "35    unknown   5   ⋯ 1           -1        0          \n",
              "36    unknown   5   ⋯ 1           -1        0          \n",
              "37    unknown   5   ⋯ 1           -1        0          \n",
              "38    unknown   5   ⋯ 1           -1        0          \n",
              "41    unknown   5   ⋯ 1           -1        0          \n",
              "46    unknown   5   ⋯ 1           -1        0          \n",
              "47    unknown   5   ⋯ 1           -1        0          \n",
              "50    unknown   5   ⋯ 1           -1        0          \n",
              "52    unknown   5   ⋯ 1           -1        0          \n",
              "⋮     ⋮         ⋮   ⋱ ⋮           ⋮         ⋮          \n",
              "45152 cellular   9  ⋯ 3           120        2         \n",
              "45154 cellular   9  ⋯ 1            95        1         \n",
              "45155 telephone  9  ⋯ 1           120        4         \n",
              "45156 cellular   9  ⋯ 1            91        1         \n",
              "45157 cellular   9  ⋯ 1            -1        0         \n",
              "45159 cellular   9  ⋯ 2            99        5         \n",
              "45162 cellular   9  ⋯ 3            -1        0         \n",
              "45163 cellular   9  ⋯ 2            91        3         \n",
              "45164 cellular   9  ⋯ 2            92        3         \n",
              "45166 cellular   9  ⋯ 2            95       11         \n",
              "45169 cellular  10  ⋯ 1            57        8         \n",
              "45172 cellular  10  ⋯ 3           120       11         \n",
              "45175 cellular  11  ⋯ 1            92        3         \n",
              "45177 cellular  11  ⋯ 1            -1        0         \n",
              "45178 cellular  12  ⋯ 1           120        1         \n",
              "45179 cellular  12  ⋯ 1            92        3         \n",
              "45185 cellular  16  ⋯ 1            22        5         \n",
              "45188 cellular  16  ⋯ 1            -1        0         \n",
              "45195 cellular  16  ⋯ 2           120        5         \n",
              "45197 cellular  16  ⋯ 1            -1        0         \n",
              "45198 cellular  16  ⋯ 1            -1        0         \n",
              "45199 cellular  16  ⋯ 2            -1        0         \n",
              "45200 cellular  16  ⋯ 3           120       11         \n",
              "45201 cellular  16  ⋯ 4            -1        0         \n",
              "45203 cellular  17  ⋯ 1            -1        0         \n",
              "45204 cellular  17  ⋯ 1            -1        0         \n",
              "45206 cellular  17  ⋯ 2            -1        0         \n",
              "45207 cellular  17  ⋯ 3            -1        0         \n",
              "45209 cellular  17  ⋯ 5           120        3         \n",
              "45211 cellular  17  ⋯ 2           120       11         \n",
              "      B_age                               \n",
              "1     0.006478782, 0.12957564, 0.86383760 \n",
              "2     0.269517331, 0.43796566, 0.23723140 \n",
              "4     0.198453191, 0.44270327, 0.32918961 \n",
              "6     0.430231616, 0.29255750, 0.06631303 \n",
              "8     0.314868805, 0.41982507, 0.18658892 \n",
              "10    0.292557499, 0.43023162, 0.21089785 \n",
              "11    0.336208293, 0.40698899, 0.16422363 \n",
              "14    0.006478782, 0.12957564, 0.86383760 \n",
              "16    0.108236152, 0.39686589, 0.48505831 \n",
              "18    0.014212828, 0.18476676, 0.80065598 \n",
              "19    0.000000000, 0.00000000, 1.00000000 \n",
              "22    0.024619372, 0.23388403, 0.74063276 \n",
              "23    0.444444444, 0.22222222, 0.03703704 \n",
              "24    0.347222222, 0.06944444, 0.00462963 \n",
              "25    0.356333009, 0.39196631, 0.14372098 \n",
              "26    0.269517331, 0.43796566, 0.23723140 \n",
              "29    0.222222222, 0.44444444, 0.29629630 \n",
              "31    0.014212828, 0.18476676, 0.80065598 \n",
              "32    0.151886945, 0.42804503, 0.40210290 \n",
              "33    0.000000000, 0.00000000, 1.00000000 \n",
              "34    0.001660188, 0.06806770, 0.93025861 \n",
              "35    0.108236152, 0.39686589, 0.48505831 \n",
              "36    0.014212828, 0.18476676, 0.80065598 \n",
              "37    0.347222222, 0.06944444, 0.00462963 \n",
              "38    0.069444444, 0.34722222, 0.57870370 \n",
              "41    0.269517331, 0.43796566, 0.23723140 \n",
              "46    0.419825073, 0.31486880, 0.07871720 \n",
              "47    0.006478782, 0.12957564, 0.86383760 \n",
              "50    0.428045028, 0.15188695, 0.01796512 \n",
              "52    0.174927114, 0.43731778, 0.36443149 \n",
              "⋮     ⋮                                   \n",
              "45152 0.198453191, 0.44270327, 0.329189612\n",
              "45154 0.000000000, 0.00000000, 1.000000000\n",
              "45155 0.000000000, 0.00000000, 1.000000000\n",
              "45156 0.269517331, 0.43796566, 0.237231400\n",
              "45157 0.406988986, 0.33620829, 0.092579095\n",
              "45159 0.437965662, 0.26951733, 0.055285606\n",
              "45162 0.442703272, 0.19845319, 0.029653925\n",
              "45163 0.428045028, 0.15188695, 0.017965123\n",
              "45164 0.000000000, 0.00000000, 1.000000000\n",
              "45166 0.442784257, 0.24599125, 0.045553936\n",
              "45169 0.000000000, 0.00000000, 1.000000000\n",
              "45172 0.442784257, 0.24599125, 0.045553936\n",
              "45175 0.000000000, 0.00000000, 1.000000000\n",
              "45177 0.052478134, 0.31486880, 0.629737609\n",
              "45178 0.419825073, 0.31486880, 0.078717201\n",
              "45179 0.437965662, 0.26951733, 0.055285606\n",
              "45185 0.000000000, 0.00000000, 1.000000000\n",
              "45188 0.444444444, 0.22222222, 0.037037037\n",
              "45195 0.001660188, 0.06806770, 0.930258611\n",
              "45197 0.347222222, 0.06944444, 0.004629630\n",
              "45198 0.419825073, 0.31486880, 0.078717201\n",
              "45199 0.406988986, 0.33620829, 0.092579095\n",
              "45200 0.437965662, 0.26951733, 0.055285606\n",
              "45201 0.391966310, 0.35633301, 0.107979700\n",
              "45203 0.437965662, 0.26951733, 0.055285606\n",
              "45204 0.277170392, 0.03745546, 0.001687183\n",
              "45206 0.347222222, 0.06944444, 0.004629630\n",
              "45207 0.108236152, 0.39686589, 0.485058309\n",
              "45209 0.000000000, 0.00000000, 1.000000000\n",
              "45211 0.406988986, 0.33620829, 0.092579095\n",
              "      B_balance                                B_campaign         \n",
              "1     0.4197550723, 3.150000e-01, 7.879593e-02 0.000, 0.000, 0.000\n",
              "2     0.0177811347, 1.073092e-04, 2.158705e-07 0.000, 0.000, 0.000\n",
              "4     0.4412754278, 1.903269e-01, 2.736335e-02 0.000, 0.000, 0.000\n",
              "6     0.1265590834, 6.156785e-03, 9.983743e-05 0.000, 0.000, 0.000\n",
              "8     0.0017974816, 1.078921e-06, 2.158705e-10 0.000, 0.000, 0.000\n",
              "10    0.2767089696, 3.729638e-02, 1.675671e-03 0.000, 0.000, 0.000\n",
              "11    0.1454260685, 8.332022e-03, 1.591246e-04 0.000, 0.000, 0.000\n",
              "14    0.0419566518, 6.128787e-04, 2.984193e-06 0.000, 0.000, 0.000\n",
              "16    0.1255733153, 6.053629e-03, 9.727762e-05 0.000, 0.000, 0.000\n",
              "18    0.0311233218, 3.333743e-04, 1.190302e-06 0.000, 0.000, 0.000\n",
              "19    0.0357054428, 4.408972e-04, 1.814759e-06 0.000, 0.000, 0.000\n",
              "22    0.3333312248, 6.159639e-02, 3.794139e-03 0.000, 0.000, 0.000\n",
              "23    0.0142592674, 6.876078e-05, 1.105257e-07 0.000, 0.000, 0.000\n",
              "24    0.0299730726, 3.088135e-04, 1.060572e-06 0.000, 0.000, 0.000\n",
              "25    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "26    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "29    0.0000000000, 0.000000e+00, 0.000000e+00 0.243, 0.027, 0.001\n",
              "31    0.3488393019, 7.042178e-02, 4.738788e-03 0.000, 0.000, 0.000\n",
              "32    0.1942002494, 1.592425e-02, 4.352583e-04 0.000, 0.000, 0.000\n",
              "33    0.0236128896, 1.903881e-04, 5.116929e-07 0.000, 0.000, 0.000\n",
              "34    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "35    0.0000000000, 0.000000e+00, 1.000000e+00 0.000, 0.000, 0.000\n",
              "36    0.0374159623, 4.850358e-04, 2.095894e-06 0.000, 0.000, 0.000\n",
              "37    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "38    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "41    0.3615943628, 3.875081e-01, 1.384263e-01 0.000, 0.000, 0.000\n",
              "46    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "47    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "50    0.0005996401, 1.199280e-07, 7.995202e-12 0.000, 0.000, 0.000\n",
              "52    0.0000000000, 0.000000e+00, 0.000000e+00 0.000, 0.000, 0.000\n",
              "⋮     ⋮                                        ⋮                  \n",
              "45152 0.16453782, 0.0109481342, 2.428249e-04   0.384, 0.096, 0.008\n",
              "45154 0.42737387, 0.2993506161, 6.989258e-02   0.000, 0.000, 0.000\n",
              "45155 0.14283179, 0.4231759485, 4.179226e-01   0.000, 0.000, 0.000\n",
              "45156 0.06965819, 0.0017418116, 1.451807e-05   0.000, 0.000, 0.000\n",
              "45157 0.17789713, 0.4382133607, 3.598165e-01   0.000, 0.000, 0.000\n",
              "45159 0.39972226, 0.3464557994, 1.000959e-01   0.243, 0.027, 0.001\n",
              "45162 0.31679148, 0.0533660415, 2.996645e-03   0.384, 0.096, 0.008\n",
              "45163 0.22948259, 0.0235250006, 8.038746e-04   0.243, 0.027, 0.001\n",
              "45164 0.42695573, 0.3002941379, 7.040275e-02   0.243, 0.027, 0.001\n",
              "45166 0.29251662, 0.4302480083, 2.109434e-01   0.243, 0.027, 0.001\n",
              "45169 0.36618299, 0.3834204198, 1.338231e-01   0.000, 0.000, 0.000\n",
              "45172 0.30788128, 0.0493610121, 2.637932e-03   0.384, 0.096, 0.008\n",
              "45175 0.14637546, 0.0084518825, 1.626737e-04   0.000, 0.000, 0.000\n",
              "45177 0.03912225, 0.0005312506, 2.404661e-06   0.000, 0.000, 0.000\n",
              "45178 0.41893896, 0.1359110770, 1.469730e-02   0.000, 0.000, 0.000\n",
              "45179 0.16863489, 0.0115666238, 2.644506e-04   0.000, 0.000, 0.000\n",
              "45185 0.44081699, 0.1881489939, 2.676851e-02   0.000, 0.000, 0.000\n",
              "45188 0.41173350, 0.1256045043, 1.277241e-02   0.000, 0.000, 0.000\n",
              "45195 0.07881255, 0.0022531767, 2.147207e-05   0.243, 0.027, 0.001\n",
              "45197 0.18554763, 0.0143497629, 3.699242e-04   0.000, 0.000, 0.000\n",
              "45198 0.44147328, 0.1913177404, 2.763661e-02   0.000, 0.000, 0.000\n",
              "45199 0.43732653, 0.1749550968, 2.333061e-02   0.243, 0.027, 0.001\n",
              "45200 0.43990135, 0.1841969893, 2.570920e-02   0.384, 0.096, 0.008\n",
              "45201 0.26420286, 0.0331814532, 1.389095e-03   0.441, 0.189, 0.027\n",
              "45203 0.26420286, 0.0331814532, 1.389095e-03   0.000, 0.000, 0.000\n",
              "45204 0.06530407, 0.0015233606, 1.184524e-05   0.000, 0.000, 0.000\n",
              "45206 0.24522266, 0.0276045976, 1.035812e-03   0.243, 0.027, 0.001\n",
              "45207 0.34533747, 0.0683230532, 4.505776e-03   0.384, 0.096, 0.008\n",
              "45209 0.00000000, 0.0000000000, 1.000000e+00   0.432, 0.288, 0.064\n",
              "45211 0.29346992, 0.4298632801, 2.098823e-01   0.243, 0.027, 0.001\n",
              "      B_pdays                            B_previous                         \n",
              "1     0, 0, 0                            0, 0, 0                            \n",
              "2     0, 0, 0                            0, 0, 0                            \n",
              "4     0, 0, 0                            0, 0, 0                            \n",
              "6     0, 0, 0                            0, 0, 0                            \n",
              "8     0, 0, 0                            0, 0, 0                            \n",
              "10    0, 0, 0                            0, 0, 0                            \n",
              "11    0, 0, 0                            0, 0, 0                            \n",
              "14    0, 0, 0                            0, 0, 0                            \n",
              "16    0, 0, 0                            0, 0, 0                            \n",
              "18    0, 0, 0                            0, 0, 0                            \n",
              "19    0, 0, 0                            0, 0, 0                            \n",
              "22    0, 0, 0                            0, 0, 0                            \n",
              "23    0, 0, 0                            0, 0, 0                            \n",
              "24    0, 0, 0                            0, 0, 0                            \n",
              "25    0, 0, 0                            0, 0, 0                            \n",
              "26    0, 0, 0                            0, 0, 0                            \n",
              "29    0, 0, 0                            0, 0, 0                            \n",
              "31    0, 0, 0                            0, 0, 0                            \n",
              "32    0, 0, 0                            0, 0, 0                            \n",
              "33    0, 0, 0                            0, 0, 0                            \n",
              "34    0, 0, 0                            0, 0, 0                            \n",
              "35    0, 0, 0                            0, 0, 0                            \n",
              "36    0, 0, 0                            0, 0, 0                            \n",
              "37    0, 0, 0                            0, 0, 0                            \n",
              "38    0, 0, 0                            0, 0, 0                            \n",
              "41    0, 0, 0                            0, 0, 0                            \n",
              "46    0, 0, 0                            0, 0, 0                            \n",
              "47    0, 0, 0                            0, 0, 0                            \n",
              "50    0, 0, 0                            0, 0, 0                            \n",
              "52    0, 0, 0                            0, 0, 0                            \n",
              "⋮     ⋮                                  ⋮                                  \n",
              "45152 0.0000000, 0.00000000, 1.000000000 0.3651390, 0.08114200, 0.0060105184\n",
              "45154 0.1016053, 0.39016438, 0.499410407 0.2253944, 0.02253944, 0.0007513148\n",
              "45155 0.0000000, 0.00000000, 1.000000000 0.4417731, 0.25244177, 0.0480841473\n",
              "45156 0.1310234, 0.41566054, 0.439549076 0.2253944, 0.02253944, 0.0007513148\n",
              "45157 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45159 0.0746799, 0.35561858, 0.564473930 0.4057100, 0.33809166, 0.0939143501\n",
              "45162 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45163 0.1310234, 0.41566054, 0.439549076 0.4327573, 0.16228400, 0.0202854996\n",
              "45164 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45166 0.1016053, 0.39016438, 0.499410407 0.0000000, 0.00000000, 1.0000000000\n",
              "45169 0.3898291, 0.35889027, 0.110135637 0.1622840, 0.43275733, 0.3846731781\n",
              "45172 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "45175 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45177 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45178 0.0000000, 0.00000000, 1.000000000 0.2253944, 0.02253944, 0.0007513148\n",
              "45179 0.1234708, 0.41009934, 0.454038557 0.4327573, 0.16228400, 0.0202854996\n",
              "45185 0.3740633, 0.08779037, 0.006867954 0.4057100, 0.33809166, 0.0939143501\n",
              "45188 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45195 0.0000000, 0.00000000, 1.000000000 0.4057100, 0.33809166, 0.0939143501\n",
              "45197 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45198 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45199 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45200 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "45201 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45203 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45204 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45206 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45207 0.0000000, 0.00000000, 0.000000000 0.0000000, 0.00000000, 0.0000000000\n",
              "45209 0.0000000, 0.00000000, 1.000000000 0.4327573, 0.16228400, 0.0202854996\n",
              "45211 0.0000000, 0.00000000, 1.000000000 0.0000000, 0.00000000, 1.0000000000\n",
              "      X0        X1       \n",
              "1     0.6912076 0.3087924\n",
              "2     0.6912076 0.3087924\n",
              "4     0.6912076 0.3087924\n",
              "6     0.6912076 0.3087924\n",
              "8     0.6912076 0.3087924\n",
              "10    0.6912076 0.3087924\n",
              "11    0.6912076 0.3087924\n",
              "14    0.6912076 0.3087924\n",
              "16    0.6912076 0.3087924\n",
              "18    0.6912076 0.3087924\n",
              "19    0.6912076 0.3087924\n",
              "22    0.6912076 0.3087924\n",
              "23    0.6912076 0.3087924\n",
              "24    0.6912076 0.3087924\n",
              "25    0.6912076 0.3087924\n",
              "26    0.6912076 0.3087924\n",
              "29    0.6912076 0.3087924\n",
              "31    0.6912076 0.3087924\n",
              "32    0.6912076 0.3087924\n",
              "33    0.6912076 0.3087924\n",
              "34    0.6912076 0.3087924\n",
              "35    0.6912076 0.3087924\n",
              "36    0.6912076 0.3087924\n",
              "37    0.6912076 0.3087924\n",
              "38    0.6912076 0.3087924\n",
              "41    0.6912076 0.3087924\n",
              "46    0.6912076 0.3087924\n",
              "47    0.6912076 0.3087924\n",
              "50    0.6912076 0.3087924\n",
              "52    0.6912076 0.3087924\n",
              "⋮     ⋮         ⋮        \n",
              "45152 0.6527043 0.3472957\n",
              "45154 0.6413766 0.3586234\n",
              "45155 0.6527043 0.3472957\n",
              "45156 0.6274899 0.3725101\n",
              "45157 0.6912076 0.3087924\n",
              "45159 0.6532363 0.3467637\n",
              "45162 0.6912076 0.3087924\n",
              "45163 0.6274899 0.3725101\n",
              "45164 0.6533850 0.3466150\n",
              "45166 0.6413766 0.3586234\n",
              "45169 0.6279270 0.3720730\n",
              "45172 0.6527043 0.3472957\n",
              "45175 0.6274767 0.3725233\n",
              "45177 0.6912076 0.3087924\n",
              "45178 0.6270424 0.3729576\n",
              "45179 0.6274767 0.3725233\n",
              "45185 0.6285563 0.3714437\n",
              "45188 0.6912076 0.3087924\n",
              "45195 0.6527043 0.3472957\n",
              "45197 0.6912076 0.3087924\n",
              "45198 0.6912076 0.3087924\n",
              "45199 0.6912076 0.3087924\n",
              "45200 0.6408124 0.3591876\n",
              "45201 0.6912076 0.3087924\n",
              "45203 0.6912076 0.3087924\n",
              "45204 0.6912076 0.3087924\n",
              "45206 0.6912076 0.3087924\n",
              "45207 0.6912076 0.3087924\n",
              "45209 0.6270424 0.3729576\n",
              "45211 0.6408124 0.3591876"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelDNNTest_out_result_data <- data.frame(samp_o,predict(modelDNNTest,samp_o,type=\"prob\"))\n",
        "modelDNNTest_out_result_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2-xJBczA3fR"
      },
      "outputs": [],
      "source": [
        "write.table(modelDNNTest_out_result_data, file = \"/content/modelDNNTest_out_result_data.csv\",row.names=F,sep=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZJAhn4mBA3fR",
        "outputId": "2686da78-3761-43ac-af53-321760377625"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "22.877074607646"
            ],
            "text/latex": "22.877074607646",
            "text/markdown": "22.877074607646",
            "text/plain": [
              "[1] 22.87707"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#目的変数名\n",
        "targetName <- \"C_yF\"\n",
        "targetPred <- modelDNNTest_out_result_data[,targetName]\n",
        "\n",
        "#ソートする変数、予測確率、GNO、CR\n",
        "sortName <- \"X1\"\n",
        "sortPred <- modelDNNTest_out_result_data[,sortName]\n",
        "\n",
        "#ARの計算\n",
        "pred <- prediction(sortPred,targetPred)\n",
        "AUC <- as.numeric( performance(pred,\"auc\")@y.values )\n",
        "AR <- 2 *(AUC-0.5) * 100 #AR値\n",
        "\n",
        "AR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 99-4.特徴量重要度"
      ],
      "metadata": {
        "id": "oAzo8wMsDTQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-1.特徴量重要度_ニューラル"
      ],
      "metadata": {
        "id": "ZsQ537BTRdF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelNnet <- readRDS(file = \"/content/modelNnet.obj\")\n",
        "caret::varImp(modelNnet, scale = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "rza2rOWiRvbG",
        "outputId": "3305edaa-857d-45f3-89b3-b7b02feb0d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "nnet variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 863)\n",
              "\n",
              "                       Overall\n",
              "C_day27:B_campaign1     100.00\n",
              "C_poutcomesuccess        98.26\n",
              "C_monthaug:B_campaign1   94.24\n",
              "C_day30:B_campaign1      87.98\n",
              "C_day26:B_age2           84.60\n",
              "B_campaign3              83.48\n",
              "C_monthjul:B_pdays3      80.34\n",
              "C_day27:B_balance2       80.06\n",
              "C_monthaug:B_pdays3      74.38\n",
              "C_day5:B_campaign1       73.01\n",
              "C_monthmar:B_campaign3   71.28\n",
              "C_day10:B_campaign1      70.44\n",
              "C_day27:B_pdays3         69.87\n",
              "C_day8:B_balance2        69.12\n",
              "C_day15:B_balance2       69.00\n",
              "C_day17:B_age2           68.32\n",
              "C_monthjan:B_campaign3   68.17\n",
              "B_previous3:C_monthjun   67.75\n",
              "C_day7:B_age2            66.90\n",
              "C_monthmar:B_age2        66.16"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-2.特徴量重要度_rf"
      ],
      "metadata": {
        "id": "F_MzubWwRlnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelRF_sw <- readRDS(file = \"/content/modelRF_sw.obj\")\n",
        "caret::varImp(modelRF_sw, scale = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "rKkJ7ck1UshE",
        "outputId": "69d0fd01-b2a8-42e6-fe40-15bd661b00ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rf variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 197)\n",
              "\n",
              "                             Overall\n",
              "C_poutcomesuccess:B_pdays3    100.00\n",
              "C_poutcomesuccess              88.03\n",
              "C_poutcomesuccess:B_balance3   83.79\n",
              "C_poutcomesuccess:B_age3       83.71\n",
              "C_poutcomesuccess:B_age2       83.24\n",
              "C_poutcomesuccess:B_balance2   83.04\n",
              "C_poutcomesuccess:B_balance1   66.34\n",
              "C_poutcomesuccess:B_age1       61.15\n",
              "C_poutcomeunknown:B_age2       43.64\n",
              "C_housingyes                   38.45\n",
              "C_poutcomesuccess:B_pdays1     37.14\n",
              "B_age2                         36.81\n",
              "C_poutcomeunknown:B_age3       36.24\n",
              "B_age3                         33.95\n",
              "B_pdays3                       33.51\n",
              "B_pdays2                       32.88\n",
              "C_poutcomesuccess:B_pdays2     32.51\n",
              "C_monthmar                     30.52\n",
              "B_age1                         30.46\n",
              "B_previous2                    30.20"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelRF_sw, scale = FALSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "YsXSSLbdiy2W",
        "outputId": "5ed4ca90-a127-4361-d9e4-9d7a5b22043d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rf variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 197)\n",
              "\n",
              "                             Overall\n",
              "C_poutcomesuccess:B_pdays3     33.11\n",
              "C_poutcomesuccess              29.15\n",
              "C_poutcomesuccess:B_balance3   27.75\n",
              "C_poutcomesuccess:B_age3       27.72\n",
              "C_poutcomesuccess:B_age2       27.57\n",
              "C_poutcomesuccess:B_balance2   27.50\n",
              "C_poutcomesuccess:B_balance1   21.98\n",
              "C_poutcomesuccess:B_age1       20.27\n",
              "C_poutcomeunknown:B_age2       14.48\n",
              "C_housingyes                   12.76\n",
              "C_poutcomesuccess:B_pdays1     12.33\n",
              "B_age2                         12.22\n",
              "C_poutcomeunknown:B_age3       12.03\n",
              "B_age3                         11.27\n",
              "B_pdays3                       11.13\n",
              "B_pdays2                       10.92\n",
              "C_poutcomesuccess:B_pdays2     10.80\n",
              "C_monthmar                     10.14\n",
              "B_age1                         10.12\n",
              "B_previous2                    10.03"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-3.特徴量重要度_勾配ブースティング"
      ],
      "metadata": {
        "id": "ZQHgC-ILRrxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelXgboostTree_sw <- readRDS(file = \"/content/modelXgboostTree_sw.obj\")\n",
        "caret::varImp(modelXgboostTree_sw, scale = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "NfZgIxTShekq",
        "outputId": "935a983a-e438-4eba-8b60-76d89420914f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "xgbTree variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 197)\n",
              "\n",
              "                                 Overall\n",
              "C_poutcomesuccess                100.000\n",
              "C_contactunknown:B_age3           50.772\n",
              "C_housingyes                      44.374\n",
              "C_poutcomesuccess:B_balance3      39.671\n",
              "C_poutcomeunknown:B_age2          38.051\n",
              "C_monthmar                        32.428\n",
              "B_age2                            22.749\n",
              "B_balance3                        21.683\n",
              "C_monthoct                        19.909\n",
              "C_contactunknown:B_age1           17.043\n",
              "C_monthsep                        14.638\n",
              "C_poutcomesuccess:B_pdays3        14.054\n",
              "C_maritalmarried                  12.581\n",
              "C_monthaug:B_campaign3            10.913\n",
              "B_campaign3                       10.868\n",
              "C_loanyes                         10.847\n",
              "C_monthaug:B_pdays3                9.951\n",
              "C_monthjun:B_pdays3                6.596\n",
              "C_housingyes:B_pdays3              6.396\n",
              "C_educationsecondary:B_campaign2   6.322"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-4.特徴量重要度_ロジスティック回帰_PLR"
      ],
      "metadata": {
        "id": "bNLYBnU7zg1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelPLR_sw <- train(\n",
        "  C_yF ~ B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age,\n",
        "  data = samp_i,\n",
        "  method = \"plr\",\n",
        "  tuneLength = 2\n",
        "  )"
      ],
      "metadata": {
        "id": "Y0q4U5Cs0oNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelPLR_sw, scale = TRUE)"
      ],
      "metadata": {
        "id": "MR5ko0Dl3Ea5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelPLR_sw"
      ],
      "metadata": {
        "id": "Y3X5ji8a4W-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelPLR_sw_out_result_data <- data.frame(samp_o,predict(modelPLR_sw,samp_o,type=\"prob\"))\n",
        "write.table(modelPLR_sw_out_result_data, file = \"/content/modelPLR_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelPLR_sw, file = \"/content/modelPLR_sw.obj\")"
      ],
      "metadata": {
        "id": "-Ow_jwQD4WTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-5.特徴量重要度_ロジスティック回帰_GLM"
      ],
      "metadata": {
        "id": "Tr2ugsCpDIGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw <- train(\n",
        "  C_yF ~ B_previous + C_poutcome + C_month + C_day + C_contact +\n",
        "             C_loan + C_housing + C_education + C_marital + B_pdays +\n",
        "             B_campaign + B_balance + B_age + B_previous:C_contact + C_poutcome:B_pdays +\n",
        "             C_month:B_pdays + C_loan:B_pdays + C_housing:B_pdays + C_month:B_campaign +\n",
        "             C_contact:B_campaign + C_housing:B_campaign + C_education:B_campaign +\n",
        "             C_poutcome:B_balance + C_poutcome:B_age + C_contact:B_age,\n",
        "  data = samp_i,\n",
        "   method = \"glm\",\n",
        "  family = binomial(link=\"logit\")\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqV-2gleDIGh",
        "outputId": "101f3804-8fca-490d-c0fa-bf31d0a3bf88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n",
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n",
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelGLM_sw, scale = TRUE)"
      ],
      "metadata": {
        "id": "FY7ePwD-DIGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "2090a0c9-4238-43f0-ce9d-0b94fdcd482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "glm variable importance\n",
              "\n",
              "  only 20 most important variables shown (out of 196)\n",
              "\n",
              "                           Overall\n",
              "`C_monthaug:B_pdays3`       100.00\n",
              "C_monthjul                   97.41\n",
              "`C_monthjul:B_pdays3`        88.45\n",
              "C_housingyes                 71.21\n",
              "C_monthaug                   58.91\n",
              "C_monthmar                   58.73\n",
              "`C_housingyes:B_pdays3`      58.09\n",
              "C_monthjan                   57.77\n",
              "C_monthmay                   56.86\n",
              "C_loanyes                    56.83\n",
              "C_monthnov                   54.79\n",
              "C_monthoct                   52.92\n",
              "C_maritalmarried             52.91\n",
              "`C_monthjun:B_pdays3`        50.13\n",
              "C_monthfeb                   46.07\n",
              "C_contactunknown             42.31\n",
              "`C_monthoct:B_campaign3`     41.37\n",
              "`C_monthoct:B_campaign2`     39.84\n",
              "C_contacttelephone           36.71\n",
              "`C_housingyes:B_campaign3`   35.70"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw"
      ],
      "metadata": {
        "id": "n-bpzlkZDIGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8903b5c0-c3af-40f4-c771-00a70f41af73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generalized Linear Model \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results:\n",
              "\n",
              "  Accuracy   Kappa    \n",
              "  0.8905579  0.2728144\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw_out_result_data <- data.frame(samp_o,predict(modelGLM_sw,samp_o,type=\"prob\"))\n",
        "write.table(modelGLM_sw_out_result_data, file = \"/content/modelGLM_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelGLM_sw, file = \"/content/modelGLM_sw.obj\")"
      ],
      "metadata": {
        "id": "Mm0rqbmNDIGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8abfedc-c499-4ce4-846b-72894c942dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 99-4-5.特徴量重要度_ロジスティック回帰_GLM_組み合わせなし"
      ],
      "metadata": {
        "id": "UEYO6gF3CKar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw_TEST <- train(\n",
        "  C_y ~  C_poutcome ,\n",
        "  data = samp_i,\n",
        "   method = \"glm\",\n",
        "  family = binomial(link=\"logit\")\n",
        "  )"
      ],
      "metadata": {
        "id": "40BHWoaRCKas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelGLM_sw_TEST, scale = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "NBlYjh-m_7KU",
        "outputId": "98199017-c3e9-44cb-b8ea-7d794254404c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "glm variable importance\n",
              "\n",
              "                  Overall\n",
              "C_poutcomesuccess  100.00\n",
              "C_poutcomeunknown   15.48\n",
              "C_poutcomeother      0.00"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caret::varImp(modelGLM_sw_TEST, scale = TRUE)$importance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "DaqYVVfXBZ5H",
        "outputId": "1fa858e9-fc22-433a-853d-d4ad535ec1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 3 × 1</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Overall</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>C_poutcomeother</th><td>  0.00000</td></tr>\n",
              "\t<tr><th scope=row>C_poutcomesuccess</th><td>100.00000</td></tr>\n",
              "\t<tr><th scope=row>C_poutcomeunknown</th><td> 15.47905</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 3 × 1\n\n| <!--/--> | Overall &lt;dbl&gt; |\n|---|---|\n| C_poutcomeother |   0.00000 |\n| C_poutcomesuccess | 100.00000 |\n| C_poutcomeunknown |  15.47905 |\n\n",
            "text/latex": "A data.frame: 3 × 1\n\\begin{tabular}{r|l}\n  & Overall\\\\\n  & <dbl>\\\\\n\\hline\n\tC\\_poutcomeother &   0.00000\\\\\n\tC\\_poutcomesuccess & 100.00000\\\\\n\tC\\_poutcomeunknown &  15.47905\\\\\n\\end{tabular}\n",
            "text/plain": [
              "                  Overall  \n",
              "C_poutcomeother     0.00000\n",
              "C_poutcomesuccess 100.00000\n",
              "C_poutcomeunknown  15.47905"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw_TEST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8903b5c0-c3af-40f4-c771-00a70f41af73",
        "id": "PDRs2H7jCKat"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generalized Linear Model \n",
              "\n",
              "22606 samples\n",
              "   13 predictor\n",
              "    2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Bootstrapped (25 reps) \n",
              "Summary of sample sizes: 22606, 22606, 22606, 22606, 22606, 22606, ... \n",
              "Resampling results:\n",
              "\n",
              "  Accuracy   Kappa    \n",
              "  0.8905579  0.2728144\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGLM_sw_out_result_data <- data.frame(samp_o,predict(modelGLM_sw,samp_o,type=\"prob\"))\n",
        "write.table(modelGLM_sw_out_result_data, file = \"/content/modelGLM_sw_out_result_data.csv\",row.names=F,sep=\",\")\n",
        "saveRDS(modelGLM_sw, file = \"/content/modelGLM_sw.obj\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8abfedc-c499-4ce4-846b-72894c942dcc",
        "id": "uMOAYsF1CKat"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
            "“prediction from a rank-deficient fit may be misleading”\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "30GNmmZH9589"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}